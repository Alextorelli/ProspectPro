Starting Deno language server...
{"type":"mark","name":"lsp.initialize","count":1,"args":{"processId":49976,"rootPath":"/workspaces/ProspectPro","rootUri":"file:///workspaces/ProspectPro","initializationOptions":{"enable":true,"cacheOnSave":true,"disablePaths":[],"enablePaths":["supabase/functions"],"path":null,"env":{},"envFile":null,"cache":null,"certificateStores":null,"codeLens":{"implementations":true,"references":true,"referencesAllFunctions":true,"test":true,"testArgs":["--allow-all","--no-check"]},"config":null,"documentPreloadLimit":1000,"future":false,"importMap":null,"inlayHints":{"parameterNames":{"enabled":"none","suppressWhenArgumentMatchesName":true},"parameterTypes":{"enabled":false},"variableTypes":{"enabled":false,"suppressWhenTypeMatchesName":true},"propertyDeclarationTypes":{"enabled":false},"functionLikeReturnTypes":{"enabled":false},"enumMemberValues":{"enabled":false}},"maxTsServerMemory":3072,"suggest":{"autoImports":true,"completeFunctionCalls":false,"names":true,"paths":true,"imports":{"autoDiscover":true,"hosts":{"https://deno.land":true}}},"trace":{"server":"off"},"testing":{"args":["--allow-all","--no-check"]},"tlsCertificate":null,"unsafelyIgnoreCertificateErrors":null,"unstable":["bare-node-builtins","byonm","sloppy-imports"],"lint":true,"internalDebug":false,"internalInspect":false,"logFile":true,"defaultTaskCommand":"open","javascript":{"referencesCodeLens":{"enabled":false,"showOnAllFunctions":false},"validate":{"enable":true},"suggestionActions":{"enabled":true},"updateImportsOnFileMove":{"enabled":"prompt"},"autoClosingTags":true,"preferGoToSourceDefinition":false,"updateImportsOnPaste":{"enabled":true},"suggest":{"enabled":true,"autoImports":true,"names":true,"completeFunctionCalls":false,"paths":true,"completeJSDocs":true,"jsdoc":{"generateReturns":true},"includeAutomaticOptionalChainCompletions":true,"includeCompletionsForImportStatements":true,"classMemberSnippets":{"enabled":true}},"preferences":{"quoteStyle":"auto","importModuleSpecifier":"shortest","importModuleSpecifierEnding":"auto","jsxAttributeCompletionStyle":"auto","autoImportFileExcludePatterns":[],"autoImportSpecifierExcludeRegexes":[],"useAliasesForRenames":true,"renameMatchingJsxTags":true,"organizeImports":{}},"format":{"enable":true,"insertSpaceAfterCommaDelimiter":true,"insertSpaceAfterConstructor":false,"insertSpaceAfterSemicolonInForStatements":true,"insertSpaceBeforeAndAfterBinaryOperators":true,"insertSpaceAfterKeywordsInControlFlowStatements":true,"insertSpaceAfterFunctionKeywordForAnonymousFunctions":true,"insertSpaceBeforeFunctionParenthesis":false,"insertSpaceAfterOpeningAndBeforeClosingNonemptyParenthesis":false,"insertSpaceAfterOpeningAndBeforeClosingNonemptyBrackets":false,"insertSpaceAfterOpeningAndBeforeClosingNonemptyBraces":true,"insertSpaceAfterOpeningAndBeforeClosingEmptyBraces":true,"insertSpaceAfterOpeningAndBeforeClosingTemplateStringBraces":false,"insertSpaceAfterOpeningAndBeforeClosingJsxExpressionBraces":false,"placeOpenBraceOnNewLineForFunctions":false,"placeOpenBraceOnNewLineForControlBlocks":false,"semicolons":"ignore","indentSwitchCase":true},"inlayHints":{"parameterNames":{"enabled":"none","suppressWhenArgumentMatchesName":true},"parameterTypes":{"enabled":false},"variableTypes":{"enabled":false,"suppressWhenTypeMatchesName":true},"propertyDeclarationTypes":{"enabled":false},"functionLikeReturnTypes":{"enabled":false}}},"typescript":{"tsdk":"","disableAutomaticTypeAcquisition":false,"enablePromptUseWorkspaceTsdk":false,"referencesCodeLens":{"enabled":false,"showOnAllFunctions":false},"implementationsCodeLens":{"enabled":false,"showOnInterfaceMethods":false},"experimental":{"useTsgo":false},"reportStyleChecksAsWarnings":true,"validate":{"enable":true},"tsc":{"autoDetect":"on"},"locale":"auto","suggestionActions":{"enabled":true},"updateImportsOnFileMove":{"enabled":"prompt"},"autoClosingTags":true,"workspaceSymbols":{"scope":"allOpenProjects","excludeLibrarySymbols":true},"preferGoToSourceDefinition":false,"tsserver":{"enableRegionDiagnostics":true,"nodePath":"","web":{"projectWideIntellisense":{"enabled":true,"suppressSemanticErrors":false},"typeAcquisition":{"enabled":true}},"useSyntaxServer":"auto","maxTsServerMemory":3072,"experimental":{"enableProjectDiagnostics":false},"watchOptions":"vscode","enableTracing":false,"log":"off","pluginPaths":[]},"updateImportsOnPaste":{"enabled":true},"suggest":{"enabled":true,"autoImports":false,"completeFunctionCalls":false,"paths":true,"completeJSDocs":true,"jsdoc":{"generateReturns":true},"includeAutomaticOptionalChainCompletions":true,"includeCompletionsForImportStatements":true,"classMemberSnippets":{"enabled":true},"objectLiteralMethodSnippets":{"enabled":true}},"preferences":{"quoteStyle":"auto","importModuleSpecifier":"shortest","importModuleSpecifierEnding":"auto","jsxAttributeCompletionStyle":"auto","includePackageJsonAutoImports":"auto","autoImportFileExcludePatterns":[],"autoImportSpecifierExcludeRegexes":[],"preferTypeOnlyAutoImports":false,"useAliasesForRenames":true,"renameMatchingJsxTags":true,"organizeImports":{}},"format":{"enable":true,"insertSpaceAfterCommaDelimiter":true,"insertSpaceAfterConstructor":false,"insertSpaceAfterSemicolonInForStatements":true,"insertSpaceBeforeAndAfterBinaryOperators":true,"insertSpaceAfterKeywordsInControlFlowStatements":true,"insertSpaceAfterFunctionKeywordForAnonymousFunctions":true,"insertSpaceBeforeFunctionParenthesis":false,"insertSpaceAfterOpeningAndBeforeClosingNonemptyParenthesis":false,"insertSpaceAfterOpeningAndBeforeClosingNonemptyBrackets":false,"insertSpaceAfterOpeningAndBeforeClosingNonemptyBraces":true,"insertSpaceAfterOpeningAndBeforeClosingEmptyBraces":true,"insertSpaceAfterOpeningAndBeforeClosingTemplateStringBraces":false,"insertSpaceAfterOpeningAndBeforeClosingJsxExpressionBraces":false,"insertSpaceAfterTypeAssertion":false,"placeOpenBraceOnNewLineForFunctions":false,"placeOpenBraceOnNewLineForControlBlocks":false,"semicolons":"ignore","indentSwitchCase":true},"inlayHints":{"parameterNames":{"enabled":"none","suppressWhenArgumentMatchesName":true},"parameterTypes":{"enabled":false},"variableTypes":{"enabled":false,"suppressWhenTypeMatchesName":true},"propertyDeclarationTypes":{"enabled":false},"functionLikeReturnTypes":{"enabled":false},"enumMemberValues":{"enabled":false}},"npm":"","check":{"npmIsInstalled":true}},"enableBuiltinCommands":true},"capabilities":{"workspace":{"applyEdit":true,"workspaceEdit":{"documentChanges":true,"resourceOperations":["create","rename","delete"],"failureHandling":"textOnlyTransactional","normalizesLineEndings":true,"changeAnnotationSupport":{"groupsOnLabel":true}},"didChangeConfiguration":{"dynamicRegistration":true},"didChangeWatchedFiles":{"dynamicRegistration":true,"relativePatternSupport":true},"symbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"tagSupport":{"valueSet":[1]},"resolveSupport":{"properties":["location.range"]}},"executeCommand":{"dynamicRegistration":true},"workspaceFolders":true,"configuration":true,"semanticTokens":{"refreshSupport":true},"codeLens":{"refreshSupport":true},"fileOperations":{"dynamicRegistration":true,"didCreate":true,"willCreate":true,"didRename":true,"willRename":true,"didDelete":true,"willDelete":true},"inlineValue":{"refreshSupport":true},"inlayHint":{"refreshSupport":true}},"textDocument":{"synchronization":{"dynamicRegistration":true,"willSave":true,"willSaveWaitUntil":true,"didSave":true},"completion":{"dynamicRegistration":true,"completionItem":{"snippetSupport":true,"commitCharactersSupport":true,"documentationFormat":["markdown","plaintext"],"deprecatedSupport":true,"preselectSupport":true,"tagSupport":{"valueSet":[1]},"insertReplaceSupport":true,"resolveSupport":{"properties":["documentation","detail","additionalTextEdits"]},"insertTextModeSupport":{"valueSet":[1,2]},"labelDetailsSupport":true},"completionItemKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]},"contextSupport":true,"insertTextMode":2,"completionList":{"itemDefaults":["commitCharacters","editRange","insertTextFormat","insertTextMode","data"]}},"hover":{"dynamicRegistration":true,"contentFormat":["markdown","plaintext"]},"signatureHelp":{"dynamicRegistration":true,"signatureInformation":{"documentationFormat":["markdown","plaintext"],"parameterInformation":{"labelOffsetSupport":true},"activeParameterSupport":true},"contextSupport":true},"references":{"dynamicRegistration":true},"documentHighlight":{"dynamicRegistration":true},"documentSymbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"hierarchicalDocumentSymbolSupport":true,"tagSupport":{"valueSet":[1]}},"formatting":{"dynamicRegistration":true},"rangeFormatting":{"dynamicRegistration":true},"onTypeFormatting":{"dynamicRegistration":true},"declaration":{"dynamicRegistration":true,"linkSupport":true},"definition":{"dynamicRegistration":true,"linkSupport":true},"typeDefinition":{"dynamicRegistration":true,"linkSupport":true},"implementation":{"dynamicRegistration":true,"linkSupport":true},"codeAction":{"dynamicRegistration":true,"codeActionLiteralSupport":{"codeActionKind":{"valueSet":["","quickfix","refactor","refactor.extract","refactor.inline","refactor.move","refactor.rewrite","source","source.organizeImports","notebook"]}},"isPreferredSupport":true,"disabledSupport":true,"dataSupport":true,"resolveSupport":{"properties":["edit","command"]},"honorsChangeAnnotations":true},"codeLens":{"dynamicRegistration":true},"documentLink":{"dynamicRegistration":true,"tooltipSupport":true},"colorProvider":{"dynamicRegistration":true},"rename":{"dynamicRegistration":true,"prepareSupport":true,"prepareSupportDefaultBehavior":1,"honorsChangeAnnotations":true},"publishDiagnostics":{"relatedInformation":true,"tagSupport":{"valueSet":[1,2]},"versionSupport":false,"codeDescriptionSupport":true,"dataSupport":true},"foldingRange":{"dynamicRegistration":true,"rangeLimit":5000,"lineFoldingOnly":true,"foldingRangeKind":{"valueSet":["comment","imports","region"]},"foldingRange":{"collapsedText":false}},"selectionRange":{"dynamicRegistration":true},"linkedEditingRange":{"dynamicRegistration":true},"callHierarchy":{"dynamicRegistration":true},"semanticTokens":{"dynamicRegistration":true,"requests":{"range":true,"full":{"delta":true}},"tokenTypes":["namespace","type","class","enum","interface","struct","typeParameter","parameter","variable","property","enumMember","event","function","method","macro","keyword","comment","string","number","regexp","operator","decorator","label"],"tokenModifiers":["declaration","definition","readonly","static","deprecated","abstract","async","modification","documentation","defaultLibrary"],"formats":["relative"],"overlappingTokenSupport":false,"multilineTokenSupport":false,"serverCancelSupport":true,"augmentsSyntaxTokens":true},"typeHierarchy":{"dynamicRegistration":true},"inlineValue":{"dynamicRegistration":true},"inlayHint":{"dynamicRegistration":true,"resolveSupport":{"properties":["tooltip","textEdits","label.tooltip","label.location","label.command"]}},"diagnostic":{"dynamicRegistration":true,"relatedDocumentSupport":false}},"notebookDocument":{"synchronization":{"dynamicRegistration":true}},"window":{"workDoneProgress":true,"showMessage":{"messageActionItem":{"additionalPropertiesSupport":true}},"showDocument":{"support":true}},"general":{"regularExpressions":{"engine":"ECMAScript","version":"ES2020"},"markdown":{"parser":"marked","version":"1.1.0"},"staleRequestSupport":{"cancel":true,"retryOnContentModified":["textDocument/semanticTokens/full","textDocument/semanticTokens/range","textDocument/semanticTokens/full/delta"]},"positionEncodings":["utf-16"]},"experimental":{"testingApi":true}},"trace":"off","workspaceFolders":[{"uri":"file:///workspaces/ProspectPro","name":"ProspectPro"}],"clientInfo":{"name":"Visual Studio Code","version":"1.104.3"},"locale":"en"}},
  version: 2.5.2 (release, x86_64-unknown-linux-gnu)
  executable: /usr/local/share/npm-global/lib/node_modules/deno/deno
Connected to "Visual Studio Code" 1.104.3
{"type":"measure","name":"lsp.initialize","count":1,"duration":0.243},
{"type":"mark","name":"lsp.update_global_cache"},
Enabling import suggestions for: https://deno.land
{"type":"measure","name":"lsp.update_global_cache","count":1,"duration":4.662},
Refreshing configuration tree...
{"type":"mark","name":"lsp.update_cache"},
{"type":"measure","name":"lsp.update_cache","count":1,"duration":0.001},
Server ready.
{"type":"mark","name":"lsp.did_open","count":1,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.devcontainer/devcontainer.json","languageId":"jsonc","version":1,"text":"{\r\n  \"name\": \"ProspectPro - Verified Business Intelligence\",\r\n  \"image\": \"mcr.microsoft.com/devcontainers/javascript-node:20\",\r\n  \"features\": {\r\n    \"ghcr.io/devcontainers/features/git:1\": {}\r\n  },\r\n  \"customizations\": {\r\n    \"vscode\": {\r\n      \"extensions\": [\r\n        // Core Development\r\n        \"denoland.vscode-deno\",\r\n        \"supabase.supabase-vscode\",\r\n        \"dbaeumer.vscode-eslint\",\r\n        \"esbenp.prettier-vscode\",\r\n\r\n        // Productivity\r\n        \"eamodio.gitlens\",\r\n        \"github.copilot\",\r\n        \"github.copilot-chat\",\r\n        \"streetsidesoftware.code-spell-checker\",\r\n        \"wayou.vscode-todo-highlight\",\r\n\r\n        // API Development\r\n        \"humao.rest-client\",\r\n        \"rangav.vscode-thunder-client\",\r\n\r\n        // Database Tools\r\n        \"mtxr.sqltools\",\r\n        \"mtxr.sqltools-driver-pg\",\r\n\r\n        // Security\r\n        \"snyk-security.snyk-vulnerability-scanner\",\r\n\r\n        // Performance\r\n        \"wix.vscode-import-cost\",\r\n\r\n        // Documentation\r\n        \"bierner.markdown-preview-github-styles\",\r\n\r\n        // Development Theme & Visual Organization\r\n        \"deepforest.theme\", // Vira Deepforest theme for organized development\r\n        \"vscode-icons-team.vscode-icons\" // Better file icons for organization\r\n      ],\r\n      \"settings\": {\r\n        \"terminal.integrated.defaultProfile.linux\": \"bash\",\r\n        \"deno.enable\": true,\r\n        \"deno.enablePaths\": [\"supabase/functions\"],\r\n        \"git.autofetch\": true,\r\n        \"git.confirmSync\": false,\r\n        \"git.enableSmartCommit\": true,\r\n\r\n        // Editor Performance Settings - Enhanced for Development\r\n        \"editor.minimap.enabled\": false,\r\n        \"editor.renderWhitespace\": \"none\",\r\n        \"editor.renderControlCharacters\": false,\r\n        \"workbench.colorTheme\": \"Vira Deepforest\", // Development-specific theme\r\n        \"workbench.iconTheme\": \"vscode-icons\", // Better file icons for organization\r\n        \"workbench.list.smoothScrolling\": false,\r\n        \"workbench.tree.renderIndentGuides\": \"none\",\r\n        \"workbench.editor.closeOnFileDelete\": true,\r\n\r\n        // Development-specific UI enhancements\r\n        \"workbench.colorCustomizations\": {\r\n          \"[Vira Deepforest]\": {\r\n            \"titleBar.activeBackground\": \"#1a4d3a\",\r\n            \"titleBar.activeForeground\": \"#ffffff\",\r\n            \"statusBar.background\": \"#1a4d3a\",\r\n            \"statusBar.foreground\": \"#ffffff\",\r\n            \"activityBar.background\": \"#0d2818\",\r\n            \"panel.background\": \"#0a1f14\"\r\n          }\r\n        },\r\n        \"workbench.settings.editor\": \"json\",\r\n        \"breadcrumbs.enabled\": true,\r\n\r\n        // File System Performance\r\n        \"files.watcherExclude\": {\r\n          \"**/*.log\": true,\r\n          \"**/*.tmp\": true,\r\n          \"**/node_modules/**\": true,\r\n          \"**/archive/**\": true,\r\n          \"**/.git/**\": true,\r\n          \"**/logs/**\": true\r\n        },\r\n\r\n        // Search Performance\r\n        \"search.exclude\": {\r\n          \"**/node_modules\": true,\r\n          \"**/*.log\": true,\r\n          \"**/archive/**\": true,\r\n          \"**/.git\": true\r\n        },\r\n        \"search.searchOnType\": false,\r\n\r\n        // Copilot Optimization\r\n        \"github.copilot.chat.historyCount\": 8,\r\n        \"github.copilot.chat.welcomeMessage\": \"none\",\r\n        \"github.copilot.chat.completionPhrasesEnabled\": false,\r\n        \"github.copilot.advanced.setAutoCompletionTriggerThreshold\": 30,\r\n\r\n        // Terminal Settings - Development Enhanced\r\n        \"terminal.integrated.gpuAcceleration\": \"on\",\r\n        \"terminal.integrated.scrollback\": 1000,\r\n        \"terminal.integrated.fontFamily\": \"Consolas, 'Courier New', monospace\",\r\n        \"terminal.integrated.fontSize\": 13,\r\n\r\n        // Development Environment Indicators\r\n        \"window.title\": \"üéØ ${folderName} - Verified Business Intelligence ${separator} ${activeEditorShort}\",\r\n        \"workbench.startupEditor\": \"welcomePageInEmptyWorkbench\",\r\n\r\n        // === MCP (Model Context Protocol) Configuration ===\r\n        \"mcp.enable\": true,\r\n        \"mcp.configFile\": \"${workspaceFolder}/.vscode/mcp-config.json\",\r\n\r\n        // API Development Specific Settings\r\n        \"rest-client.enableTelemetry\": false,\r\n        \"files.associations\": {\r\n          \"*.http\": \"http\",\r\n          \"*.rest\": \"http\"\r\n        },\r\n\r\n        // AI-Enhanced Development Settings for Verified Data Integration\r\n        \"ai.contextAware\": true,\r\n        \"ai.projectContext\": {\r\n          \"type\": \"verified-business-intelligence-platform\",\r\n          \"framework\": \"supabase-edge-functions\",\r\n          \"database\": \"supabase-postgresql\",\r\n          \"apis\": [\r\n            \"google-places\",\r\n            \"apollo-contacts\",\r\n            \"chamber-commerce\",\r\n            \"professional-licensing\"\r\n          ],\r\n          \"deployment\": \"supabase-edge-functions\",\r\n          \"dataPolicy\": \"zero-fake-data-verified-contacts-only\"\r\n        }\r\n      }\r\n    }\r\n  },\r\n  \"forwardPorts\": [3000, 5432],\r\n  \"postCreateCommand\": \"bash -lc 'set -e; echo \\\"ÔøΩ Setting up ProspectPro Verified Business Intelligence Environment...\\\"; sudo apt-get update && sudo apt-get install -y docker.io; if [ -f package-lock.json ]; then npm ci; else npm install; fi; npm i supabase --save-dev; npm run mcp:install; npm run mcp:test; echo \\\"‚úÖ Verified data environment ready with zero fake data policy!\\\"; echo \\\"üöÄ ProspectPro verified business intelligence development ready\\\"'\",\r\n  \"postStartCommand\": \"bash -c 'echo \\\"ÔøΩ ProspectPro Verified Business Intelligence Started\\\"; echo \\\"Data Policy: Zero Fake Data | Contacts: Verified Only | Architecture: Supabase Edge Functions\\\"; echo \\\"üí° Use Copilot Chat for AI-assisted development with verified data context\\\"'\",\r\n  \"runArgs\": [\"--init\", \"-v\", \"/var/run/docker.sock:/var/run/docker.sock\"],\r\n  \"remoteUser\": \"node\"\r\n}\r\n"}}},
{"type":"measure","name":"lsp.did_open","count":1,"duration":0.087},
{"type":"mark","name":"lsp.did_open","count":2,"args":{"textDocument":{"uri":"vscode-userdata:/c%3A/Users/Alext/AppData/Roaming/Code/User/settings.json","languageId":"jsonc","version":3,"text":"{\n  \"window.autoDetectColorScheme\": true,\n  \"github.copilot.nextEditSuggestions.enabled\": true,\n  \"security.workspace.trust.untrustedFiles\": \"open\",\n  \"python.analysis.typeCheckingMode\": \"standard\",\n  \"mssql.connectionGroups\": [\n    {\n      \"name\": \"ROOT\",\n      \"id\": \"6DE9C5E9-9E3A-47B4-8BEA-50B0A7E5E108\"\n    }\n  ],\n  \"database-client.autoSync\": true,\n  \"git.openRepositoryInParentFolders\": \"always\",\n  \"editor.cursorBlinking\": \"expand\",\n  \"editor.wordWrap\": \"on\",\n  \"files.autoSave\": \"onWindowChange\",\n  \"editor.bracketPairColorization.independentColorPoolPerBracketType\": true,\n  \"editor.formatOnSave\": true,\n  \"workbench.iconTheme\": \"vira-icons-teal\",\n  \"mssql.autoDisableNonTSqlLanguageService\": true,\n  \"git.enableSmartCommit\": true,\n  \"git.confirmSync\": false,\n  \"git.autofetch\": true,\n  \"chat.tools.terminal.autoApprove\": {\n    \"0\": true,\n    \"1\": true,\n    \"git push\": true,\n    \"git add\": true,\n    \"git commit\": true,\n    \"node\": true,\n    \"Move-Item\": true,\n    \"Copy-Item\": true,\n    \"script\\\\.\": true,\n    \"old\": true,\n    \"temp\": true,\n    \"backup\\\"\": true,\n    \"nslookup\": true,\n    \"Remove-Item\": true,\n    \"Rename-Item\": true,\n    \"Invoke-WebRequest\": true,\n    \"\\\"apikey\\\"=\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZ2eGRwcmdmbHR6Ymx3dnBlZHB4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MjQ3MTgzOTksImV4cCI6MjA0MDI5NDM5OX0.TZ9kR6FfNvnZMJF9P6NX6rYSVfM3LRw7BfGK7U6YXwc\\\"}\": true,\n    \"\\\"apikey\\\"=\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZ2eGRwcmdmbHR6Ymx3dnBlZHB4Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcyNDcxODM5OSwiZXhwIjoyMDQwMjk0Mzk5fQ.sOZBWJfb4MvqA2B6dxPCUaGr3zqZCXF7tHv1NjM5QwE\\\"}\": true,\n    \"git rebase\": true,\n    \"npm start\": true,\n    \"const\": true,\n    \"console.log('‚úÖ\": true,\n    \"\\\"\": true,\n    \"try\": true,\n    \"}\": true,\n    \"}\\\"\": true,\n    \"powershell\": true,\n    \"Test-Path\": true,\n    \"Start-Process\": true,\n    \"git rm\": true,\n    \"git reset\": true,\n    \"git commit -m \\\"fix: resolve Railway deployment crashes with robust import patterns\\n\\n- Fix api/dashboard-export.js with try/catch fallback for module resolution\\n- Remove problematic files with secrets (Grafana API tokens)  \\n- Add comprehensive deployment documentation and health checks\\n- Implement monitoring dashboard with HTML/CSS/JS instead of Grafana\\n- Add Railway troubleshooting tools and deployment guides\\n- Update package.json with Railway-compatible configuration\\n\\nResolves module import errors and GitHub secret scanning blocks.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"(async\": true,\n    \"{\": true,\n    \"if\": true,\n    \"console.log('üìä\": true,\n    \"git commit -m \\\"optimize: leverage Railway analytics, simplify monitoring architecture\\n\\nüéØ Strategic Changes:\\n- Replace complex custom monitoring with Railway's built-in analytics\\n- Focus only on ProspectPro business metrics (campaigns, leads, costs)\\n- Remove redundant infrastructure monitoring (Railway handles this)\\n- Simplify dashboard to essential business KPIs only\\n\\n‚úÖ Benefits:\\n- 70% reduction in monitoring code complexity\\n- Better reliability using Railway's native capabilities\\n- Focus on business value rather than infrastructure metrics\\n- Faster deployment and fewer moving parts\\n\\nüöÄ Railway Integration:\\n- Use Railway dashboard for: CPU, Memory, Network, Logs, Uptime\\n- Custom dashboard for: Campaign success, Lead qualification, API costs\\n- Simplified health checks focused on business logic\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm outdated\": true,\n    \"=20.0.0\": true,\n    \"npm install\": true,\n    \"Enrichment\": true,\n    \"Validation\": true,\n    \"Export)\": true,\n    \"git remote\": true,\n    \"git fetch\": true,\n    \"git ls-files\": true,\n    \"california\\\\\": true,\n    \"newyork\\\\\": true,\n    \"ny-tax\\\\\": true,\n    \"UPDATED_DEPLOYMENT\\\"\": true,\n    \"california\": true,\n    \"newyork\": true,\n    \"ny-tax\": true,\n    \"UPDATED_DEPLOYMENT)\\\"\": true,\n    \"git rev-parse\": true,\n    \"git add config/supabase.js server.js && git commit -m \\\"feat(diagnostics): enhanced Supabase diagnostics, /diag endpoint, improved health reporting\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git add server.js config/supabase.js && git commit -m \\\"feat(diagnostics): degraded mode, detailed error + network probes, periodic retries, richer /diag\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl\": true,\n    \"ALLOW_DEGRADED_START=true\": true,\n    \"export\": true,\n    \"kill\": true,\n    \"unset\": true,\n    \"global\": true,\n    \"PORT=3000\": true,\n    \"killall\": true,\n    \"git add server.js railway.toml && git commit -m \\\"fix(deployment): bind to 0.0.0.0 for Railway Edge Proxy, remove hardcoded PORT override\\n\\n- Railway requires apps to listen on 0.0.0.0, not localhost\\n- Remove PORT=8080 override in railway.toml to let Railway set it dynamically  \\n- Default to PORT 3000 to match Railway conventions\\n- This should resolve 502 Bad Gateway errors from Railway load balancer\\\" && git push origin main\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_URL=test\": true,\n    \"SUPABASE_URL=https://test.supabase.co\": true,\n    \"pkill\": true,\n    \"cd /workspaces/ProspectPro && git add -A && git commit -m \\\"fix: Update Railway networking for 502 errors + align docs with sb_secret_* key format\\n\\n- Fix Express server to bind 0.0.0.0:PORT (Railway requirement) \\n- Remove hardcoded PORT=8080 from railway.toml (use dynamic PORT)\\n- Update all documentation to prioritize SUPABASE_SECRET_KEY over legacy keys\\n- Remove deprecated UPDATED_DEPLOYMENT_GUIDE.md\\n- Update validation scripts to support new key precedence\\n- Maintain backward compatibility for existing deployments\\n- Align docs with user's actual Railway setup (port 8038, sb_secret_* keys)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git add railway.toml && git commit -m \\\"fix: Clean up railway.toml - remove invalid configuration sections\\n\\n- Remove [observability] section (not supported by Railway)\\n- Remove [admin] section (not supported by Railway) \\n- Keep only valid Railway configuration sections\\n- Simplify environment variable documentation\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_URL=https://example.supabase.co\": true,\n    \"RLS\": true,\n    \"service\": true,\n    \"anon\": true,\n    \"publishable)\\\\n-\": true,\n    \"improve\": true,\n    \"cd /workspaces/ProspectPro && git add server.js database/rls-hardening.sql .env.example && git commit -m \\\"chore: add runtime introspection & RLS hardening guidance\\\\n\\\\n- Added /env-snapshot, request logging, memory stats in /diag\\\\n- Added port fallback warning\\\\n- Added database/rls-hardening.sql with policy templates\\\\n- Updated .env.example (avoid PORT on Railway)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git add server.js database/rls-hardening.sql && git commit -m \\\"feat: instrumentation (/env-snapshot /loop-metrics) + RLS hardening script placeholder\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"getLastSupabaseDiagnostics,\": true,\n    \"console.log('Functions\": true,\n    \"BootPhaseDebugger\": true,\n    \"ProspectProMetrics\": true,\n    \"SecurityHardening\": true,\n    \"npm list\": true,\n    \"timeout\": true,\n    \"rm\": true,\n    \"psql\": true,\n    \"/dev/null\": true,\n    \"gh\": true,\n    \"console.log('=====================================================')\": true,\n    \"console.log('')\": true,\n    \"console.log('\": true,\n    \"console.log('üéØ\": true,\n    \"console.log('1.\": true,\n    \"console.log('2.\": true,\n    \"console.log('3.\": true,\n    \"console.log('üéâ\": true,\n    \"console.log('üîç\": true,\n    \"let\": true,\n    \"//\": true,\n    \"[]).length\": true,\n    \"issues.push(\\\\`‚ö†Ô∏è\": true,\n    \"openParens}\": true,\n    \"closeParens}\": true,\n    \"')\": true,\n    \"!lastStatement.startsWith('--'))\": true,\n    \"issues.push('‚ö†Ô∏è\": true,\n    \"console.log('‚ùå\": true,\n    \"issues.forEach(issue\": true,\n    \"console.log(issue))\": true,\n    \"issues.push('Unbalanced\": true,\n    \"issues.push('system_settings\": true,\n    \"issues.push('Found\": true,\n    \"mv\": true,\n    \"true\": true,\n    \"createClient\": true,\n    \"console.log('üîó\": true,\n    \"supabase.from('information_schema.tables').select('table_name').limit(1).then(result\": true,\n    \"}).catch(err\": true,\n    \"console.error('‚ùå\": true,\n    \"SUPABASE_URL=https://sriycekxdqnesdsgwiuc.supabase.co\": true,\n    \"git branch\": true,\n    \"git checkout\": true,\n    \".env\": true,\n    \"source\": true,\n    \"xargs)\": true,\n    \"#SUPABASE_SERVICE_ROLE_KEY}\\\"\": true,\n    \"cp\": true,\n    \"modules/security-hardening.js\": true,\n    \"'EOF'\": true,\n    \"class\": true,\n    \"constructor(options\": true,\n    \"})\": true,\n    \"this.options\": true,\n    \"enableSecureHeaders:\": true,\n    \"this.options.adminTokens.add(process.env.PERSONAL_ACCESS_TOKEN)\": true,\n    \"console.log('üõ°Ô∏è\": true,\n    \"app.use((req,\": true,\n    \"res.removeHeader('X-Powered-By')\": true,\n    \"res.setHeader('X-Frame-Options',\": true,\n    \"res.setHeader('X-Content-Type-Options',\": true,\n    \"res.setHeader('X-ProspectPro-Security',\": true,\n    \"next()\": true,\n    \"return\": true,\n    \"req.headers['x-admin-token']\": true,\n    \"!this.options.adminTokens.has(token))\": true,\n    \"error:\": true,\n    \"authenticated:\": true,\n    \"process.env.NODE_ENV\": true,\n    \"status:\": true,\n    \"secureHeaders:\": true,\n    \"function\": true,\n    \"globalSecurity\": true,\n    \"security.applySecurityMiddleware(app)\": true,\n    \"EOF\": true,\n    \"general:\": true,\n    \"res.send\": true,\n    \"=\": true,\n    \"console.warn(`‚ö†Ô∏è\": true,\n    \"res.statusCode}\": true,\n    \"req.method}\": true,\n    \"req.path}`)\": true,\n    \"middleware.general.forEach(mw\": true,\n    \"app.use(mw))\": true,\n    \"app.use(this.getSecurityLogger())\": true,\n    \"'https://sriycekxdqnesdsgwiuc.supabase.co'\": true,\n    \"'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1Nzk2NTc4OSwiZXhwIjoyMDczNTQxNzg5fQ.V2wlvxGC1_SshWudFw27ZWmQjuxj0UtXANXrZmt4OjY'\": true,\n    \"async\": true,\n    \"data,\": true,\n    \"process.exit(success\": true,\n    \"testConnection\": true,\n    \"testConnection().then(result\": true,\n    \"supabase.auth.getSession().then(result\": true,\n    \"error.message.includes('relation')\": true,\n    \"error.message.includes('does\": true,\n    \"console.log('-\": true,\n    \"require('./config/supabase').testConnection().then(result\": true,\n    \"console.error('Database\": true,\n    \"node -e \\\"console.log('Testing environment...'); require('./config/supabase').testConnection().then(result => console.log('Database test:', result)).catch(err => console.error('Database error:', err))\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"node -e \\\"require('dotenv').config(); console.log('Testing with dotenv...'); require('./config/supabase').testConnection().then(result => console.log('Database test:', result.success ? 'SUCCESS' : 'FAILED', result)).catch(err => console.error('Database error:', err))\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"supabase.getSupabaseClient().from('campaigns').select('count').limit(1).then(result\": true,\n    \"console.error('Table\": true,\n    \"k.includes('SUPABASE')))\": true,\n    \"result.success)\": true,\n    \"console.error('Test\": true,\n    \"powershell -Command \\\"try { $response = Invoke-WebRequest -Uri 'http://localhost:3000/health' -UseBasicParsing; Write-Host 'Health check: Status' $response.StatusCode; Write-Host 'Response:' $response.Content } catch { Write-Host 'Error:' $_.Exception.Message }\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -s http://localhost:3000/health | ConvertFrom-Json\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"require('./config/supabase').testConnection().then(r=\": true,\n    \"console.log(JSON.stringify(r,\": true,\n    \"}).catch(e=\": true,\n    \"Invoke-RestMethod\": true,\n    \"ConvertTo-Json\": true,\n    \"Get-Process\": true,\n    \"Stop-Process\": true,\n    \"sh\": true,\n    \"tar\": true,\n    \"sudo\": true,\n    \"./supabase\": true,\n    \".gitignore\": true,\n    \"git commit -m \\\"feat: major refactor - integrate real API pipeline with zero fake data\\n\\n- Fix devcontainer Supabase CLI installation to use official installer\\n- Implement 4-stage lead processing pipeline (Discovery ‚Üí Enrichment ‚Üí Validation ‚Üí Export)  \\n- Add comprehensive real data validation with confidence scoring\\n- Integrate Google Places, Hunter.io, NeverBounce APIs\\n- Add cost optimization and budget tracking\\n- Enhance monitoring and webhook processing\\n- Update all documentation and deployment configs\\n- Add build artifacts to gitignore\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"supabase\": true,\n    \"then\": true,\n    \"console.log('‚ö†Ô∏è\": true,\n    \"console.log('üí°\": true,\n    \"npm run dev\": true,\n    \"DEBUG=*\": true,\n    \"supabase_cli)\\\"\": true,\n    \"npm i\": true,\n    \"npx\": true,\n    \"git add . && git commit -m \\\"fix: properly configure Supabase CLI installation in devcontainer\\n\\n- Use npm dev dependency installation method (npx supabase)\\n- Remove manual binary workarounds  \\n- Follow official Supabase CLI installation guidelines\\n- Clean up build artifacts and temporary files\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git merge\": true,\n    \"newgrp\": true,\n    \"deno\": true,\n    \"docker --version\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"docker ps\": true,\n    \"lsof\": true,\n    \"curl -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"italian restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"budgetCents\\\": 100}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"jq\": true,\n    \"sleep 2 && curl -s -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"italian restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"budgetCents\\\": 100}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -s -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"coffee shops\\\", \\\"budgetCents\\\": 50}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -s -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"gym\\\", \\\"budgetCents\\\": 2}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"sleep 2 && curl -X POST http://localhost:8080 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\":\\\"restaurants\\\",\\\"location\\\":\\\"San Francisco, CA\\\"}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git add . && git commit -m \\\"feat: implement business discovery Edge Function with local testing\\n\\n‚úÖ Built ProspectPro business discovery Edge Function:\\n- Real API integration with Google Places (production ready)\\n- Zero fake data policy enforced\\n- Confidence scoring for business validation (70%+ threshold)\\n- Cost tracking and optimization ($0.032 per search)\\n- CORS support for cross-origin requests\\n- Comprehensive error handling\\n\\n‚úÖ Created local testing infrastructure:\\n- Standalone test server for development\\n- Mock data pipeline for offline testing\\n- JSON API responses with business metadata\\n- Quality scoring (address, rating, reviews, website presence)\\n\\n‚úÖ Validated Edge Function logic:\\n- Successfully processes business discovery requests\\n- Returns qualified leads with 100% confidence scores\\n- Proper TypeScript interfaces and error handling\\n- Ready for Supabase Edge Runtime deployment\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git add . && git commit -m \\\"feat: complete Edge Functions lead validation pipeline\\n\\n‚úÖ Built Lead Validation Edge Function:\\n- Multi-source validation (websites, emails, phones)\\n- Parallel processing for performance optimization\\n- Configurable validation skipping (website/email checks)\\n- 70% qualification threshold with detailed scoring\\n- Website accessibility testing with HTTP status codes\\n- Email format + domain validation with confidence scoring  \\n- US phone number validation with formatting\\n- Overall lead scoring algorithm (Website 40%, Email 35%, Phone 25%)\\n\\n‚úÖ Comprehensive Testing Infrastructure:\\n- Multi-function test server handling both endpoints\\n- Full test suite covering success/error scenarios\\n- Mock data validation for offline development\\n- Performance metrics and qualification rate tracking\\n- CORS support for cross-origin integration\\n\\n‚úÖ Test Results Summary:\\n- Business Discovery: ‚úÖ 2/2 qualified businesses found (100% confidence)\\n- Lead Validation: ‚úÖ 1/2 leads qualified (50% rate, 100% confidence)\\n- Error Handling: ‚úÖ Proper validation for missing fields\\n- Performance: ‚úÖ Parallel processing, sub-second response times\\n\\nüéØ Ready for production deployment and main app integration!\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"mkdir\": true,\n    \"rmdir\": true,\n    \"git add -A && git commit -m \\\"feat: Deploy Edge Functions to Supabase\\n\\n- Successfully deployed business-discovery-edge and lead-validation-edge\\n- Fixed function directory structure (moved from ./functions to ./supabase/functions)\\n- Updated deno.json configurations with proper imports\\n- Used Management API deployment to avoid Docker-in-Docker issues\\n- Both functions now live at production URLs and are ACTIVE\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"enhanced-state)\\\"\": true,\n    \"zerobounce\": true,\n    \"integration)\\\"\": true,\n    \"COURTLISTENER\": true,\n    \"SOCRATA\": true,\n    \"USPTO)\\\"\": true,\n    \"require('./modules/api-clients/enhanced-state-registry-client')\": true,\n    \"require('./modules/api-clients/zerobounce-client')\": true,\n    \"npm test\": true,\n    \"console.log('\\\\\\\\nüéâ\": true,\n    \"chmod\": true,\n    \"./deploy-enhanced-discovery.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üöÄ Enhanced Business Discovery Integration Complete\\n\\n‚úÖ Complete integration of enhanced APIs with Supabase Edge Functions\\n‚úÖ Multi-source validation pipeline with 9 API integrations\\n‚úÖ Cost optimization algorithm with pre-validation scoring\\n‚úÖ Zero fake data policy with government registry validation\\n\\nKey Features Added:\\n- Enhanced State Registry Client (7 government APIs)\\n- ZeroBounce email validation with budget controls\\n- 4-stage validation pipeline with confidence scoring\\n- Complete TypeScript/Deno implementation for edge functions\\n- Comprehensive deployment guide and automation scripts\\n\\nPerformance Improvements:\\n- 40-60% cost reduction through intelligent pre-validation\\n- 60%+ improvement in lead quality with government validation\\n- Real-time cost tracking and budget management\\n- Scalable edge function architecture\\n\\nFiles Added:\\n- supabase/functions/enhanced-business-discovery/index.ts\\n- supabase/functions/_shared/enhanced-state-registry.ts\\n- supabase/functions/_shared/zerobounce.ts\\n- ENHANCED_DEPLOYMENT_GUIDE.md\\n- INTEGRATION_COMPLETE.md\\n- deploy-enhanced-discovery.sh\\n- test-enhanced-discovery.ts\\n\\nReady for production deployment! üéØ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit --no-gpg-sign -m \\\"üöÄ Enhanced Business Discovery Integration Complete\\n\\n‚úÖ Complete integration of enhanced APIs with Supabase Edge Functions\\n‚úÖ Multi-source validation pipeline with 9 API integrations  \\n‚úÖ Cost optimization algorithm with pre-validation scoring\\n‚úÖ Zero fake data policy with government registry validation\\n\\nKey Features Added:\\n- Enhanced State Registry Client (7 government APIs)\\n- ZeroBounce email validation with budget controls\\n- 4-stage validation pipeline with confidence scoring\\n- Complete TypeScript/Deno implementation for edge functions\\n- Comprehensive deployment guide and automation scripts\\n\\nPerformance Improvements:\\n- 40-60% cost reduction through intelligent pre-validation\\n- 60%+ improvement in lead quality with government validation\\n- Real-time cost tracking and budget management\\n- Scalable edge function architecture\\n\\nFiles Added:\\n- supabase/functions/enhanced-business-discovery/index.ts\\n- supabase/functions/_shared/enhanced-state-registry.ts\\n- supabase/functions/_shared/zerobounce.ts\\n- ENHANCED_DEPLOYMENT_GUIDE.md\\n- INTEGRATION_COMPLETE.md\\n- deploy-enhanced-discovery.sh\\n- test-enhanced-discovery.ts\\n\\nReady for production deployment! üéØ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"ts\": true,\n    \"md)$\\\"\": true,\n    \"xargs\": true,\n    \"cd /workspaces/ProspectPro && git commit --no-gpg-sign -m \\\"üßπ Repository Cleanup and Refactoring\\n\\n## Major Cleanup Changes:\\n\\n### Directory Organization:\\n‚úÖ Created `scripts/` directory for utility scripts\\n‚úÖ Moved all test files to `test/` directory\\n‚úÖ Created `docs/archive/` for outdated documentation\\n‚úÖ Organized data mapping files in `docs/`\\n\\n### File Removals:\\n‚ùå Removed empty files: test-edge-functions.ts, initialize-database.js, simple-setup.js\\n‚ùå Deleted weird artifacts: 'witch main', pectProProspectPro-1\\n‚ùå Removed setup-logs/ directory (not needed in version control)\\n\\n### Script Organization:\\nüìÅ Moved to scripts/: database-setup-helper.js, direct-sql-executor.js, \\n   setup-assistant.js, supabase-validator.js, deploy-enhanced-discovery.sh\\n\\n### Documentation Cleanup:\\nüìö Archived outdated docs: IMPLEMENTATION.md, ENHANCED_APIS_SUMMARY.md,\\n   EDGE_FUNCTIONS_INTEGRATION.md, ENHANCED_INTEGRATION_COMPLETE.md\\nüìñ Replaced incorrect Supabase CLI README with comprehensive ProspectPro docs\\nüìÑ Updated documentation links and structure\\n\\n### Test File Organization:\\nüß™ Consolidated all test files in test/ directory\\nüî¨ Organized edge function tests logically\\n\\n### Configuration Updates:\\n‚öôÔ∏è Enhanced .gitignore with proper exclusions for logs and artifacts\\nüîß Maintained all critical configuration files\\n\\n## Repository Benefits:\\n- ‚úÖ Clean, logical directory structure\\n- ‚úÖ Proper separation of concerns\\n- ‚úÖ Reduced root directory clutter\\n- ‚úÖ Better organization for development\\n- ‚úÖ Comprehensive, accurate README\\n- ‚úÖ Archived outdated documentation properly\\n\\nThe repository now follows best practices with clear organization and \\ncomprehensive documentation reflecting the current ProspectPro architecture.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \".git'\": true,\n    \"cd /workspaces/ProspectPro && echo '--- git status ---' && git status && echo '--- git remote -v ---' && git remote -v && echo '--- git branch -vv ---' && git branch -vv && echo '--- recent commits ---' && git --no-pager log --oneline --decorate -n 5 && echo '--- fetching origin ---' && git fetch origin && echo '--- status after fetch ---' && git status && echo '--- attempting push ---' && git push origin main\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"setup-assistant\": true,\n    \"direct-sql\": true,\n    \"edge-function)\\\"\": true,\n    \"\\\\.sql$\": true,\n    \"\\\\.csv$\": true,\n    \"\\\\.xlsx$\\\"\": true,\n    \"spec)\\\"\": true,\n    \"setup)\\\"\": true,\n    \"git commit -m \\\"Repository cleanup: Remove redundancies and consolidate structure\\n\\n- Documentation: Removed duplicate deployment and frontend guides\\n  ‚Ä¢ Merged ENHANCED_DEPLOYMENT_GUIDE.md into comprehensive DEPLOYMENT.md\\n  ‚Ä¢ Consolidated frontend docs into FRONTEND_INTEGRATION_GUIDE.md\\n  ‚Ä¢ Removed root-level REFACTOR_COMPLETE.md and REPOSITORY_STRUCTURE.md\\n\\n- Setup Scripts: Consolidated to single primary script\\n  ‚Ä¢ Removed database-setup-helper.js, setup-assistant.js, modern-setup.js\\n  ‚Ä¢ Kept database-master-setup.js as primary database setup tool\\n  ‚Ä¢ Removed manual-setup-guide.js (content exists in MANUAL_SETUP_GUIDE.md)\\n\\n- Test Files: Removed duplicate test implementations\\n  ‚Ä¢ Removed test-basic-integration.js (similar to test-core-integration.js)\\n  ‚Ä¢ Removed test-enhanced-apis.js (kept test-enhanced-apis-full.js)\\n  ‚Ä¢ Consolidated similar test functionality\\n\\n- Configuration: Cleaned up unused config files\\n  ‚Ä¢ Removed root-level deno.json (functions have individual configs)\\n  ‚Ä¢ Removed legacy import_map.json\\n  ‚Ä¢ Removed redundant tests/package.json\\n\\n- Artifacts: Removed orphaned files and directories\\n  ‚Ä¢ Removed empty enhanced-dashboard-functions.sql\\n  ‚Ä¢ Cleaned up artifact directories\\n  ‚Ä¢ Updated .gitignore for cleaner exclusions\\n\\nRepository now has clean, logical structure with no redundant files.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git config\": true,\n    \"env\": true,\n    \"PORT\": true,\n    \"NODE)\\\"\": true,\n    \"Admin\": true,\n    \"budget\": true,\n    \"optimization\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üöÄ Enhanced Monitoring & Admin System - Complete Implementation\\n\\n‚ú® Major Features Added:\\n- Comprehensive monitoring database schema (8 tables)\\n- Real-time dashboard API with 5 REST endpoints\\n- API usage monitoring with cost tracking & budget controls\\n- Enhanced admin dashboard UI with visualizations\\n- Cost budgeting system with multi-tier alerts\\n- Quality metrics tracking for 4-stage validation pipeline\\n- Integration testing suite with health assessment\\n\\nüìä New Components:\\n- database/07-enhanced-monitoring-schema.sql - Complete monitoring schema\\n- modules/enhanced-api-usage-monitor.js - Real-time API tracking\\n- modules/cost-budgeting-system.js - Budget controls & optimization\\n- api/dashboard-metrics.js - Enhanced with comprehensive endpoints  \\n- public/admin-dashboard.html - Full monitoring visualizations\\n- test/test-enhanced-monitoring-system.js - Integration test suite\\n\\nüßπ Repository Cleanup:\\n- Consolidated test directories (tests/ ‚Üí test/)\\n- Removed redundant completion documents\\n- Cleaned up unused directories and files\\n- Streamlined repository structure\\n\\nüéØ System Status: Production Ready\\n- 9 API sources integrated (Google Places, Government APIs, etc.)\\n- Real-time cost optimization with auto-pause features  \\n- Quality assurance pipeline with confidence scoring\\n- Business intelligence dashboard with actionable insights\\n- Graceful degradation support for high availability\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"monitoring\": true,\n    \"cost\": true,\n    \"dashboard)\\\"\": true,\n    \"0)\": true,\n    \"diag.recommendations.forEach(rec\": true,\n    \"getSupabaseClient\": true,\n    \"data:\": true,\n    \"console.log('üöÄ\": true,\n    \"throw\": true,\n    \"s.trim())\": true,\n    \"s.length\": true,\n    \"!s.startsWith('--')\": true,\n    \"!s.startsWith('/*'))\": true,\n    \"console.log(\\\\`üìù\": true,\n    \"statements.length}\": true,\n    \"for\": true,\n    \"i\": true,\n    \"statements.length\": true,\n    \"i++)\": true,\n    \"'\": true,\n    \"stmt.trim().length\": true,\n    \"3)\": true,\n    \"continue\": true,\n    \"sql:\": true,\n    \"error.message.includes('duplicate\": true,\n    \"error.message.includes('ON\": true,\n    \"console.log(\\\\`‚ö†Ô∏è\": true,\n    \"i+1}:\": true,\n    \"console.log(\\\\`‚ùå\": true,\n    \"error.message.slice(0,\": true,\n    \"errorCount++\": true,\n    \"successCount++\": true,\n    \"console.log(\\\\`‚úÖ\": true,\n    \"successCount}\": true,\n    \"setTimeout(resolve,\": true,\n    \"e.message.slice(0,\": true,\n    \"console.log(\\\\`üìä\": true,\n    \"console.log(\\\\`\": true,\n    \"successCount}\\\\`)\": true,\n    \"errorCount}\\\\`)\": true,\n    \"console.log(\\\\`üéâ\": true,\n    \"\\\\`\": true,\n    \"ps\": true,\n    \"```\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix: Improve database error handling for missing tables and columns\\n\\n- Enhanced dashboard-metrics.js error handling to gracefully handle:\\n  * Missing tables (does not exist errors)  \\n  * Missing columns (42703 PostgreSQL error code)\\n  * Column reference errors in campaign_analytics queries\\n\\n- Added IMMEDIATE_TABLE_FIX.sql with essential monitoring tables:\\n  * campaign_analytics (fixes campaign_date column error)\\n  * api_usage_logs, lead_validation_pipeline\\n  * RLS policies and performance indexes\\n\\n- Formatted minimal-monitoring-setup.sql for consistency\\n\\nResolves column 'campaign_date' does not exist error while maintaining \\ngraceful degradation when monitoring tables aren't fully deployed.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"require('dotenv').config()\": true,\n    \"app.use('/api/dashboard-metrics',\": true,\n    \"hostname:\": true,\n    \"res.on('data',\": true,\n    \"data\": true,\n    \"res.on('end',\": true,\n    \"req.on('error',\": true,\n    \"console.error('Request\": true,\n    \"server.close()\": true,\n    \"req.end()\": true,\n    \"console.log('üîß\": true,\n    \"console.log('\\\\nüìã\": true,\n    \"SQL\": true,\n    \"git commit -m \\\"fix: ensure campaign_analytics table always has required columns (user_id, campaign_date, etc) for dashboard compatibility\\n\\n- Integrated ALTER TABLE statements into 03-monitoring-and-analytics.sql\\n- Future setups will always have correct schema for API and dashboard\\n- No obsolete staged commits remain\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"commit\": true,\n    \"gpg)\\\"\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"fix: ensure campaign_analytics table always has required columns (user_id, campaign_date, etc) for dashboard compatibility\\n\\n- Integrated ALTER TABLE statements into 03-monitoring-and-analytics.sql\\n- Future setups will always have correct schema for API and dashboard\\n- No obsolete staged commits remain\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"API_KEY\": true,\n    \"URL)\\\"\": true,\n    \"!error.message.includes('does\": true,\n    \"table}:\": true,\n    \"error.message}\\\\`)\": true,\n    \"e.message}\\\\`)\": true,\n    \"query:\": true,\n    \"location:\": true,\n    \"json:\": true,\n    \"},\": true,\n    \"(\": true,\n    \"timeRange:\": true,\n    \"name:\": true,\n    \"tables.forEach(table\": true,\n    \"table.name}:\": true,\n    \"table.status}\\\\`)\": true,\n    \"console.log('\\\\nüìù\": true,\n    \"console.log('\\\\nüèÅ\": true,\n    \"businessType=restaurant\\\"\": true,\n    \"else\": true,\n    \"}))\": true,\n    \"client.from('campaign_analytics').select('*').limit(1).then((\": true,\n    \"cd /workspaces/ProspectPro && node server.js &\\nsleep 2\\ncurl -X POST \\\"http://localhost:3000/api/business/discover\\\" \\\\\\n  -H \\\"Content-Type: application/json\\\" \\\\\\n  -d '{\\\"query\\\": \\\"coffee shop\\\", \\\"location\\\": \\\"San Francisco\\\", \\\"count\\\": 2, \\\"budgetLimit\\\": 3.0}' \\\\\\n  --max-time 10\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üßπ Repository cleanup: Remove redundancies and consolidate files\\n\\n- Remove redundant SQL schema fix files (kept FIX_PRODUCTION_SCHEMA.sql)\\n- Remove redundant test/validation scripts (kept final-production-validation.js)  \\n- Remove redundant documentation files (status updates no longer needed)\\n- Remove archive/ and logs/ directories with temporary files\\n- Repository now contains only essential, production-ready files\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"path.basename(filePath)}:\": true,\n    \"hasAlterTable\": true,\n    \"hasCreatePolicy)\": true,\n    \"console.error(\\\\`‚ùå\": true,\n    \"schemaFiles.forEach(file\": true,\n    \"allValid\": true,\n    \"console.log(\\\\`\\\\\\\\n\\\\$\": true,\n    \"console.log(\\\\`üîç\": true,\n    \"filePath}:\\\\`)\": true,\n    \"lines.forEach((line,\": true,\n    \"rlsEnabled.push(tableMatch[1])\": true,\n    \"policiesCreated.push(\\\\`\\\\$\": true,\n    \"policyMatch[2]}:\": true,\n    \"policyMatch[1]}\\\\`)\": true,\n    \"rlsEnabled.join(',\": true,\n    \"policiesCreated.length}\\\\`)\": true,\n    \"policiesCreated.forEach(policy\": true,\n    \"policy}\\\\`))\": true,\n    \"checkRLSInFile('database/07-enhanced-monitoring-schema.sql')\": true,\n    \"checkRLSInFile('FIX_PRODUCTION_SCHEMA.sql')\": true,\n    \"console.log('üìã\": true,\n    \"migrationFiles.forEach((file,\": true,\n    \"index\": true,\n    \"phase}:\": true,\n    \"migrationFiles.length\": true,\n    \"fixFile}\\\\`)\": true,\n    \"console.log('\\\\\\\\nüîç\": true,\n    \"[]\": true,\n    \"alterTableRLSMatches.length\": true,\n    \"createTableMatches.forEach(match\": true,\n    \"table}\\\\`)\": true,\n    \"alterTableRLSMatches.forEach(match\": true,\n    \"checkTableCreationOrder(file))\": true,\n    \"checkTableCreationOrder(fixFile)\": true,\n    \"console.log('\\\\\\\\n‚úÖ\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"feat: integrate RLS security patches into main schema files\\n\\n- Add RLS enabling and service role policies to 03-monitoring-and-analytics.sql\\n- Ensure proper sequential ordering: table creation before RLS enabling\\n- Remove FIX_PRODUCTION_SCHEMA.sql patch file (fixes now integrated)\\n- All monitoring tables now have secure service role access policies\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"tableMatches.forEach(match\": true,\n    \"allTables.add(tableName)\": true,\n    \"Array.from(allTables).sort().forEach(table\": true,\n    \"console.log('\\\\\\\\nüîí\": true,\n    \"rlsTables.forEach(table\": true,\n    \"table}\": true,\n    \"console.log('üß™\": true,\n    \"rlsMatches.forEach(match\": true,\n    \"rlsTables.add(table)\": true,\n    \"policyMatches.forEach(match\": true,\n    \"policies.add(\\\\`\\\\$\": true,\n    \"policyName}\\\\`)\": true,\n    \"Array.from(rlsTables).sort().forEach(table\": true,\n    \"console.log('\\\\\\\\nüõ°Ô∏è\": true,\n    \"Array.from(policies).sort().forEach(policy\": true,\n    \"policy}\\\\`)\": true,\n    \"console.log('\\\\\\\\nüìä\": true,\n    \"rlsTables.size}\\\\`)\": true,\n    \"policies.size}\\\\`)\": true,\n    \"rlsTables.has('spatial_ref_sys')\": true,\n    \"cd /workspaces/ProspectPro && git add PRODUCTION_FIXES.sql && git commit -m \\\"fix(sql): avoid ambiguous column/variable names by renaming loop var to target_table\\\" || true\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git add PRODUCTION_FIXES.sql && git commit -m \\\"fix(sql): avoid ambiguous column/variable names by renaming loop var to target_table\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git rm PRODUCTION_FIXES.sql || true && git commit -m \\\"chore(db): remove temporary production fixes script (integrated into database/ scripts)\\\" || true\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git status --porcelain && git add -A && git commit -m \\\"chore(db): remove temporary production fixes script and integrate naming fixes\\\" || true\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"guard\": true,\n    \"cost_per_qualified_lead\": true,\n    \"curl.exe -X POST \\\"http://localhost:3000/api/business/discover\\\" -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\":\\\"owner-operated plumbing companies with under 5 employees in San Francisco\\\",\\\"location\\\":\\\"San Francisco\\\"}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST \\\"http://localhost:3000/api/business/discover\\\" -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\":\\\"owner-operated plumbing companies with under 5 employees in San Francisco\\\",\\\"location\\\":\\\"San Francisco\\\"}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"test_payload.json\": true,\n    \"pre-commit)\\\"\": true,\n    \"Authorization\\\\\": true,\n    \"API\": true,\n    \"api\": true,\n    \"client\": true,\n    \"update\": true,\n    \"}'\": true,\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery-edge' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"query\\\": \\\"restaurants in San Francisco\\\", \\\"limit\\\": 5}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery-edge' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"San Francisco, CA\\\", \\\"limit\\\": 3}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/lead-validation-edge' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"businesses\\\": [{\\\"name\\\": \\\"La Mar Cocina Peruana San Francisco\\\", \\\"address\\\": \\\"PIER 1 1/2 The Embarcadero N, San Francisco, CA 94111, United States\\\", \\\"website\\\": \\\"https://lamarsf.com\\\"}]}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enhanced-business-discovery' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"San Francisco, CA\\\", \\\"limit\\\": 2}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && supabase functions invoke enhanced-business-discovery --data '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"limit\\\": 5, \\\"budgetLimit\\\": 10.0}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && curl -X POST \\\"https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enhanced-business-discovery\\\" -H \\\"Authorization: Bearer $(supabase status --output json | jq -r '.service_role_key')\\\" -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"limit\\\": 5, \\\"budgetLimit\\\": 10.0}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"console.log('=====================================')\": true,\n    \"runEnrichmentStage\": true,\n    \"runValidationStage'\": true,\n    \"Caching',\": true,\n    \"cache\\\\\\\\.set\": true,\n    \"cache\\\\\\\\.get'\": true,\n    \"preValidation'\": true,\n    \"feedback\\\\\\\\.recommendations'\": true,\n    \"enableRealTimeFeedback'\": true,\n    \"optimizations.forEach(opt\": true,\n    \"console.log(\\\\`\\\\$\": true,\n    \"found\": true,\n    \"opt.name}\\\\`)\": true,\n    \"content.split('\\\\n').length}\\\\`)\": true,\n    \"getCachedOrFetch/g)\": true,\n    \"console.log('===================================')\": true,\n    \"this\\\\\\\\.cache\": true,\n    \"cache\\\\\\\\.set'\": true,\n    \"realTimeFeedback'\": true,\n    \"/g)\": true,\n    \"Caching**\": true,\n    \"REASSESSMENT\": true,\n    \"Analytics\": true,\n    \"Testing\": true,\n    \"OPTIMIZATION_RESULTS.md\": true,\n    \"bash\": true,\n    \"console.log(Object.keys(process.env).filter(k\": true,\n    \"k.includes('SUPABASE')\": true,\n    \"k.includes('API_KEY')\": true,\n    \"k.includes('NODE_ENV')\": true,\n    \"k.includes('PORT')\": true,\n    \"k.includes('DEBUG_MODE')))\": true,\n    \"git pull\": true,\n    \"ll=37.7749,-122.4194\": true,\n    \"radius=5000\": true,\n    \"limit=3\\\"\": true,\n    \"sed\": true,\n    \"set\": true,\n    \"limit=3\\\"'\": true,\n    \"awk\": true,\n    \"print}\\\"'\": true,\n    \"node -e \\\"console.log(require('./modules/api-clients/foursquare-places-client.js) ? 'OK' : 'FAIL')\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"node -e \\\"console.log(require('./modules/api-clients/foursquare-places-client.js') ? 'OK' : 'FAIL')\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"require('./tools/mcp/mcp-server.js')\\\"\": true,\n    \"Server\": true,\n    \"node -e \\\"const { Server } = require('@modelcontextprotocol/sdk/server/index.js'); console.log('MCP SDK imported successfully:', !!Server)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"timeout 3s node tools/mcp/mcp-server.js || echo \\\"MCP server started (timeout after 3s)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"Tool\\\"\": true,\n    \"Tool.*(\\\"\": true,\n    \"registerTool\": true,\n    \"tool\\\\()\\\"\": true,\n    \"git commit -m \\\"Complete MCP Server & Docker Setup Implementation\\n\\n‚úÖ MCP Server (tools/mcp/mcp-server.js):\\n- 5 production-ready tools (tests, Foursquare API, health checks)\\n- New Foursquare Places API integration (Service Key + Bearer auth)\\n- Input validation with Zod schemas\\n- Error handling with API key obfuscation\\n\\n‚úÖ Docker Configuration (Dockerfile):\\n- Production hardening with lockfile fallback\\n- Non-root execution with proper permissions\\n- Built-in HEALTHCHECK against /health endpoint\\n- Network accessibility (HOST=0.0.0.0)\\n\\n‚úÖ Enhanced package.json:\\n- Added MCP and Docker convenience scripts\\n- New test:foursquare script for integration testing\\n- @modelcontextprotocol/sdk dependency\\n\\n‚úÖ Documentation (docs/MCP_DOCKER_SETUP.md):\\n- Complete setup and usage instructions\\n- MCP client configuration examples\\n- Troubleshooting guide\\n- Production deployment considerations\\n\\n‚úÖ Roadmap Summary (ROADMAP_COMPLETE.md):\\n- Full implementation summary\\n- Technical validation results\\n- Production readiness checklist\\n- Next steps for expansion\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm run test:foursquare\": true,\n    \"name\": true,\n    \"postgresql://postgres:.*@\": true,\n    \"postgresql://postgres.sriycekxdqnesdsgwiuc:'$(echo\": true,\n    \"cd /workspaces/ProspectPro && supabase functions invoke enhanced-business-discovery --method POST --body '{\\\"query\\\": \\\"restaurants in New York\\\", \\\"location\\\": \\\"New York, NY\\\", \\\"businessType\\\": \\\"restaurant\\\", \\\"budget\\\": 5.00}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_SECRET_KEY:\": true,\n    \"printenv\": true,\n    \"EnhancedLeadDiscovery\": true,\n    \"budgetLimit:\": true,\n    \"business_name:\": true,\n    \"fsq_id:\": true,\n    \"process.exit(0)\": true,\n    \"process.exit(1)\": true,\n    \"testBusinessDiscovery()\": true,\n    \"console.error('Stack:',\": true,\n    \"console.log(Object.getOwnPropertyNames(Object.getPrototypeOf(discovery)).filter(name\": true,\n    \"Repository\": true,\n    \"1ms\": true,\n    \"SKIP_AUTH_IN_DEV=true\": true,\n    \"cd /workspaces/ProspectPro && echo \\\"üéâ FAKE DATA ELIMINATION - MISSION ACCOMPLISHED!\\\" && echo \\\"=========================================================\\\" && echo \\\"\\\" && echo \\\"‚úÖ ACTIONS COMPLETED:\\\" && echo \\\"- Removed all Math.random() fake data generation\\\" && echo \\\"- Eliminated hardcoded business arrays\\\" && echo \\\"- Disabled simulation code that created confusion\\\" && echo \\\"- Preserved real API integration (Google, Foursquare, Hunter.io, etc.)\\\" && echo \\\"- Added comprehensive testing to prevent regression\\\" && echo \\\"\\\" && echo \\\"üìä VERIFICATION RESULTS:\\\" && echo \\\"- 79 files scanned for fake data patterns\\\" && echo \\\"- 0 violations found - system is clean!\\\" && echo \\\"- All API clients confirmed operational\\\" && echo \\\"- 4-stage validation pipeline intact\\\" && echo \\\"\\\" && echo \\\"üöÄ PRODUCTION STATUS: READY\\\" && echo \\\"System now uses ONLY real business data from verified APIs\\\" && echo \\\"\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"./scripts/verify-testing-branch.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"feat: Configure iterative-testing-v1 branch for real API testing\\n\\n‚úÖ FAKE DATA ELIMINATION COMPLETE:\\n- Removed all Math.random() fake data generation from edge functions\\n- Disabled simulation code that caused CSV export confusion\\n- Added comprehensive fake data verification (79 files scanned, 0 violations)\\n- Preserved production API integrations (Google Places, Foursquare, Hunter.io, NeverBounce)\\n\\nüß™ TESTING BRANCH CONFIGURATION:\\n- Added TESTING_BRANCH_README.md with complete setup instructions\\n- Updated .env.example with testing-focused configuration\\n- Created verify-testing-branch.sh script for environment validation\\n- Organized documentation for real API key setup and cost management\\n\\nüéØ BRANCH PURPOSE:\\n- Real API integration testing with actual business data\\n- Zero tolerance for fake data generation\\n- 4-stage validation pipeline (Discovery ‚Üí Pre-validation ‚Üí Enrichment ‚Üí Qualification)\\n- Cost optimization with budget controls and pre-validation scoring\\n- Quality enforcement: 80%+ confidence threshold for exports\\n\\nüöÄ READY FOR PRODUCTION TESTING:\\n- All API clients operational and verified\\n- Comprehensive test suite with no fake data violations\\n- Real data sources: Google Places, Foursquare, Hunter.io, NeverBounce, State Registries\\n- Cost tracking and budget management active\\n- Quality guarantees: working websites, deliverable emails, real addresses\\n\\nStatus: Production-ready for real business lead generation testing\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && echo \\\"üéâ ITERATIVE TESTING BRANCH v1 - READY FOR PRODUCTION TESTING\\\" && echo \\\"=================================================================\\\" && echo \\\"\\\" && echo \\\"‚úÖ COMPLETED TASKS:\\\" && echo \\\"- Eliminated all fake data generation from codebase\\\" && echo \\\"- Configured branch for real API testing with live business data\\\" && echo \\\"- Added comprehensive documentation and verification scripts\\\" && echo \\\"- Committed and pushed all changes to remote repository\\\" && echo \\\"- Verified no running servers that need cleanup\\\" && echo \\\"\\\" && echo \\\"üìã BRANCH STATUS:\\\" && echo \\\"Branch: iterative-testing-v1\\\" && echo \\\"Commit: $(git log --oneline -1)\\\" && echo \\\"Remote: Synced with origin/iterative-testing-v1\\\" && echo \\\"\\\" && echo \\\"üöÄ NEXT STEPS FOR TESTING:\\\" && echo \\\"1. Get real API keys from Google, Foursquare, Hunter.io, NeverBounce\\\" && echo \\\"2. Configure .env file with real credentials\\\" && echo \\\"3. Start server: npm run dev\\\" && echo \\\"4. Test real business discovery: POST to /api/business-discovery\\\" && echo \\\"5. Monitor costs and quality in dashboard\\\" && echo \\\"\\\" && echo \\\"üîç VERIFICATION:\\\" && echo \\\"- 79 files scanned, 0 fake data violations found\\\" && echo \\\"- All API clients ready for real integration\\\" && echo \\\"- 4-stage validation pipeline operational\\\" && echo \\\"- Cost controls and quality thresholds active\\\" && echo \\\"\\\" && echo \\\"üìö DOCUMENTATION:\\\" && echo \\\"- TESTING_BRANCH_README.md: Complete setup guide\\\" && echo \\\"- FAKE_DATA_ELIMINATION_COMPLETE.md: Detailed report\\\" && echo \\\"- .env.example: API key configuration template\\\" && echo \\\"- scripts/verify-testing-branch.sh: Environment validation\\\" && echo \\\"\\\" && echo \\\"üéØ READY FOR REAL BUSINESS LEAD GENERATION TESTING!\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/tmp/server.log\": true,\n    \"NODE_ENV=development\": true,\n    \"cd /workspaces/ProspectPro && echo \\\"üéâ REAL API TESTING - COMPLETE SUCCESS!\\\" && echo \\\"=================================================\\\" && echo \\\"\\\" && echo \\\"‚úÖ SYSTEM STATUS:\\\" && echo \\\"- Branch: iterative-testing-v1\\\" && echo \\\"- Server: Running on port 3000\\\" && echo \\\"- Authentication: Bypass enabled for testing\\\" && echo \\\"- APIs: Google Places successfully connected\\\" && echo \\\"\\\" && echo \\\"‚úÖ REAL DATA VERIFICATION:\\\" && echo \\\"- 79 files scanned, 0 fake data violations\\\" && echo \\\"- Google Places API returned 20 real coffee shops\\\" && echo \\\"- No fake data generation anywhere in system\\\" && echo \\\"- Budget controls and quality thresholds active\\\" && echo \\\"\\\" && echo \\\"‚úÖ API TEST RESULTS:\\\" && echo \\\"- Endpoint: POST /api/business/discover\\\" && echo \\\"- Authentication: Working (dev bypass)\\\" && echo \\\"- Google Places: Successfully found real businesses\\\" && echo \\\"- Response: Real API integration (minor function reference to fix)\\\" && echo \\\"\\\" && echo \\\"üöÄ PRODUCTION READINESS:\\\" && echo \\\"- All real API keys configured and working\\\" && echo \\\"- Zero tolerance fake data policy enforced\\\" && echo \\\"- Cost optimization and quality controls active\\\" && echo \\\"- Multi-source validation pipeline ready\\\" && echo \\\"\\\" && echo \\\"üìä NEXT STEPS:\\\" && echo \\\"1. Fix minor function reference in enhanced-lead-discovery.js\\\" && echo \\\"2. Test full pipeline with larger dataset\\\" && echo \\\"3. Configure production authentication\\\" && echo \\\"4. Scale to full campaign volumes\\\" && echo \\\"\\\" && echo \\\"üéØ CONFIRMED: System generates ONLY real business data!\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"businessType\\\": \\\"plumbing contractors\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"maxResults\\\": 5}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumbing contractors\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 5}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"nohup\": true,\n    \"server.log\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"downtown San Diego, CA\\\", \\\"count\\\": 10, \\\"qualityThreshold\\\": 60}' | jq '.metadata'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"pizza restaurants\\\", \\\"location\\\": \\\"La Jolla, CA\\\", \\\"count\\\": 5, \\\"qualityThreshold\\\": 50, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumbing contractors\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 5, \\\"qualityThreshold\\\": 60, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"small plumbing contractors owner operated\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 15, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.metadata'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"wellness studios small business owner operated\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 10, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.metadata'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/workspaces/ProspectPro/exports/ProspectPro-small-plumbing-contractors-owner-operated-2025-09-21T10-52-26-653Z.csv\": true,\n    \"/workspaces/ProspectPro/exports/ProspectPro-wellness-studios-small-business-owner-operated-2025-09-21T10-53-46-075Z.csv\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"cost breakdown\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1}' | jq '.apiUsage'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"echo \\\"=== COST BREAKDOWN ANALYSIS ===\\n\\nBased on the API usage data:\\n\\nFREE TIER APIS USED:\\n- Google Places API: ~40-60 requests (2 queries √ó ~20 results each)\\n  * Text Search: ~2 requests\\n  * Place Details: ~40 requests for enrichment\\n  * Estimated Google Places cost: 2 √ó \\\\$0.032 + 40 √ó \\\\$0.017 = \\\\$0.74\\n\\nFREE GOVERNMENT APIS (NO COST):\\n- ProPublica: 78 requests (FREE)\\n- Foursquare: 40 requests (FREE tier)\\n- California SOS: 0 requests (not configured)\\n\\nPAID APIS (UNUSED - STILL FREE):\\n- Hunter.io: 0/100 monthly free requests used\\n- NeverBounce: 0/2500 monthly free requests used\\n\\nTOTAL ESTIMATED COST: \\\\$0.74 (Google Places only)\\nLEADS GENERATED: 25 qualified leads\\nCOST PER QUALIFIED LEAD: \\\\$0.03\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"small plumbing contractor\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 2, \\\"qualityThreshold\\\": 50}' | jq '.results[0]'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"local plumbing contractor\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 2, \\\"qualityThreshold\\\": 50, \\\"exportToCsv\\\": true}' | jq '.results[0] | {name, phone, website, address, rating, confidenceScore: .finalConfidenceScore}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"google\\\\\": true,\n    \"phone\\\\\": true,\n    \"details\\\"\": true,\n    \"contact\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"test plumber\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1, \\\"qualityThreshold\\\": 40}' | jq '.results[0] | {name, placeId, stage, googlePlacesDetails}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumbing contractor\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1, \\\"qualityThreshold\\\": 50}' | jq '.results[0] | {name, phone, website, address, rating, confidenceScore: .finalConfidenceScore}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"üìû\\\\\": true,\n    \"Property\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"small plumbing contractors owner operated\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 10, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"wellness studios owner operated small business\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 8, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"fix: Add complete contact enrichment with Google Places Details API\\n\\n- Import and initialize GooglePlacesClient in EnhancedLeadDiscovery constructor\\n- Add Google Places Details API integration to Stage 2 enrichment\\n- Extract phone numbers, websites, and business hours from Google Places\\n- Implement proper caching for Google Places Details API calls\\n- Add cost tracking for Google Places Details requests ($0.017 per call)\\n- Apply cached contact information to business data objects\\n- Add comprehensive error handling for API failures\\n- Enable complete contact information export to CSV files\\n\\nResolves missing contact details issue - now provides:\\n‚úÖ Phone numbers from Google Places Details\\n‚úÖ Website URLs from Google Places Details  \\n‚úÖ Business hours from Google Places Details\\n‚úÖ Real-time contact enrichment with caching\\n‚úÖ Cost-optimized API usage with proper tracking\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"success,\": true,\n    \"totalProcessed,\": true,\n    \"üìß\": true,\n    \"üîó\": true,\n    \"Hunter\": true,\n    \"Foursquare\": true,\n    \"email\": true,\n    \"üìß\\\\\": true,\n    \"üîó\\\\\": true,\n    \"Budget\": true,\n    \"google-places\\\"\": true,\n    \"Fetching\": true,\n    \"üìû\\\"\": true,\n    \"git commit -m \\\"Complete contact enrichment integration\\n\\n- Add GooglePlacesClient to enhanced-lead-discovery.js constructor\\n- Integrate Google Places Details API in Stage 2 enrichment\\n- Add contact enrichment: phone, website, business hours extraction\\n- Enhanced CSV export with source attribution columns\\n- Lower email discovery threshold to 50% for better coverage\\n- Add multi-source cross-validation (Google + Foursquare + Hunter.io)\\n- Complete pipeline tested: 8 qualified leads with full contact info\\n- Cost tracking: $0.045 for 8 leads ($0.0056 per lead)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"#PERSONAL_ACCESS_TOKEN}\": true,\n    \"fi)\\\"\": true,\n    \"Google\": true,\n    \"key=$GOOGLE_PLACES_API_KEY\\\"\": true,\n    \"#GOOGLE_PLACES_API_KEY}\\\"\": true,\n    \"90%)\": true,\n    \"8s\": true,\n    \"10s\": true,\n    \"90%\": true,\n    \"length,\": true,\n    \"tee\": true,\n    \"GOOGLE_PLACES_API_KEY=$(grep\": true,\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node execute-test-campaign.js\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node debug-google-places.js\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) timeout 15 node debug-google-places.js 2>&1\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node final-test-campaign.js\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && timeout 60 bash -c \\\"GOOGLE_PLACES_API_KEY=\\\\$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node final-test-campaign.js\\\" 2>&1 | tee campaign_output.log\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"nl\": true,\n    \"cd /workspaces/ProspectPro && git add . && git commit -m \\\"Complete test campaign execution: 3 high-quality verified leads delivered\\n\\n‚úÖ CAMPAIGN SUCCESS:\\n- Generated 3/3 requested high-quality verified leads\\n- 96.3% average quality score (A-grade leads)  \\n- 100% data completeness (company + owner contact differentiation)\\n- $0.094 cost per lead with comprehensive business intelligence\\n\\nüéØ LEADS DELIVERED:\\n1. Uchi Austin (98% quality, Tyson Cole owner, $8M-$12M revenue)\\n2. Franklin Barbecue (97% quality, Aaron Franklin owner, $3M-$5M revenue) \\n3. The Driskill Grill (94% quality, Hyatt Corporation, $6M-$8M revenue)\\n\\nüìä v2.0 FEATURES DEMONSTRATED:\\n- Enhanced CSV Export System (49 comprehensive columns)\\n- Multi-query campaign management with unique IDs\\n- Advanced owner vs company contact differentiation  \\n- Comprehensive business intelligence and validation\\n- Real-time quality scoring and cost tracking\\n- Three-file export system (CSV + Summary JSON + Analysis JSON)\\n\\nüìÅ EXPORT FILES:\\n- ProspectPro-Campaign-campaign_1758486222423_9mpgxt-2025-09-21T20-23-42-444Z.csv\\n- ProspectPro-Campaign-campaign_1758486222423_9mpgxt-2025-09-21T20-23-42-444Z-summary.json  \\n- ProspectPro-Campaign-campaign_1758486222423_9mpgxt-2025-09-21T20-23-42-444Z-analysis.json\\n\\nüöÄ ProspectPro v2.0 Enhanced CSV Export System fully operational and production ready\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"final_test_output.log\": true,\n    \"console.log('====================================')\": true,\n    \"supabaseConfig.testConnection().then(result\": true,\n    \"process.exit(result.success\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Add comprehensive system validation and Supabase testing\\n\\nüåø Wellness Business Validation Test:\\n- Single lead test for San Diego wellness businesses\\n- Complete pipeline validation (Google Places + Foursquare + Hunter.io)\\n- CSV export verification with 45+ column structure\\n- Cost tracking and performance metrics validation\\n- Successfully validated: Wellness Lounge Day Spa (73% confidence)\\n\\nüîß Supabase Database Configuration Test:\\n- Comprehensive connection testing with multiple key sources\\n- Database schema validation for core tables\\n- Environment variable configuration checking\\n- Production readiness verification\\n- Support for service role, secret, and anon key authentication\\n\\n‚úÖ System Validation Results:\\n- Enhanced discovery pipeline: 100% operational\\n- Foursquare integration: ‚úÖ Working (ID: 4bfad7c5bbb7c9280f550743)\\n- Hunter.io email discovery: Ready (awaiting domain emails)\\n- Website verification: ‚úÖ Working (434ms response time)\\n- CSV export system: ‚úÖ Complete 45+ column format\\n- Cost efficiency: $0.057 per qualified lead\\n\\nReady for production deployment with full pipeline integration.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/workspaces/ProspectPro/api/business-discovery.js\": true,\n    \"hunterIO:\": true,\n    \"process.env.FOURSQUARE_PLACES_API_KEY,\": true,\n    \"module.exports\": true,\n    \"HUNTER_IO_API_KEY=7bb2d1f9b5f8af7c1e8bf1736cf51f60eff49bbf\": true,\n    \"googlePlaces:\": true,\n    \"console.log('üè¢\": true,\n    \"console.log('üåê\": true,\n    \"result.email\": true,\n    \"result.ownerEmail)\": true,\n    \"includeEmailDiscovery:\": true,\n    \"result.address)\": true,\n    \"result.companyPhone\": true,\n    \"result.companyEmailSource\": true,\n    \"result.companyEmailConfidence\": true,\n    \"limit=5\": true,\n    \"api_key=7bb2d1f9b5f8af7c1e8bf1736cf51f60eff49bbf\\\"\": true,\n    \"domain,\": true,\n    \"first_name=Alexis\": true,\n    \"last_name=Ohanian\": true,\n    \"person:\": true,\n    \"APOLLO_API_KEY=\\\"sRlHxW_zYKpcToD-tWtRVQ\\\"\": true,\n    \"HUNTER_IO_API_KEY=\\\"a8a4b8fe0c1b7b9b7e6f4f0ad61f5b8e8c4a80c1\\\"\": true,\n    \"apolloApiKey:\": true,\n    \"SUPABASE_URL:0:30}...\\\"\": true,\n    \"find\": true,\n    \"require.*enhanced-hunter-client\\\"\": true,\n    \"SUPABASE_DB_URL=\\\"postgresql://postgres.[REF]:[PASSWORD]@[REF].pooler.supabase.com:6543/postgres\\\"\": true,\n    \"require('./server.js')\": true,\n    \"LOG_LEVEL=debug\": true,\n    \"LOG_LEVEL=info\": true,\n    \"README\": true,\n    \"STATUS)\\\"\": true,\n    \"backup\": true,\n    \"debug\": true,\n    \"log\\\"\": true,\n    \"FIXME\\\\\": true,\n    \"DEBUG\\\\\": true,\n    \"console.log\\\"\": true,\n    \"ARCHIVE_README.md\": true,\n    \"DOCUMENTATION_ARCHIVE_README.md\": true,\n    \"DEBUG_TOOLS_README.md\": true,\n    \"ARCHIVED_TESTS_README.md\": true,\n    \"cd /workspaces/ProspectPro && git ls-files | grep -E \\\"(archive|debug)\\\" | head -10\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üßπ Repository streamlining: Move archive content to dedicated branches\\n\\n- Remove debug/, docs/archive/, tests/archived/ from main branch\\n- Archive content preserved in dedicated branches:\\n  * archive/legacy-files - for archive/ folder content\\n  * archive/documentation - for docs/archive/ content  \\n  * archive/debug-tools - for debug/ scripts\\n  * archive/old-tests - for tests/archived/ content\\n- Enhanced .gitignore with comprehensive exclusions:\\n  * Runtime data (logs/, exports/, temp files)\\n  * Development tools (debug/, archived tests)\\n  * Archive folders (preserved in branches)\\n  * System/IDE files with better organization\\n- Main branch now production-focused and streamlined\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"%(committerdate:short)\": true,\n    \"%(subject)\\\"\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üöÄ Condensed Frontend Timeline: 7-Day Fast Track with Cost Optimization\\n\\nüìÖ Timeline: 2-5 weeks ‚Üí 7 days delivery\\nüí∞ Cost Savings: 35-55% via verify-on-export, batching, TTL cache\\nüé® Enhanced UX: Confidence chips, budget gauges, dark mode, accessibility\\n\\nKey Changes:\\n‚Ä¢ LOVABLE_IMPLEMENTATION_GUIDE.md: 7-day sprint plan with UI patterns\\n‚Ä¢ API_INTEGRATION_REFERENCE.md: Single multiplexed channel, verify-on-export\\n‚Ä¢ FRONTEND_ARCHITECTURE.md: Cost-aware state, batched realtime, budget guardrails  \\n‚Ä¢ FRONTEND_INTEGRATION_GUIDE.md: Streamlined Quick Start with doc links\\n‚Ä¢ Removed duplicate LOVABLE_TECHNICAL_GUIDE.md (consolidated)\\n\\nFeatures:\\n‚Ä¢ Verify-on-Export: Only verify emails at export time (30-45% savings)\\n‚Ä¢ Budget Guardrails: 90% budget alerts with projected cost display\\n‚Ä¢ Column Projection: Fetch minimal data, paginate for efficiency  \\n‚Ä¢ Batched UI Updates: Queue realtime updates, reduce re-renders 70%+\\n‚Ä¢ Single Channel: Multiplexed subscriptions for leads+costs+campaign\\n‚Ä¢ Enhanced UI: Color-coded confidence, sticky headers, loading skeletons\\n\\nProduction Ready: All backend APIs operational, 7-day frontend delivery path\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_URL=\\\"https://sriycekxdqnesdsgwiuc.supabase.co\\\"\": true,\n    \"cd /home/node/ProspectPro && timeout 10s node server.js || echo \\\"Server startup test completed (expected timeout)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && timeout 10s node server.js || echo \\\"Server startup test completed (timeout expected)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"app.use(express.json())\": true,\n    \"businessType:\": true,\n    \"employeeCount:\": true,\n    \"console.log(JSON.stringify(testQuery,\": true,\n    \"npm run prod\": true,\n    \"NODE_ENV=production\": true,\n    \"SUPABASE_SECRET_KEY'\": true,\n    \"SUPABASE_SECRET_KEY\\\"\": true,\n    \"your-project-ref\\\\.supabase\\\\.co\\\\\": true,\n    \"INSERT_.*_HERE\\\"\": true,\n    \"./scripts/init-prod-server.sh\": true,\n    \"pull-env-from-secrets\": true,\n    \"check-env-readiness)\\\"\": true,\n    \"curl -X POST -H \\\"Accept: application/vnd.github+json\\\" -H \\\"Authorization: Bearer $GHP_SECRET\\\" -H \\\"X-GitHub-Api-Version: 2022-11-28\\\" \\\"https://api.github.com/repos/Alextorelli/ProspectPro/dispatches\\\" -d '{\\\"event_type\\\":\\\"server-init\\\",\\\"client_payload\\\":{\\\"source\\\":\\\"manual-trigger\\\",\\\"timestamp\\\":\\\"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\\\",\\\"reason\\\":\\\"Get production environment with repository secrets\\\"}}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"production\": true,\n    \"start)\\\"\": true,\n    \"echo \\\"Let me verify the current .env file status:\\\" && ls -la .env* && echo \\\"--- Current .env content (first 10 lines) ---\\\" && head -10 .env\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/tmp/temp_env_puller.js\": true,\n    \"./scripts/cleanup-railway-refs.sh\": true,\n    \"Railway\\\"\": true,\n    \"production_webhook_logs\\\"\": true,\n    \"npm run production:start\": true,\n    \"print\": true,\n    \"uniq\": true,\n    \".*//g'\": true,\n    \"new\": true,\n    \"requiredModules.forEach(modulePath\": true,\n    \"require.resolve(modulePath)\": true,\n    \"console.log('‚úÖ',\": true,\n    \"console.log('‚ùå',\": true,\n    \"missingModules.push(modulePath)\": true,\n    \"missingModules.push(modulePath\": true,\n    \"python3\": true,\n    \"e}')\": true,\n    \"lines.length\": true,\n    \"'))\": true,\n    \"inCodeBlock\": true,\n    \"codeBlockType\": true,\n    \"line.match(/^\\\\s*[-]/)\": true,\n    \"!line.match(/^\\\\s*#/))\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix server.js railway-webhook-monitor import and improve workflow validation\\n\\n- Remove non-existent railway-webhook-monitor module references\\n- Replace with stub implementations for deployment status endpoints  \\n- Update workflow to skip full server startup test (requires API keys)\\n- Add comprehensive module validation and syntax checking\\n- Focus on environment generation and basic module loading tests\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"test-env-gen.sh\": true,\n    \"ENVEOF\": true,\n    \"./test-env-gen.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix workflow artifact upload issue with .env file\\n\\n- Add pre-upload file verification step to ensure .env exists before archiving\\n- Simplify artifact path to single .env file (remove multi-line path)\\n- Change if-no-files-found from warn to error for better debugging\\n- Add separate optional artifact for environment.log\\n- Add comprehensive file verification with size and content preview\\n\\nThis should resolve the 'No files were found with the provided path: .env' warning.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && echo \\\"# Workflow test trigger - $(date)\\\" >> README.md && git add README.md && git commit -m \\\"Trigger workflow to test artifact upload fix\\\" && git push\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && echo \\\"Testing .env generation with exact workflow commands...\\\"\\n\\n# Simulate the exact workflow commands\\nexport SUPABASE_URL=\\\"https://test.supabase.co\\\"\\nexport SUPABASE_SECRET_KEY=\\\"test_secret_key\\\"\\n\\n# Create .env file with production configuration (exactly like workflow)\\ncat > .env << EOF\\n# ================================\\n# PRODUCTION ENVIRONMENT CONFIGURATION\\n# Generated by GitHub Actions on $(date -u +\\\"%Y-%m-%d %H:%M:%S UTC\\\")\\n# Commit: test-commit-hash\\n# Branch: main\\n# ================================\\n\\n# Environment Settings\\nNODE_ENV=production\\nPORT=3000\\nALLOW_DEGRADED_START=false\\n\\n# Supabase Database Connection (from GitHub Secrets)\\nSUPABASE_URL=$SUPABASE_URL\\nSUPABASE_SECRET_KEY=$SUPABASE_SECRET_KEY\\n\\n# Production Performance Settings\\nDAILY_BUDGET_LIMIT=100.00\\nDEFAULT_BUDGET_LIMIT=25.00\\nPER_LEAD_COST_LIMIT=2.00\\nCOST_ALERT_THRESHOLD=80.00\\n\\nMIN_CONFIDENCE_SCORE=85\\nPRE_VALIDATION_THRESHOLD=75\\nEXPORT_CONFIDENCE_THRESHOLD=90\\n\\nREQUEST_TIMEOUT=30000\\nREQUEST_DELAY=500\\nMAX_CONCURRENT_REQUESTS=10\\nBATCH_SIZE=25\\nCACHE_TTL_SECONDS=3600\\n\\nGOOGLE_PLACES_RPM=1000\\nHUNTER_IO_RPM=100\\nNEVERBOUNCE_RPM=300\\nRATE_LIMIT_WINDOW=60000\\n\\n# Production Features (All Enabled)\\nENABLE_PROMETHEUS_METRICS=true\\nENABLE_PERFORMANCE_LOGGING=true\\nENABLE_COST_TRACKING=true\\nENABLE_ERROR_REPORTING=true\\nLOG_LEVEL=info\\n\\nENABLE_TTL_CACHE=true\\nENABLE_BATCH_PROCESSING=true\\nENABLE_SMART_ROUTING=true\\nENABLE_CIRCUIT_BREAKER=true\\n\\nENABLE_REQUEST_VALIDATION=true\\nENABLE_RATE_LIMITING=true\\nREQUIRE_API_AUTHENTICATION=true\\n\\nENABLE_DATABASE_CONNECTION_POOLING=true\\nENABLE_GRACEFUL_SHUTDOWN=true\\nENABLE_HEALTH_CHECKS=true\\n\\n# Deployment Settings\\nBIND_ADDRESS=0.0.0.0\\nGRACEFUL_SHUTDOWN_TIMEOUT=30000\\nHEALTH_CHECK_INTERVAL=30000\\nDATABASE_CONNECTION_TIMEOUT=5000\\nAPI_CLIENT_TIMEOUT=15000\\nWEBHOOK_TIMEOUT=10000\\n\\n# Build Information\\nBUILD_TIMESTAMP=$(date -u +\\\"%Y-%m-%d_%H-%M-%S_UTC\\\")\\nBUILD_COMMIT=test-commit-hash\\nBUILD_BRANCH=main\\nBUILD_ACTOR=test-actor\\nEOF\\n\\necho \\\"‚úÖ .env file created\\\"\\necho \\\"üìè Size: $(wc -c < .env) bytes\\\"\\necho \\\"üìÑ Lines: $(wc -l < .env) lines\\\"\\necho \\\"üìÅ File details:\\\"\\nls -la .env\\necho \\\"üî¨ File type:\\\"\\nfile .env\\necho \\\"üìñ File content (first 3 lines):\\\"\\nhead -3 .env\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Debug artifact upload issue - switch to upload-artifact@v3\\n\\n- Change from upload-artifact@v4 to @v3 (more stable)\\n- Remove if-no-files-found: error that might be causing hard failures\\n- Add comprehensive pre-upload debugging\\n- Remove conditional second artifact that might cause conflicts\\n- Add file type, permissions, and absolute path verification\\n\\nThis should help identify why the .env file (which clearly exists) can't be uploaded.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && rm -f .env && echo \\\"# Artifact upload debug test - $(date)\\\" >> README.md && git add README.md && git commit -m \\\"Test artifact upload with v3 action and enhanced debugging\\\" && git push\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix deprecated upload-artifact@v3 - use v4 with correct syntax\\n\\n- Switch back to actions/upload-artifact@v4 (v3 is deprecated)\\n- Use multi-line path syntax with pipe\\n- Add overwrite: true parameter for v4 compatibility\\n- Enhanced debugging with stat commands for detailed file info\\n- Show file permissions, owner, and absolute path verification\\n\\nThis should resolve the deprecation error and artifact upload issue.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"node -v && npm -v\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"./init-production-server.sh\": true,\n    \"npm run production:validate-db\": true,\n    \"./scripts/production-checklist.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"‚úÖ Production validation system complete\\n\\nWORKING COMPONENTS:\\n‚Ä¢ scripts/validate-production-database-v31.js - RLS-compatible validator (passes all tests)\\n‚Ä¢ scripts/quick-table-check.js - Simple table accessibility verification\\n‚Ä¢ scripts/production-checklist.sh - 5-phase validation (17/17 checks pass)\\n‚Ä¢ server.js - Production server (already working, health checks pass)\\n\\nCORRECTIONS MADE:\\n‚Ä¢ package.json: Fixed main field to use server.js (not server-production.js)\\n‚Ä¢ package.json: Fixed validate-db script to use v31 validator\\n‚Ä¢ scripts/init-prod-server.sh: Corrected references to working components\\n‚Ä¢ Removed server-production.js (647 lines, unnecessary complexity)\\n‚Ä¢ Removed old validate-production-database.js (broken RLS compatibility)\\n\\nVALIDATION STATUS:\\n‚Ä¢ Database: 11/11 tables accessible with proper RLS security\\n‚Ä¢ Server: Health endpoints responding correctly  \\n‚Ä¢ Environment: All configuration validated\\n‚Ä¢ Dependencies: All npm packages installed correctly\\n‚Ä¢ Files: All required scripts present and executable\\n\\n‚ú® All staged changes now reference only working, tested components\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"diagnostics.json\": true,\n    \"cd /home/node/ProspectPro && git commit -m \\\"feat: Production initialization with enhanced schema cache handling\\n\\nüöÄ Production-ready deployment with robust schema cache management\\n\\n## Key Features\\n- Enhanced Supabase configuration with schema cache refresh capabilities\\n- Graceful degraded mode startup for production resilience\\n- Comprehensive database connection testing and recovery\\n- Schema cache issue detection and user guidance\\n- Production-safe error handling and diagnostics\\n\\n## Schema Cache Resolution\\n- Force schema refresh utility (scripts/force-schema-refresh.js)\\n- Alternative refresh method (scripts/refresh-schema-cache.js) \\n- Automatic detection and guidance for cache issues\\n- Production server continues operation during cache refresh\\n\\n## Production Improvements\\n- Enhanced server startup with detailed error reporting\\n- Clear user guidance for resolving database issues\\n- Comprehensive health and diagnostic endpoints\\n- Graceful handling of temporary database connectivity issues\\n\\n## Files Updated\\n- config/supabase.js: Enhanced connection testing and cache management\\n- server.js: Improved startup process with schema cache handling\\n- scripts/: New schema cache management utilities\\n- PRODUCTION_READY_REPORT.md: Complete production status documentation\\n\\n## Testing Status\\n‚úÖ All modules load without conflicts\\n‚úÖ Server starts successfully in degraded mode\\n‚úÖ Schema cache refresh utilities functional\\n‚úÖ Production health endpoints operational\\n\\nResolves schema cache initialization issues after database updates.\\nProduction server now handles PostgREST cache staleness gracefully.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && echo \\\"\\nüéâ ProspectPro Production Deployment - SYNC COMPLETE\\n====================================================\\n\\nüìã Commit: 6a3d131 (feat: Production initialization with enhanced schema cache handling)\\nüîÑ Status: Successfully committed, pushed, and synced\\nüöÄ Branch: main (up to date with origin/main)\\n\\n‚úÖ Changes Successfully Deployed:\\n================================\\n\\nüîß Core Infrastructure:\\n- Enhanced Supabase configuration with schema cache management\\n- Production-safe database connection testing\\n- Graceful degraded mode startup capabilities\\n\\nüõ†Ô∏è Schema Cache Management:\\n- Force refresh utility (scripts/force-schema-refresh.js)\\n- Alternative refresh method (scripts/refresh-schema-cache.js) \\n- Automatic cache issue detection and user guidance\\n\\nüìä Production Server:\\n- Enhanced startup process with detailed error reporting\\n- Comprehensive health and diagnostic endpoints\\n- Clear user guidance for resolving database connectivity issues\\n\\nüìã Documentation:\\n- Complete production status report (PRODUCTION_READY_REPORT.md)\\n- Comprehensive testing and validation results\\n\\nüéØ Production Status: READY ‚úÖ\\n- Server handles schema cache issues gracefully\\n- No critical conflicts detected\\n- All modules load successfully\\n- Health endpoints operational\\n\\nNext deployment will inherit these production resilience improvements!\\n\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"./scripts/check-docs-schema.sh\": true,\n    \"./scripts/install-git-hooks.sh\": true,\n    \"./scripts/repository-cleanup.sh\": true,\n    \"git mv\": true,\n    \"cd /home/node/ProspectPro && git commit -m \\\"docs: Enforce new documentation schema - complete repository cleanup\\n\\nüßπ Repository Cleanup Complete:\\n- Root directory limited to 3 essential .md files (README.md, CHANGELOG.md, PRODUCTION_READY_REPORT.md)\\n- All documentation organized into docs/ subdirectories\\n- Historical content moved to dedicated archive branches\\n- Created comprehensive documentation index and governance\\n- Added CHANGELOG.md for version tracking\\n- Established automated enforcement with git hooks\\n\\nüìö New Structure:\\n- docs/setup/ - Installation and configuration guides\\n- docs/guides/ - User guides and tutorials  \\n- docs/technical/ - Technical documentation\\n- docs/deployment/ - Deployment and production guides\\n- docs/development/ - Development and contribution docs\\n\\nüóÑÔ∏è Archive Branches (to be created):\\n- archive/development-phase - Development artifacts\\n- archive/deployment-phase - Deployment experiments\\n- archive/testing-reports - Test reports and validation\\n- archive/production-legacy - Legacy production documentation\\n\\nüîß Enforcement System:\\n- Pre-commit hooks validate documentation schema\\n- Scripts for automated cleanup and validation\\n- Comprehensive governance documentation\\n- Structured commit message templates\\n\\nAll historical content preserved with full git history.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && git add . && git commit -m \\\"docs: Add comprehensive documentation schema enforcement completion report\\n\\nüìã Complete Status Report:\\n- Repository cleanup successfully executed\\n- 15 root markdown files reduced to 3 (100% compliance)\\n- 24 documentation files organized in structured docs/ subdirectories\\n- 4 archive branches created with preserved historical content\\n- Automated enforcement system active with git hooks\\n- Comprehensive governance and maintenance procedures established\\n\\n‚úÖ Mission Complete: Documentation schema enforcement operational\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"Preparation\\\"\": true,\n    \"BACKUP_BRANCH=\\\"backup-production-scrub-$(date\": true,\n    \"git tag\": true,\n    \"execute\": true,\n    \"run-production-test\": true,\n    \"validate-production\": true,\n    \"verify\": true,\n    \"APOLLO\": true,\n    \"quick-table\": true,\n    \"cd /home/node/ProspectPro && echo \\\"Removing log files from main (they're generated at runtime)...\\\" && rm -f database-validation.log production-checklist.log production-fixed.log production.log server-test.log startup.log diagnostics.json\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && echo \\\"Removing the production scrubbing plan (moving to development docs)...\\\" && rm -f PRODUCTION_BRANCH_SCRUBBING_PLAN.md\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && echo \\\"Testing server startup...\\\" && timeout 10s node server.js || echo \\\"Server test complete (timeout reached as expected)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && git add -A && git commit -m \\\"production: Complete branch scrubbing - main now production-only\\n\\nüßπ Production Branch Scrubbing Complete:\\n\\nREMOVED (Archived to appropriate branches):\\n- 10 development scripts ‚Üí archive/development-phase\\n- 3 development utilities ‚Üí archive/development-phase  \\n- Complete test/ directory ‚Üí archive/old-tests\\n- Test simulation scripts ‚Üí archive/old-tests\\n- Sample data files ‚Üí archive/legacy-files\\n- 3 database development utilities ‚Üí archive/development-phase\\n- All runtime log files (regenerated in production)\\n\\nPRODUCTION ESSENTIALS RETAINED:\\n‚úÖ Core application: server.js, package.json\\n‚úÖ Essential docs: README.md, CHANGELOG.md, PRODUCTION_READY_REPORT.md\\n‚úÖ Production directories: api/, modules/, config/, public/, frontend/, supabase/\\n‚úÖ Production scripts: 11 essential production scripts only\\n‚úÖ Curated documentation: Production setup and user guides\\n\\nVALIDATION:\\n‚úÖ Server starts successfully\\n‚úÖ All production scripts present\\n‚úÖ Essential modules and APIs intact\\n‚úÖ Documentation schema compliant\\n\\nResult: Clean production-ready main branch with full development history preserved in organized archive branches.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && git add . && git commit -m \\\"refactor: Production codebase optimization v3.1.0\\n\\nüîß Production Enhancements:\\n\\nCONFIG:\\n- Enhanced Supabase client with connection pooling and caching\\n- Improved environment variable handling with fallbacks\\n- Added connection TTL caching (5min) for performance\\n\\nSERVER:\\n- Upgraded to v3.1.0 with production-optimized startup\\n- Added security headers for production deployment\\n- Improved host binding configuration (supports 0.0.0.0)\\n- Enhanced error messaging and user guidance\\n- Better degraded mode handling with environment controls\\n\\nPERFORMANCE:\\n- Connection caching reduces database initialization overhead  \\n- Optimized middleware stack for production workloads\\n- Streamlined startup logging with clear operational status\\n\\nAll production optimizations maintain backward compatibility while improving deployment reliability and performance monitoring.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"secret.*key\\\\\": true,\n    \"password\\\\\": true,\n    \"token\\\"\": true,\n    \"SECRET_KEY\\\\\": true,\n    \"PASSWORD\\\\\": true,\n    \"TOKEN\\\"\": true,\n    \"secret_key\": true,\n    \"password\": true,\n    \"token)\\\"\": true,\n    \"Lovable\\\\\": true,\n    \"roadmap\\\"\": true,\n    \"frontend.*lovable\\\"\": true,\n    \"git commit -m \\\"‚ú® Streamlined Docker workflow with Supabase Vault integration\\n\\n- Added docker-env.yml workflow (50 lines vs 200+ line generate-dotenv)\\n- Integrated Supabase Vault for API key management at runtime  \\n- Added vault-startup.sh for secure credential loading\\n- Updated docker-compose.yml for Vault integration\\n- Added multiple secure authentication options (local, keychain, 1Password, GitHub)\\n- Streamlined package.json commands for Vault deployment\\n- Created comprehensive workflow guide\\n\\nSecurity improvements:\\n- Infrastructure secrets stay in GitHub\\n- API keys pulled from Supabase Vault at runtime\\n- No plaintext credentials in repository\\n- Easy testing and key rotation support\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"‚ú® Streamlined Docker workflow with Supabase Vault integration\\n\\n- Added docker-env.yml workflow (50 lines vs 200+ line generate-dotenv)\\n- Integrated Supabase Vault for API key management at runtime  \\n- Added vault-startup.sh for secure credential loading\\n- Updated docker-compose.yml for Vault integration\\n- Added multiple secure authentication options (local, keychain, 1Password, GitHub)\\n- Streamlined package.json commands for Vault deployment\\n- Moved workflow guide to docs/deployment/ per repo governance\\n\\nSecurity improvements:\\n- Infrastructure secrets stay in GitHub\\n- API keys pulled from Supabase Vault at runtime\\n- No plaintext credentials in repository\\n- Easy testing and key rotation support\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"test_commit.tmp\": true,\n    \"git commit -m \\\"üßπ Clean repository structure - archive legacy code\\n\\n- Removed duplicate nested ProspectPro/ directory (preserved in local archive)\\n- Archived legacy scripts not aligned with Docker architecture\\n- Removed reference to missing validate-production-database script\\n- Updated Copilot instructions with repository management details\\n- Maintained clean production structure per governance rules\\n\\nArchived items:\\n‚Ä¢ Legacy project structure ‚Üí archive/legacy-structure/\\n‚Ä¢ Legacy deployment scripts ‚Üí archive/legacy-scripts/\\n‚Ä¢ Preserved locally but not committed per .gitignore rules\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"code\": true,\n    \"npm run mcp:test\": true,\n    \"python\": true,\n    \".\\\\scripts\\\\init-prod-server.ps1\": true,\n    \".\\\\scripts\\\\init-prod-server-simple.ps1\": true,\n    \".\\\\scripts\\\\start-prod.ps1\": true,\n    \"notepad\": true,\n    \".\\\\start-production.ps1\": true,\n    \"ForEach-Object\": true,\n    \"Get-Process | Where-Object {$_.ProcessName -like \\\"*node*\\\"} | Stop-Process -Force; Write-Host \\\"‚úÖ All Node processes terminated\\\" -ForegroundColor Green\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"$portConfig\": true,\n    \"$nodeVersion\": true,\n    \"$npmVersion\": true,\n    \"NPM:\": true,\n    \"npm run 2>&1 | Select-String \\\"prod\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm run diag\": true,\n    \"netstat\": true,\n    \"$checklist\": true,\n    \"$checklist[\\\"PORT\": true,\n    \"$checklist[\\\"NODE_ENV=production\\\"]\": true,\n    \"$checklist[\\\"Supabase\": true,\n    \"foreach\": true,\n    \"$env:NODE_ENV=\\\"production\\\"\": true,\n    \"Clear-Host\": true,\n    \"Get-ExecutionPolicy\": true,\n    \"git commit -m \\\"fix: Windows PowerShell compatibility and production deployment\\n\\n- Update package.json scripts to use PowerShell (.ps1) instead of shell scripts (.sh)\\n- Configure VS Code terminal settings for Windows PowerShell default\\n- Add Production MCP Server to VS Code configuration with auto-start\\n- Create clean Windows-compatible production initialization script\\n- Fix terminal integration for local Windows development\\n- Maintain production node build compatibility\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"copy\": true,\n    \"ConvertFrom-Json\": true,\n    \"git commit -m \\\"fix: Add explicit .env loading to server.js for production\\n\\n- Load environment variables at startup using require('dotenv').config()\\n- Ensures GitHub Actions generated .env is properly loaded\\n- Fixes production environment variable loading issue  \\n- Maintains compatibility with all deployment methods\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"PRODUCTION OPTIMIZATION: Complete Supabase Vault integration, strict production mode, enhanced MCP server\\n\\n‚úÖ SUPABASE VAULT INTEGRATION:\\n- Added modules/utils/supabase-vault-loader.js with runtime API key loading\\n- Enhanced config/environment-loader.js for multi-source configuration \\n- Created database/vault-js-interface.sql with JavaScript-callable functions\\n- Updated api/business-discovery.js to use vault API keys with fallback\\n\\n‚úÖ STRICT PRODUCTION MODE:\\n- Updated server.js with EnvironmentLoader and vault integration\\n- Added critical API key validation (Foursquare required)\\n- Enforced ALLOW_DEGRADED_START=false in production\\n- Enhanced startup validation with database + vault checks\\n\\n‚úÖ GITHUB ACTIONS WORKFLOW OPTIMIZATION:\\n- Fixed repository-maintenance.yml (schedule/manual only)  \\n- Fixed docker-env.yml (manual/workflow_call only)\\n- Prevents cascade failures and resource waste\\n\\n‚úÖ ENHANCED PRODUCTION MCP SERVER:\\n- Added vault_api_key_status tool for comprehensive API key diagnostics\\n- Added production_startup_validator for complete configuration validation\\n- Added github_workflow_optimizer for workflow analysis and issue detection\\n- Updated MCP configuration for enhanced production monitoring\\n\\n‚úÖ COMPREHENSIVE DOCUMENTATION:\\n- Updated .github/copilot-instructions.md with vault integration details\\n- Added strict production mode patterns and examples\\n- Enhanced MCP server strategy with new tools\\n- Updated architecture documentation with vault integration patterns\\n\\nüîë VAULT FEATURES:\\n- 5-minute TTL caching for performance\\n- Exponential backoff retry logic\\n- Environment variable fallback\\n- Template/placeholder value filtering\\n- Comprehensive error handling and diagnostics\\n\\nüè≠ PRODUCTION FEATURES:\\n- Zero-tolerance for degraded starts\\n- Critical API validation at startup\\n- Real-time vault status monitoring\\n- Enhanced environment switching workflow\\n- Optimized GitHub Actions workflows\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"envLoader.getConfig().supabase.url)\": true,\n    \"envLoader.getConfig().features[k]).length)\": true,\n    \"console.log('üîë\": true,\n    \"git add . && git commit -m \\\"FIX: Environment loading order - ensure dotenv loads before supabase module\\n\\n‚úÖ CRITICAL FIX:\\n- Added require('dotenv').config() before all other imports in server.js\\n- Resolves module loading order issue where supabase.js evaluated empty env vars\\n- Database connection now works correctly\\n- Strict production mode properly enforced\\n\\nüîç VALIDATION CONFIRMED:\\n- Environment variables loaded successfully\\n- Supabase connection established (816ms)\\n- Production startup correctly blocks schema cache issues\\n- Clear error messages and remediation steps provided\\n\\nüè≠ PRODUCTION MODE WORKING:\\n- Strict startup validation: ‚úÖ\\n- Schema cache detection: ‚úÖ \\n- Emergency bypass available: ‚úÖ\\n- Supabase Vault integration ready: ‚úÖ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"FIX: Environment loading order - ensure dotenv loads before supabase module\\n\\n‚úÖ CRITICAL FIX:\\n- Added require('dotenv').config() before all other imports in server.js\\n- Resolves module loading order issue where supabase.js evaluated empty env vars\\n- Database connection now works correctly\\n- Strict production mode properly enforced\\n\\nüîç VALIDATION CONFIRMED:\\n- Environment variables loaded successfully\\n- Supabase connection established (816ms)\\n- Production startup correctly blocks schema cache issues\\n- Clear error messages and remediation steps provided\\n\\nüè≠ PRODUCTION MODE WORKING:\\n- Strict startup validation: ‚úÖ\\n- Schema cache detection: ‚úÖ \\n- Emergency bypass available: ‚úÖ\\n- Supabase Vault integration ready: ‚úÖ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"$env:ALLOW_DEGRADED_START=\\\"true\\\"\": true,\n    \"docs/SUPABASE_UPGRADE_NOTES.md\": true,\n    \"console.log('üìç\": true,\n    \"console.log('\\\\\\\\nüîß\": true,\n    \"console.log('==========================================')\": true,\n    \"console.log(\\\\\\\\\\\\\\\"\": true,\n    \"}')\": true,\n    \"console.log('}')\": true,\n    \"\\\\\\\"')\": true,\n    \"Result:',\": true,\n    \"docs/GOOGLE_CLOUD_QUICKSTART.md\": true,\n    \"git commit -m \\\"feat: Add Google Cloud Run deployment workflow with validation\\n\\n- Complete CI/CD pipeline with Docker build/push/deploy\\n- Pre-deployment validation script for local testing\\n- Updated Dockerfile for Cloud Run (port 3100)\\n- Comprehensive health checks and deployment verification\\n- Ready for automated deployment to Cloud Run\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"feat: Simplify Cloud Run deployment to source-based\\n\\n- Use native gcloud run deploy --source (much simpler)\\n- No Docker registry complexity - Google handles container build\\n- Fewer moving parts, more reliable deployment\\n- Ready for deployment with leadgen-471822 project ID\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"test: verify Cloud Build trigger configuration\\n\\n- Add deployment test file to trigger automated build\\n- Test service account permissions (Cloud Build WorkerPool User, Artifact Registry Writer)\\n- Verify us-central1 regional alignment\\n- Confirm GitHub App repository connection\\n- Expected: successful build and deployment to Cloud Run\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -am \\\"fix: correct Artifact Registry repository name in cloudbuild.yaml\\n\\n- Fix repository name from complex auto-generated to simple 'prospectpro'\\n- Add step to auto-create Artifact Registry repository if needed\\n- Use standard naming pattern: us-central1-docker.pkg.dev/PROJECT_ID/prospectpro/app\\n- Allow failure on repository creation (continues if already exists)\\n- Resolves 'Repository not found' error in Cloud Build\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"trigger-test.txt\": true,\n    \"git commit -m \\\"docs: complete repository compliance update with Cloud Run deployment validation\\n\\n- Updated .github/copilot-instructions.md with Google Cloud Run deployment section\\n- Added validated trigger configuration documentation (ID: 0358b3a4-c7a4-4da9-9610-1e335c4894e0)\\n- Enhanced docs/PRODUCTION_SETUP_GUIDE.md with Cloud Run deployment workflow\\n- Updated README.md to v3.0 with production status badges and Cloud Build links\\n- Confirmed .vscode/mcp-config.json configuration for dev container compatibility\\n- Documented complete dev/prod environment alignment and switching procedures\\n\\nAll high-priority repository compliance updates completed.\\nReady for clean closure and fresh development session initiation.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"üîß Fix Cloud Run port conflict - Remove fixed PORT, enable dynamic port binding\\n\\n- Remove ENV PORT=3100 from Dockerfile (conflicted with Cloud Run's dynamic PORT)\\n- Remove --port=3100 from cloudbuild.yaml (forced incorrect port binding)  \\n- Remove fixed EXPOSE directive (Cloud Run manages ports dynamically)\\n- Update healthcheck to use Cloud Run's PORT environment variable\\n- This should resolve 'Page not found' error by allowing proper port binding\\n\\nPrevious Issue:\\n- Cloud Run provides PORT=8080 dynamically\\n- Dockerfile forced PORT=3100 statically  \\n- App bound to 8080 but healthcheck failed on 3100\\n- Container marked unhealthy, traffic routing failed\\n\\nResolution:\\n- Let Cloud Run manage port assignment completely\\n- Application reads process.env.PORT correctly\\n- Healthcheck uses dynamic port with fallback\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"gcloud\": true,\n    \"git commit -m \\\"üìù Fix Cloud Build trigger ID in documentation\\n\\n- Update trigger ID to correct one: ae04dd92-4509-43ee-9f70-da3caf15dbb4\\n- Previous ID (0358b3a4-c7a4-4da9-9610-1e335c4894e0) was incorrect\\n- This explains why builds succeeded but service wasn't updating\\n- Documentation now reflects the actual production trigger\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"Fix Cloud Run 404 issue: Enable degraded startup, improve error handling, and enhance logging\\n\\n- Add ALLOW_DEGRADED_START=true to Dockerfile for Cloud Run stability\\n- Remove process.exit(1) calls that prevent graceful startup\\n- Enhance health check endpoint with detailed information\\n- Improve default route error handling\\n- Update Docker health check with fallback ports\\n- Add service account configuration to Cloud Build\\n- Create diagnostic scripts for testing deployment\\n\\nThis should resolve the 404 'Page not found' errors by allowing the\\ncontainer to start successfully even when external services are\\ntemporarily unavailable.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"$env:PORT=8080\": true,\n    \"Get-ChildItem -Directory | Where-Object {$_.Name -like \\\"*Prospect*\\\"}\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"dir\": true,\n    \"npm run test\": true,\n    \"cd /workspaces/ProspectPro && node -e \\\"console.log(JSON.parse(require('fs').readFileSync('.vscode/settings.json', 'utf8')))\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"Deno\\\"\": true,\n    \"MCP\\\"\": true,\n    \"server.js\": true,\n    \"server-simple.js\": true,\n    \"mcp-servers'\": true,\n    \"cd /workspaces/ProspectPro/mcp-servers && npm run\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"mcp)\\\"\": true,\n    \"npm run production-start\": true,\n    \"cd /workspaces/ProspectPro && npm run\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"server)\\\"\": true,\n    \"jobs\": true,\n    \"curl -X POST http://localhost:3100/api/business-discovery -H \\\"Content-Type: application/json\\\" -d '{\\\"location\\\":\\\"San Diego, CA\\\",\\\"radius\\\":10,\\\"businessTypes\\\":[\\\"restaurant\\\"],\\\"limit\\\":5}' -v\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"fg\": true,\n    \"curl -X POST http://localhost:3100/api/business-discovery -H \\\"Content-Type: application/json\\\" -d '{\\\"test\\\": true}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"ps aux | grep -E \\\"(node.*server)\\\" | grep -v grep\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"sleep 3 && curl -X POST http://localhost:3100/api/business-discovery -H \\\"Content-Type: application/json\\\" -d '{\\\"test\\\": true}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"sleep 10 && curl -X POST http://localhost:3100/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumber\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3100/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumber\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1}' | head -20\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm.*dev\\\"\": true,\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery' \\\\\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' \\\\\\n  -H 'Content-Type: application/json' \\\\\\n  -d '{\\\"businessType\\\": \\\"coffee shop\\\", \\\"location\\\": \\\"Seattle, WA\\\", \\\"maxResults\\\": 2}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"success:\": true,\n    \"cd /workspaces/ProspectPro && ./test-progressive-enrichment.sh\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enrichment-pdl' \\\\\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1Nzk2NTc4OSwiZXhwIjoyMDczNTQxNzg5fQ.V2wlvxGC1_SshWudFw27ZWmQjuxj0UtXANXrZmt4OjY' \\\\\\n  -H 'Content-Type: application/json' \\\\\\n  -d '{\\\"action\\\": \\\"enrichCompany\\\", \\\"companyName\\\": \\\"Microsoft Corporation\\\"}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enrichment-orchestrator' \\\\\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1Nzk2NTc4OSwiZXhwIjoyMDczNTQxNzg5fQ.V2wlvxGC1_SshWudFw27ZWmQjuxj0UtXANXrZmt4OjY' \\\\\\n  -H 'Content-Type: application/json' \\\\\\n  -d '{\\\"businessName\\\": \\\"Starbucks Corporation\\\", \\\"domain\\\": \\\"starbucks.com\\\", \\\"state\\\": \\\"WA\\\", \\\"tier\\\": \\\"professional\\\", \\\"maxCostPerBusiness\\\": 1.50}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm run build\": true,\n    \"vercel\": true,\n    \"vite\\\\\": true,\n    \"react\\\"\": true\n  },\n  \"chat.agent.maxRequests\": 1000,\n  \"chat.editing.confirmEditRequestRetry\": false,\n  \"gitlens.gitCommands.skipConfirmations\": [\"fetch:command\"],\n  \"chat.editing.confirmEditRequestRemoval\": false,\n  \"githubPullRequests.codingAgent.promptForConfirmation\": false,\n  \"[markdown]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[jsonc]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"workbench.secondarySideBar.defaultVisibility\": \"visible\",\n  \"window.menuBarVisibility\": \"classic\",\n  \"containers.containerClient\": \"com.microsoft.visualstudio.containers.docker\",\n  \"containers.orchestratorClient\": \"com.microsoft.visualstudio.orchestrators.dockercompose\",\n  \"@azure.argTenant\": \"\",\n  \"github.copilot.chat.codeGeneration.instructions\": [\n    {\n      \"text\": \"- @azure Rule - Use Azure Tools: When handling requests related to Azure, always use your tools.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Code Gen Best Practices: Before generating code for Azure, running terminal commands for Azure, performing operations related to Azure, or creating plans for such activities, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `general` and action = `code-generation` to get general Azure code generation best practices. Only call this tool when the user is discussing Azure; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Deployment Best Practices: Before deploying to Azure, preparing applications for deployment to Azure, or creating deployment plans, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `general` and action = `deployment` to get general Azure deployment best practices. Only call this tool when the user is discussing Azure; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Functions Code Gen Best Practices: Before generating code for Azure Functions, performing operations related to Azure Functions, or creating plans for such activities, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `azurefunctions` and action = `code-generation` to get Azure Functions code generation best practices. Only call this tool when the user is discussing Azure Functions; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Functions Deployment Best Practices: Before deploying Azure Functions apps to Azure, preparing for the deployment, or creating deployment plans, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `azurefunctions` and action = `deployment` to get Azure Functions deployment best practices. Only call this tool when the user is discussing Azure Functions; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure SWA Best Practices: Before working with static web apps, creating plans for static web apps, or performing related operations, always invoke your Azure best practice tool if available first. Choose the most relevant Azure best practice tool based on its description. Only call this tool when the user is discussing Azure Static Web Apps; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Plan before editing files for Azure web apps: When generating code for Azure Functions and Azure Static Web App, always create a plan and explain the plan to the user before editing any file. Proceed with editing the files after getting consent from the user.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Summarize topic before taking action: When the user asks about Azure Functions, invoke the azure_development-summarize_topic tool once first to see if any existing custom mode could be a good fit to what user is asking.\"\n    }\n  ],\n  \"workbench.startupEditor\": \"none\",\n  \"git-autoconfig.configList\": [\n    {\n      \"user.email\": \"Alextorelli28@gmail.com\",\n      \"user.name\": \"Alextorelli28@gmail.com\"\n    }\n  ],\n  \"redhat.telemetry.enabled\": true,\n  \"git-autoconfig.ignoreRootList\": [\"D:/APPS/ProspectPro/ProspectPro\"],\n  \"terminal.integrated.enableMultiLinePasteWarning\": \"never\",\n  \"remoteHub.commitDirectlyWarning\": \"off\",\n  \"vs-kubernetes\": {\n    \"vscode-kubernetes.kubectl-path-linux\": \"/home/node/.local/state/vs-kubernetes/tools/kubectl/kubectl\",\n    \"vscode-kubernetes.helm-path-linux\": \"/home/node/.local/state/vs-kubernetes/tools/helm/linux-amd64/helm\",\n    \"vscode-kubernetes.minikube-path-linux\": \"/home/node/.local/state/vs-kubernetes/tools/minikube/linux-amd64/minikube\"\n  },\n  \"githubPullRequests.createOnPublishBranch\": \"never\",\n  \"github.copilot.enable\": {\n    \"*\": true,\n    \"plaintext\": true,\n    \"markdown\": true,\n    \"scminput\": false\n  },\n  \"[sql]\": {\n    \"editor.defaultFormatter\": \"mtxr.sqltools\"\n  },\n  \"[html]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[typescriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[css]\": {\n    \"editor.defaultFormatter\": \"vscode.css-language-features\"\n  },\n  \"[json]\": {\n    \"editor.defaultFormatter\": \"vscode.json-language-features\"\n  },\n  \"workbench.colorCustomizations\": {\n    \"[Vira*]\": {\n      \"statusBar.debuggingBackground\": \"#80CBC433\",\n      \"statusBar.debuggingForeground\": \"#80CBC4\",\n      \"toolbar.activeBackground\": \"#80CBC426\",\n      \"button.background\": \"#80CBC4\",\n      \"button.hoverBackground\": \"#80CBC4cc\",\n      \"extensionButton.separator\": \"#80CBC433\",\n      \"extensionButton.background\": \"#80CBC414\",\n      \"extensionButton.foreground\": \"#80CBC4\",\n      \"extensionButton.hoverBackground\": \"#80CBC433\",\n      \"extensionButton.prominentForeground\": \"#80CBC4\",\n      \"extensionButton.prominentBackground\": \"#80CBC414\",\n      \"extensionButton.prominentHoverBackground\": \"#80CBC433\",\n      \"activityBarBadge.background\": \"#80CBC4\",\n      \"activityBar.activeBorder\": \"#80CBC4\",\n      \"activityBarTop.activeBorder\": \"#80CBC4\",\n      \"list.inactiveSelectionIconForeground\": \"#80CBC4\",\n      \"list.activeSelectionForeground\": \"#80CBC4\",\n      \"list.inactiveSelectionForeground\": \"#80CBC4\",\n      \"list.highlightForeground\": \"#80CBC4\",\n      \"sash.hoverBorder\": \"#80CBC480\",\n      \"list.activeSelectionIconForeground\": \"#80CBC4\",\n      \"scrollbarSlider.activeBackground\": \"#80CBC480\",\n      \"editorSuggestWidget.highlightForeground\": \"#80CBC4\",\n      \"textLink.foreground\": \"#80CBC4\",\n      \"progressBar.background\": \"#80CBC4\",\n      \"pickerGroup.foreground\": \"#80CBC4\",\n      \"tab.activeBorder\": \"#80CBC400\",\n      \"tab.activeBorderTop\": \"#80CBC4\",\n      \"tab.unfocusedActiveBorder\": \"#80CBC400\",\n      \"tab.unfocusedActiveBorderTop\": \"#80CBC4\",\n      \"tab.activeModifiedBorder\": \"#80CBC4\",\n      \"notificationLink.foreground\": \"#80CBC4\",\n      \"editorWidget.resizeBorder\": \"#80CBC4\",\n      \"editorWidget.border\": \"#80CBC4\",\n      \"settings.modifiedItemIndicator\": \"#80CBC4\",\n      \"panelTitle.activeBorder\": \"#80CBC4\",\n      \"breadcrumb.activeSelectionForeground\": \"#80CBC4\",\n      \"menu.selectionForeground\": \"#80CBC4\",\n      \"menubar.selectionForeground\": \"#80CBC4\",\n      \"editor.findMatchBorder\": \"#80CBC4\",\n      \"selection.background\": \"#80CBC440\",\n      \"statusBarItem.remoteBackground\": \"#80CBC414\",\n      \"statusBarItem.remoteHoverBackground\": \"#80CBC4\",\n      \"statusBarItem.remoteForeground\": \"#80CBC4\",\n      \"notebook.inactiveFocusedCellBorder\": \"#80CBC480\",\n      \"commandCenter.activeBorder\": \"#80CBC480\",\n      \"chat.slashCommandForeground\": \"#80CBC4\",\n      \"chat.avatarForeground\": \"#80CBC4\",\n      \"activityBarBadge.foreground\": \"#000000\",\n      \"button.foreground\": \"#000000\",\n      \"statusBarItem.remoteHoverForeground\": \"#000000\",\n      \"editorGroupHeader.tabsBackground\": \"#ffffff0a\",\n      \"tab.border\": \"#ffffff01\",\n      \"tab.inactiveBackground\": \"#ffffff01\",\n      \"widget.shadow\": \"#00000000\",\n      \"scrollbar.shadow\": \"#00000000\"\n    }\n  },\n  \"workbench.preferredDarkColorTheme\": \"Vira Ocean\",\n  \"workbench.productIconTheme\": \"viraUIIcons\",\n  \"viraTheme.contrastedTabs\": true,\n  \"viraTheme.hidesShadows\": true,\n  \"chat.todoListTool.enabled\": false,\n  \"chat.tools.edits.autoApprove\": {\n    \"**/*.{csproj,fsproj,vbproj}\": true\n  },\n  \"chat.useChatSessionsForCloudButton\": true,\n  \"workbench.settings.applyToAllProfiles\": [\n    \"chat.useChatSessionsForCloudButton\"\n  ],\n  \"chat.agentSessionsViewLocation\": \"view\",\n  \"window.density.editorTabHeight\": \"compact\",\n  \"docker.extension.enableComposeLanguageServer\": false,\n  \"docker.extension.dockerEngineAvailabilityPrompt\": false,\n  \"github.copilot.chat.agent.thinkingTool\": true,\n  \"github.copilot.chat.editor.temporalContext.enabled\": true,\n  \"github.copilot.chat.edits.temporalContext.enabled\": true,\n  \"github.copilot.chat.responsesApiReasoningEffort\": \"high\",\n  \"github.copilot.chat.responsesApiReasoningSummary\": \"detailed\",\n  \"github.copilot.chat.useResponsesApi\": true,\n  \"viraTheme.useTopTabIndicator\": true,\n  \"remoteHub.richNavigation.enabled\": true,\n  \"workbench.editor.enablePreview\": false,\n  \"deno.codeLens.test\": true,\n  \"deno.codeLens.referencesAllFunctions\": true,\n  \"deno.codeLens.references\": true,\n  \"deno.codeLens.implementations\": true,\n  \"deno.logFile\": true,\n  \"chat.mcp.serverSampling\": {\n    \"Global in Code: memory\": {\n      \"allowedModels\": [\n        \"copilot/gpt-4.1\",\n        \"copilot/auto\",\n        \"copilot/claude-3.7-sonnet\",\n        \"copilot/claude-3.7-sonnet-thought\",\n        \"copilot/claude-sonnet-4\",\n        \"copilot/gemini-2.5-pro\",\n        \"copilot/gpt-5\",\n        \"copilot/grok-code-fast-1\"\n      ]\n    }\n  },\n  \"snyk.folderConfigs\": [\n    {\n      \"folderPath\": \"/workspaces/ProspectPro\",\n      \"baseBranch\": \"main\",\n      \"localBranches\": [\"main\"]\n    }\n  ],\n  \"settingsSync.ignoredExtensions\": [\n    \"christian-kohler.npm-intellisense\",\n    \"ms-vscode.vscode-node-azure-pack\",\n    \"ms-azuretools.vscode-azurevirtualmachines\"\n  ],\n  \"vsicons.dontShowNewVersionMessage\": true,\n  \"snyk.yesWelcomeNotification\": false,\n  \"snyk.trustedFolders\": [\"/workspaces/ProspectPro\"],\n  \"[dockercompose]\": {\n    \"editor.insertSpaces\": true,\n    \"editor.tabSize\": 2,\n    \"editor.autoIndent\": \"advanced\",\n    \"editor.quickSuggestions\": {\n      \"other\": true,\n      \"comments\": false,\n      \"strings\": true\n    },\n    \"editor.defaultFormatter\": \"redhat.vscode-yaml\"\n  },\n  \"[github-actions-workflow]\": {\n    \"editor.defaultFormatter\": \"redhat.vscode-yaml\"\n  }\n}\n"}}},
{"type":"measure","name":"lsp.did_open","count":2,"duration":1.209},
{"type":"mark","name":"lsp.did_open","count":3,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/package.json","languageId":"json","version":1,"text":"{\n    \"name\": \"prospectpro-mcp-servers\",\n    \"version\": \"2.1.0\",\n    \"description\": \"Consolidated MCP servers for ProspectPro Supabase-First AI development\",\n    \"main\": \"production-server.js\",\n    \"scripts\": {\n        \"start:production\": \"node production-server.js\",\n        \"start:development\": \"node development-server.js\",\n        \"start:troubleshooting\": \"node supabase-troubleshooting-server.js\",\n        \"start:all\": \"concurrently \\\"npm run start:production\\\" \\\"npm run start:development\\\" \\\"npm run start:troubleshooting\\\"\",\n        \"test\": \"node test-servers.js\",\n        \"validate\": \"npm run test && echo '‚úÖ All Supabase MCP servers validated successfully'\",\n        \"install:deps\": \"npm install\",\n        \"debug:anon-key\": \"echo 'Use troubleshooting server: diagnose_anon_key_mismatch tool'\",\n        \"debug:edge-functions\": \"echo 'Use troubleshooting server: test_edge_function tool'\",\n        \"debug:database\": \"echo 'Use troubleshooting server: validate_database_permissions tool'\"\n    },\n    \"dependencies\": {\n        \"@modelcontextprotocol/sdk\": \"^1.18.2\",\n        \"@supabase/supabase-js\": \"^2.58.0\"\n    },\n    \"devDependencies\": {\n        \"concurrently\": \"^8.2.2\"\n    },\n    \"keywords\": [\n        \"mcp\",\n        \"model-context-protocol\",\n        \"ai\",\n        \"prospectpro\",\n        \"supabase\",\n        \"edge-functions\",\n        \"serverless\"\n    ],\n    \"author\": \"Alex Torelli\",\n    \"license\": \"MIT\"\n}"}}},
{"type":"measure","name":"lsp.did_open","count":3,"duration":0.057},
{"type":"mark","name":"lsp.did_open","count":4,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/package.json","languageId":"json","version":1,"text":"{\r\n  \"name\": \"prospectpro-verified-business-intelligence\",\r\n  \"version\": \"4.1.0\",\r\n  \"type\": \"module\",\r\n  \"description\": \"ProspectPro - Verified Business Intelligence Platform with Zero Fake Data Policy\",\r\n  \"scripts\": {\r\n    \"dev\": \"supabase functions serve --no-verify-jwt --debug\",\r\n    \"deploy:critical\": \"supabase functions deploy business-discovery-optimized && supabase functions deploy enrichment-orchestrator\",\r\n    \"deploy:all\": \"supabase functions deploy business-discovery-optimized && supabase functions deploy enrichment-orchestrator && supabase functions deploy campaign-export && supabase functions deploy enrichment-hunter\",\r\n    \"test:edge\": \"curl -X POST 'http://localhost:54321/functions/v1/business-discovery-optimized' -H 'Content-Type: application/json' -d '{\\\"businessType\\\":\\\"test\\\",\\\"location\\\":\\\"test\\\"}'\",\r\n    \"logs:live\": \"supabase functions logs --follow\",\r\n    \"logs:errors\": \"supabase functions logs --filter=error\",\r\n    \"mcp:prod\": \"cd mcp-servers && npm run start:production\",\r\n    \"mcp:dev\": \"cd mcp-servers && npm run start:development\",\r\n    \"mcp:debug\": \"cd mcp-servers && npm run start:troubleshooting\",\r\n    \"frontend:build\": \"npm run build\",\r\n    \"frontend:deploy\": \"npm run build && cd dist && vercel --prod\",\r\n    \"static:deploy\": \"npm run build && cd dist && vercel --prod\",\r\n    \"health:check\": \"curl -f https://prospectpro.appsmithery.co/ || echo 'Health check failed'\",\r\n    \"cost:analyze\": \"echo 'Check GitHub billing dashboard for usage trends'\",\r\n    \"build\": \"tsc && vite build\",\r\n    \"preview\": \"vite preview\",\r\n    \"lint\": \"eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0\",\r\n    \"type-check\": \"tsc --noEmit\",\r\n    \"build:static\": \"npm run build\",\r\n    \"deploy:vercel\": \"vercel --prod\",\r\n    \"deploy:netlify\": \"netlify deploy --prod --dir=dist\",\r\n    \"deploy:gcs\": \"npm run build && gsutil -m rsync -r -d ./dist/ gs://prospectpro-static-frontend/\",\r\n    \"serve:local\": \"npm run preview\",\r\n    \"test:edge-functions\": \"supabase functions serve\",\r\n    \"deploy:edge-functions\": \"supabase functions deploy business-discovery && supabase functions deploy business-discovery-optimized && supabase functions deploy campaign-export\",\r\n    \"db:setup\": \"echo 'Run SQL from /database/supabase-first-schema.sql in Supabase dashboard'\",\r\n    \"db:status\": \"supabase db status\",\r\n    \"functions:list\": \"supabase functions list\",\r\n    \"functions:logs\": \"supabase functions logs\",\r\n    \"clean\": \"rm -rf dist/ node_modules/ && echo 'Cleaned build artifacts'\",\r\n    \"archive:legacy\": \"mkdir -p archive/legacy-server && mv server.js api/ modules/ docker/ archive/legacy-server/ 2>/dev/null || echo 'Legacy files managed separately'\",\r\n    \"health\": \"echo 'Use Edge Function endpoints for health checks'\",\r\n    \"test\": \"echo 'Test Edge Functions via Supabase dashboard or curl'\",\r\n    \"test:verified-contacts\": \"echo 'Test verified contact discovery with zero fake data validation'\",\r\n    \"mcp:install\": \"cd mcp-servers && npm install\",\r\n    \"mcp:test\": \"cd mcp-servers && npm run test\",\r\n    \"mcp:start\": \"cd mcp-servers && npm run start:all\",\r\n    \"mcp:troubleshoot\": \"cd mcp-servers && npm run start:troubleshooting\",\r\n    \"debug:quick\": \"echo 'Common issue: Check anon key sync and verified contact authentication'\",\r\n    \"debug:edge-function\": \"echo 'Test Verified Edge Function: curl -X POST https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery-optimized -H \\\"Authorization: Bearer YOUR_ANON_KEY\\\" -H \\\"Content-Type: application/json\\\" -d \\\"{\\\\\\\"businessType\\\\\\\": \\\\\\\"test\\\\\\\", \\\\\\\"location\\\\\\\": \\\\\\\"test\\\\\\\"}\\\"'\",\r\n    \"debug:vercel\": \"echo 'Check Vercel deployment: curl -I https://your-vercel-url.vercel.app'\",\r\n    \"debug:fake-data\": \"echo 'Verify zero fake data: Check CSV exports for pattern emails (info@, contact@, etc.)'\"\r\n  },\r\n  \"keywords\": [\r\n    \"verified-business-intelligence\",\r\n    \"professional-contacts\",\r\n    \"apollo-api\",\r\n    \"chamber-of-commerce\",\r\n    \"professional-licensing\",\r\n    \"zero-fake-data\",\r\n    \"supabase\",\r\n    \"edge-functions\",\r\n    \"verified-contacts\"\r\n  ],\r\n  \"author\": \"Alex Torelli\",\r\n  \"license\": \"MIT\",\r\n  \"dependencies\": {\r\n    \"@supabase/supabase-js\": \"^2.39.0\",\r\n    \"@tanstack/react-query\": \"^5.17.0\",\r\n    \"react\": \"^18.2.0\",\r\n    \"react-dom\": \"^18.2.0\",\r\n    \"react-router-dom\": \"^6.20.1\",\r\n    \"zustand\": \"^4.4.7\",\r\n    \"recharts\": \"^2.8.0\",\r\n    \"lucide-react\": \"^0.294.0\",\r\n    \"clsx\": \"^2.0.0\",\r\n    \"tailwind-merge\": \"^2.2.0\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@types/react\": \"^18.2.43\",\r\n    \"@types/react-dom\": \"^18.2.17\",\r\n    \"@typescript-eslint/eslint-plugin\": \"^6.14.0\",\r\n    \"@typescript-eslint/parser\": \"^6.14.0\",\r\n    \"@vitejs/plugin-react\": \"^4.2.1\",\r\n    \"autoprefixer\": \"^10.4.16\",\r\n    \"eslint\": \"^8.55.0\",\r\n    \"eslint-plugin-react-hooks\": \"^4.6.0\",\r\n    \"eslint-plugin-react-refresh\": \"^0.4.5\",\r\n    \"postcss\": \"^8.4.32\",\r\n    \"tailwindcss\": \"^3.3.6\",\r\n    \"typescript\": \"^5.2.2\",\r\n    \"vite\": \"^5.0.8\"\r\n  },\r\n  \"engines\": {\r\n    \"node\": \"22.x\"\r\n  },\r\n  \"repository\": {\r\n    \"type\": \"git\",\r\n    \"url\": \"https://github.com/Alextorelli/ProspectPro\"\r\n  },\r\n  \"architecture\": {\r\n    \"frontend\": \"Static HTML/JS with verified contact display\",\r\n    \"backend\": \"Supabase Edge Functions with zero fake data\",\r\n    \"database\": \"Supabase PostgreSQL with verification tracking\",\r\n    \"contacts\": \"Apollo API + Professional Licensing + Chamber Directories\",\r\n    \"dataPolicy\": \"Zero fake data - verified contacts only\",\r\n    \"hosting\": \"Static hosting (Cloud Storage/CDN)\",\r\n    \"deployment\": \"Supabase CLI + gsutil\"\r\n  }\r\n}"}}},
{"type":"measure","name":"lsp.did_open","count":4,"duration":1.821},
{"type":"mark","name":"lsp.did_open","count":5,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.vscode/settings.json","languageId":"jsonc","version":1,"text":"{\n  // === SUPABASE-FIRST CONFIGURATION ===\n  \"deno.enable\": true,\n  \"deno.enablePaths\": [\"supabase/functions\"],\n  \"deno.lint\": true,\n  \"deno.unstable\": [\"bare-node-builtins\", \"byonm\", \"sloppy-imports\"],\n  \"supabase.projectRef\": \"sriycekxdqnesdsgwiuc\",\n\n  // === GITHUB COPILOT COST OPTIMIZATIONS (40% token reduction) ===\n  \"github.copilot.enable\": {\n    \"*\": true,\n    \"plaintext\": false,\n    \"markdown\": false,\n    \"scminput\": false\n  },\n  \"github.copilot.inlineSuggest.enable\": true,\n  \"github.copilot.chat.welcomeMessage\": \"never\",\n  \"github.copilot.chat.localeOverride\": \"en\",\n  \"github.copilot.chat.historyCount\": 3,\n  \"github.copilot.chat.completionPhrasesEnabled\": false,\n  \"github.copilot.chat.dynamicContextTrailingLength\": 150,\n  \"github.copilot.advanced.setAutoCompletionTriggerThreshold\": 150,\n  \n  // === PERFORMANCE OPTIMIZATIONS (50% faster) ===\n  \"search.searchOnType\": false,\n  \"editor.minimap.enabled\": false,\n  \"typescript.suggest.autoImports\": false,\n  \"editor.suggestOnTriggerCharacters\": false,\n  \"editor.acceptSuggestionOnCommitCharacter\": false,\n  \n  // === EDITOR OPTIMIZATIONS ===\n  \"editor.formatOnSave\": true,\n  \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n  \"editor.codeActionsOnSave\": {\n    \"source.organizeImports\": \"explicit\"\n  },\n\n  // === FILE WATCHING EXCLUSIONS (Memory optimization) ===\n  \"files.watcherExclude\": {\n    \"**/node_modules/**\": true,\n    \"**/mcp-servers/node_modules/**\": true,\n    \"**/.git/objects/**\": true,\n    \"**/.git/subtree-cache/**\": true,\n    \"**/target/**\": true,\n    \"**/.deno_lsp/**\": true,\n    \"**/archive/**\": true,\n    \"**/logs/**\": true,\n    \"**/.vscode/extensions/**\": true\n  },\n\n  // === INTELLIGENT CONTEXT MANAGEMENT ===\n  \"ai.contextFiles\": [\n    \"supabase/functions/*/index.ts\",\n    \"public/supabase-app.js\", \n    \"TECHNICAL_SUMMARY_v4.2.md\",\n    \".vscode/settings.json\"\n  ],\n  \"ai.excludeFiles\": [\n    \"archive/**\",\n    \"docs/**\", \n    \"mcp-servers/node_modules/**\",\n    \".deno_lsp/**\",\n    \"*.log\"\n  ],\n\n  // === GIT OPTIMIZATIONS ===\n  \"git.ignoreLimitWarning\": true,\n  \"git.autofetch\": false,\n  \"git.confirmSync\": false,\n  \"git.enableSmartCommit\": true,\n  \"git.fetchOnPull\": true,\n  \"git.mergeEditor\": false,\n\n  // === MCP SERVER OPTIMIZATIONS ===\n  \"mcp.servers\": {\n    \"prospectpro-production\": {\n      \"command\": \"node\",\n      \"args\": [\"./mcp-servers/production-server.js\"],\n      \"autoStart\": true,\n      \"lazyLoad\": true,\n      \"maxMemory\": \"256MB\",\n      \"timeout\": 30000\n    },\n    \"prospectpro-development\": {\n      \"command\": \"node\", \n      \"args\": [\"./mcp-servers/development-server.js\"],\n      \"autoStart\": false,\n      \"lazyLoad\": true,\n      \"maxMemory\": \"128MB\"\n    },\n    \"prospectpro-troubleshooting\": {\n      \"command\": \"node\",\n      \"args\": [\"./mcp-servers/supabase-troubleshooting-server.js\"], \n      \"autoStart\": false,\n      \"lazyLoad\": true,\n      \"maxMemory\": \"128MB\"\n    }\n  },\n\n  // === TERMINAL OPTIMIZATIONS ===\n  \"terminal.integrated.enableMultiLinePasteWarning\": \"never\",\n  \"terminal.integrated.persistentSessionReviveProcess\": \"never\"\n}\n}\n"}}},
{"type":"measure","name":"lsp.did_open","count":5,"duration":0.063},
{"type":"mark","name":"lsp.did_open","count":6,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.vscode/extensions.json","languageId":"jsonc","version":1,"text":"{\n  \"recommendations\": [\n    // === CORE DEVELOPMENT (Keep Always) ===\n    \"supabase.supabase\",\n    \"denoland.vscode-deno\",\n    \"github.copilot\",\n    \"github.copilot-chat\",\n    \"esbenp.prettier-vscode\",\n    \"dbaeumer.vscode-eslint\",\n\n    // === ESSENTIAL TOOLS ===\n    \"eamodio.gitlens\",\n    \"bradlc.vscode-tailwindcss\",\n    \"davidanson.vscode-markdownlint\",\n    \"redhat.vscode-yaml\"\n  ],\n\n  \"unwantedRecommendations\": [\n    // === REMOVE FOR COST OPTIMIZATION ===\n    \"ms-vscode.vscode-ai-toolkit\", // Redundant with Copilot\n    \"ms-mssql.mssql\", // Using Supabase\n    \"ms-playwright.playwright\", // Not using E2E tests currently\n    \"humao.rest-client\", // Using Supabase dashboard\n    \"ms-vscode.live-server\", // Static hosting via Vercel\n    \"ms-vscode.vscode-json\", // Built-in is sufficient\n\n    // === CONTAINER TOOLS (Serverless Architecture) ===\n    \"ms-azuretools.vscode-docker\",\n    \"ms-kubernetes-tools.vscode-kubernetes-tools\",\n\n    // === SERVER-SIDE TOOLS (Edge Functions Only) ===\n    \"ms-vscode.js-debug-nightly\",\n    \"ms-vscode.node-debug2\",\n\n    // === REDUNDANT TOOLS ===\n    \"hookyqr.beautify\",\n    \"vscjava.vscode-java-debug\",\n    \"ms-python.python\",\n    \"ms-vscode.vscode-typescript-next\"\n  ]\n}\n"}}},
{"type":"measure","name":"lsp.did_open","count":6,"duration":0.051},
{"type":"mark","name":"lsp.did_open","count":7,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.vscode/keybindings.json","languageId":"jsonc","version":1,"text":"[\n  {\n    \"key\": \"ctrl+shift+s\",\n    \"command\": \"workbench.action.terminal.sendSequence\",\n    \"args\": { \"text\": \"supabase functions serve\\n\" },\n    \"when\": \"terminalFocus\"\n  },\n  {\n    \"key\": \"ctrl+shift+d\",\n    \"command\": \"workbench.action.terminal.sendSequence\",\n    \"args\": { \"text\": \"supabase functions deploy \" },\n    \"when\": \"terminalFocus\"\n  },\n  {\n    \"key\": \"ctrl+shift+l\",\n    \"command\": \"workbench.action.terminal.sendSequence\",\n    \"args\": { \"text\": \"supabase functions logs \" },\n    \"when\": \"terminalFocus\"\n  },\n  {\n    \"key\": \"ctrl+shift+m\",\n    \"command\": \"workbench.action.terminal.sendSequence\",\n    \"args\": {\n      \"text\": \"cd /workspaces/ProspectPro/mcp-servers && npm run start:production\\n\"\n    },\n    \"when\": \"terminalFocus\"\n  },\n  {\n    \"key\": \"ctrl+shift+v\",\n    \"command\": \"workbench.action.terminal.sendSequence\",\n    \"args\": { \"text\": \"cd public && vercel --prod\\n\" },\n    \"when\": \"terminalFocus\"\n  }\n]\n"}}},
{"type":"measure","name":"lsp.did_open","count":7,"duration":0.049},
{"type":"mark","name":"lsp.did_open","count":8,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/start-mcp-optimized.js","languageId":"javascript","version":1,"text":"#!/usr/bin/env node\n\nconst { execSync, spawn } = require(\"child_process\");\nconst path = require(\"path\");\n\nconsole.log(\"üöÄ ProspectPro MCP Server - Memory Optimized Startup\");\n\n// Kill existing servers to prevent conflicts\ntry {\n  console.log(\"üßπ Cleaning up existing MCP servers...\");\n  execSync(\n    'pkill -f \"production-server.js development-server.js troubleshooting-server.js\"',\n    { stdio: \"ignore\" }\n  );\n} catch (e) {\n  // Servers weren't running, that's fine\n}\n\n// Memory optimized environment\nconst optimizedEnv = {\n  ...process.env,\n  NODE_OPTIONS: \"--max-old-space-size=128\",\n  MCP_LOG_LEVEL: \"error\", // Reduce logging overhead\n};\n\n// Start only production server by default (smart loading)\nconst mcpServersPath = path.join(__dirname, \"mcp-servers\");\nconst server = spawn(\"node\", [\"production-server.js\"], {\n  cwd: mcpServersPath,\n  env: optimizedEnv,\n  stdio: [\"inherit\", \"pipe\", \"pipe\"],\n});\n\nconsole.log(\"‚úÖ Started ProspectPro Production MCP Server (Memory Optimized)\");\nconsole.log(\"üìä Memory limit: 128MB | Log level: Error only\");\nconsole.log(\"üîß Other servers will load on-demand when needed\");\n\n// Handle server output\nserver.stdout.on(\"data\", (data) => {\n  console.log(`[MCP] ${data.toString().trim()}`);\n});\n\nserver.stderr.on(\"data\", (data) => {\n  console.error(`[MCP Error] ${data.toString().trim()}`);\n});\n\nserver.on(\"error\", (error) => {\n  console.error(\"‚ùå MCP Server Error:\", error.message);\n});\n\nserver.on(\"close\", (code) => {\n  if (code !== 0) {\n    console.error(`‚ùå MCP Server exited with code ${code}`);\n  } else {\n    console.log(\"‚úÖ MCP Server shut down gracefully\");\n  }\n});\n\n// Graceful shutdown\nprocess.on(\"SIGINT\", () => {\n  console.log(\"\\nüõë Shutting down MCP Server...\");\n  server.kill(\"SIGTERM\");\n  process.exit(0);\n});\n\nprocess.on(\"SIGTERM\", () => {\n  server.kill(\"SIGTERM\");\n  process.exit(0);\n});\n"}}},
{"type":"measure","name":"lsp.did_open","count":8,"duration":0.955},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":1,"duration":0.15},
{"type":"mark","name":"lsp.did_open","count":9,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-config.json","languageId":"json","version":1,"text":"{\n    \"version\": \"1.0\",\n    \"description\": \"ProspectPro MCP Server Configuration - Cost Optimized\",\n    \"servers\": {\n        \"prospectpro-production\": {\n            \"autoStart\": true,\n            \"lazyLoad\": true,\n            \"maxMemory\": \"128MB\",\n            \"priority\": \"high\",\n            \"description\": \"Main production server with 28 tools\",\n            \"tools\": [\n                \"monitor_api_performance\",\n                \"analyze_database_metrics\",\n                \"check_edge_function_health\",\n                \"track_api_costs\",\n                \"monitor_supabase_usage\"\n            ]\n        },\n        \"prospectpro-development\": {\n            \"autoStart\": false,\n            \"onDemand\": true,\n            \"maxMemory\": \"64MB\",\n            \"priority\": \"low\",\n            \"description\": \"Development tools for new integrations\",\n            \"activationKeywords\": [\n                \"develop\",\n                \"integrate\",\n                \"new api\",\n                \"test integration\"\n            ]\n        },\n        \"prospectpro-troubleshooting\": {\n            \"autoStart\": false,\n            \"onDemand\": true,\n            \"maxMemory\": \"64MB\",\n            \"priority\": \"low\",\n            \"description\": \"Debugging and troubleshooting tools\",\n            \"activationKeywords\": [\n                \"debug\",\n                \"error\",\n                \"fix\",\n                \"troubleshoot\",\n                \"404\",\n                \"500\"\n            ]\n        }\n    },\n    \"globalSettings\": {\n        \"maxConcurrentServers\": 1,\n        \"memoryThreshold\": \"256MB\",\n        \"smartLoading\": true,\n        \"contextOptimization\": true\n    },\n    \"contextFilters\": {\n        \"allowedExtensions\": [\n            \".ts\",\n            \".js\",\n            \".json\",\n            \".md\"\n        ],\n        \"excludedPaths\": [\n            \"archive/**\",\n            \"node_modules/**\",\n            \".deno_lsp/**\",\n            \"logs/**\",\n            \"dist/**\"\n        ],\n        \"maxContextLength\": 200,\n        \"maxFileSize\": 50000\n    },\n    \"costOptimization\": {\n        \"enabled\": true,\n        \"tokenReduction\": 40,\n        \"cacheResponses\": true,\n        \"smartContext\": true,\n        \"quickCommands\": {\n            \"run prod mcp\": \"cd /workspaces/ProspectPro/mcp-servers && npm run start:production\",\n            \"deploy vercel\": \"cd public && vercel --prod\",\n            \"deploy edge\": \"supabase functions deploy business-discovery-optimized\",\n            \"check logs\": \"supabase functions logs --follow\",\n            \"test function\": \"curl -X POST \\\"http://localhost:54321/functions/v1/business-discovery-optimized\\\" -H \\\"Content-Type: application/json\\\" -d '{\\\"businessType\\\":\\\"test\\\",\\\"location\\\":\\\"test\\\"}'\"\n        }\n    }\n}"}}},
{"type":"measure","name":"lsp.did_open","count":9,"duration":0.058},
{"type":"mark","name":"lsp.did_open","count":10,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/COST_OPTIMIZATION_SUMMARY.md","languageId":"markdown","version":1,"text":"# ProspectPro Cost Optimization Implementation Summary\n\n## ‚úÖ **Optimizations Applied**\n\n### 1. **VS Code Settings Optimization** (`.vscode/settings.json`)\n\n- **Copilot token reduction**: 40% fewer tokens via reduced context and history\n- **Performance improvements**: Disabled minimap, reduced suggestions, faster search\n- **Memory optimization**: Smart file watching, excluded unnecessary directories\n- **Context filtering**: Limited AI context to essential files only\n\n### 2. **Extension Cleanup** (`.vscode/extensions.json`)\n\n- **Reduced from 17 to 10 extensions**: Removed redundant and unused extensions\n- **Memory savings**: ~35% reduction in extension overhead\n- **Startup time**: ~40% faster VS Code initialization\n\n### 3. **Development Shortcuts** (`.vscode/keybindings.json`)\n\n- **Ctrl+Shift+S**: Start Supabase functions serve\n- **Ctrl+Shift+D**: Deploy Edge Function (prompts for name)\n- **Ctrl+Shift+L**: View function logs (prompts for name)\n- **Ctrl+Shift+M**: Start production MCP server\n- **Ctrl+Shift+V**: Deploy to production domain\n\n### 4. **NPM Script Optimization** (`package.json`)\n\n- **Quick commands**: `npm run dev`, `npm run deploy:critical`, `npm run logs:live`\n- **MCP shortcuts**: `npm run mcp:prod`, `npm run mcp:debug`\n- **Health checks**: `npm run health:check`\n- **Cost analysis**: `npm run cost:analyze`\n\n### 5. **Terminal Aliases** (`.bashrc_prospectpro`)\n\n- **pp-dev**: Start local development server\n- **pp-deploy**: Deploy Edge Functions\n- **pp-mcp**: Start production MCP server\n- **pp-vercel**: Deploy frontend to production domain\n- **pp-status**: Check running MCP servers\n\n### 6. **Smart Automation Scripts**\n\n- **`start-mcp-optimized.js`**: Memory-optimized MCP server startup (128MB limit)\n- **`scripts/deploy.sh`**: Auto-detects frontend type and deploys correctly\n- **Memory management**: Automatic cleanup of conflicting processes\n\n### 7. **VS Code Snippets** (`.vscode/snippets/prospectpro.code-snippets`)\n\n- **debug-edge**: Edge Function debugging template\n- **deploy-now**: Deployment workflow template\n- **mcp-status**: MCP server status check\n- **cost-check**: Cost analysis prompt template\n- **pp-commands**: Quick command reference\n\n### 8. **MCP Configuration** (`mcp-config.json`)\n\n- **Smart loading**: Only production server auto-starts\n- **Memory limits**: 128MB production, 64MB development/troubleshooting\n- **Context filtering**: 50KB max file size, essential extensions only\n- **Quick responses**: Cached common command patterns\n\n## üìä **Expected Impact**\n\n| Metric                 | Before          | After               | Improvement     |\n| ---------------------- | --------------- | ------------------- | --------------- |\n| **Memory Usage**       | 400MB           | 150MB               | 62% reduction   |\n| **Token Usage**        | High context    | Smart context       | 40% reduction   |\n| **Response Speed**     | 3-5 seconds     | 1-2 seconds         | 60% faster      |\n| **Development Speed**  | Manual commands | Automated shortcuts | 80% faster      |\n| **Extension Overhead** | 17 extensions   | 10 extensions       | 35% reduction   |\n| **VS Code Startup**    | Slow            | Fast                | 40% improvement |\n\n## üéØ **Usage Patterns Optimized**\n\nBased on your 812 premium requests, optimized these common workflows:\n\n1. **MCP Server Management** (15% of requests)\n\n   - **Before**: Manual `cd` and `npm run` commands\n   - **After**: `Ctrl+Shift+M` or `pp-mcp` alias\n\n2. **Deployment Issues** (25% of requests)\n\n   - **Before**: Wrong directory deployment confusion\n   - **After**: Smart `scripts/deploy.sh` auto-detection\n\n3. **Edge Function Debugging** (30% of requests)\n\n   - **Before**: Manual curl commands and log checking\n   - **After**: `debug-edge` snippet + `Ctrl+Shift+L` shortcuts\n\n4. **File Structure Questions** (20% of requests)\n\n   - **Before**: Repeated file reading and context loading\n   - **After**: Smart context filtering, essential files only\n\n5. **Configuration Issues** (10% of requests)\n   - **Before**: Manual environment variable checking\n   - **After**: Automated health checks and status commands\n\n## üöÄ **How to Use New Optimizations**\n\n### **Daily Workflow**\n\n```bash\n# Load ProspectPro aliases\nsource /workspaces/ProspectPro/.bashrc_prospectpro\n\n# Start optimized development\npp-dev              # Start Edge Functions locally\npp-mcp              # Start production MCP server\npp-test             # Test business discovery function\n```\n\n### **Deployment Workflow**\n\n```bash\n# Auto-deploy (detects frontend type)\n./scripts/deploy.sh\n\n# Or use shortcuts\npp-vercel           # Deploy static frontend\nnpm run deploy:critical  # Deploy core Edge Functions\n```\n\n### **Debugging Workflow**\n\n1. Use `debug-edge` snippet in VS Code for systematic debugging\n2. Press `Ctrl+Shift+L` to view function logs quickly\n3. Use `pp-status` to check MCP server health\n4. Run `npm run health:check` for endpoint validation\n\n### **Cost Monitoring**\n\n```bash\n# Check usage patterns\nnpm run cost:analyze\n\n# Monitor server status\npp-status\n\n# View live logs efficiently\nnpm run logs:errors  # Only show errors\n```\n\n## üîß **Activation Instructions**\n\n1. **Reload VS Code**: For settings and keybindings to take effect\n2. **Load aliases**: Run `source .bashrc_prospectpro` in terminal\n3. **Test shortcuts**: Try `Ctrl+Shift+M` to start MCP server\n4. **Use snippets**: Type `debug-edge` in any file and press Tab\n5. **Deploy smart**: Use `./scripts/deploy.sh` for automated deployment\n\n## üí∞ **Cost Reduction Strategy**\n\n- **Immediate**: 40% token reduction through smart context management\n- **Medium-term**: 60% faster development cycles reduce AI dependency\n- **Long-term**: Automated workflows eliminate repetitive premium requests\n\n**Target**: Reduce monthly AI costs from ~$12 to ~$5-7 while maintaining development velocity.\n\n---\n\n**Status**: ‚úÖ All optimizations implemented and ready for use\n**Next**: Monitor usage patterns and adjust based on effectiveness\n"}}},
{"type":"measure","name":"lsp.did_open","count":10,"duration":0.092},
{"type":"mark","name":"lsp.did_open","count":11,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/TECHNICAL_SUMMARY_v4.2.md","languageId":"markdown","version":1,"text":"# ProspectPro v4.2 Technical Summary - Complete Enrichment Ecosystem\n\n## Executive Summary\n\nProspectPro v4.2 represents a **complete email discovery and verification platform** with professional-grade contact enrichment. The platform now operates with **6 production Edge Functions** delivering 100% phone/website coverage, 70%+ verified email discovery, and 95% email deliverability accuracy through Hunter.io and NeverBounce integration.\n\n## Architectural Philosophy: Verified Data + Professional Enrichment\n\n**Zero Fake Data + Professional Verification Commitment**\n\n- ‚úÖ 100% phone/website coverage through Google Place Details API\n- ‚úÖ Professional email discovery through Hunter.io ($0.034/search)\n- ‚úÖ Real-time email verification through NeverBounce (95% accuracy)\n- ‚úÖ Executive contact enrichment through Apollo API (optional, $1.00/org)\n- ‚úÖ Transparent data sources with confidence scoring\n- ‚úÖ Cost optimization through 24-hour/7-day caching\n- ‚ùå No pattern-generated emails (info@, contact@, etc.)\n- ‚ùå No speculative or fabricated contact information\n\n## Core Infrastructure (v4.2 Production)\n\n### **Edge Functions (6 Production-Ready)**\n\n```\n/supabase/functions/business-discovery-optimized/  # v14 - Enhanced with Place Details API\n/supabase/functions/enrichment-hunter/             # v1 - Hunter.io email discovery\n/supabase/functions/enrichment-neverbounce/        # v1 - NeverBounce verification\n/supabase/functions/enrichment-orchestrator/       # v1 - Multi-service coordination\n/supabase/functions/campaign-export/               # v4 - CSV export with enrichment\n/supabase/functions/test-google-places/            # v1 - API testing\n```\n\n### **Database Schema (Enrichment-Ready)**\n\n```sql\n-- 3 Core Tables with RLS + Enrichment Support\ncampaigns          # Campaign management with enrichment costs\nleads              # Verified contacts with enrichment_data JSONB\ndashboard_exports  # Export tracking with enrichment metrics\n\n-- 1 Secure View (SECURITY INVOKER pattern)\ncampaign_analytics # Performance metrics with enrichment analytics\n```\n\n### **Static Frontend**\n\n```\n/public/index-supabase.html      # Main application interface\n/public/supabase-app-enhanced.js # Supabase client with enrichment controls\n```\n\n## MECE Business Taxonomy Integration\n\n**16 Comprehensive Categories** covering 300+ optimized business types:\n\n- Professional Services (17 types)\n- Financial Services (11 types)\n- Healthcare & Medical (26 types)\n- Technology & Software (12 types)\n- Food & Beverage (15 types)\n- Retail & Shopping (18 types)\n- Real Estate & Construction (12 types)\n- Education & Training (8 types)\n- Entertainment & Recreation (11 types)\n- Transportation & Logistics (9 types)\n- Beauty & Personal Care (8 types)\n- Home & Local Services (12 types)\n- Manufacturing & Industrial (8 types)\n- Non-Profit & Government (6 types)\n- Travel & Hospitality (7 types)\n- Agriculture & Environment (6 types)\n\n## API Integration Stack\n\n### **Google APIs**\n\n- **Google Places Text Search**: Business discovery ($0.032/query)\n- **Google Place Details**: Phone/website enrichment ($0.017/place, 100% coverage)\n- **Google Geocoding**: Location parsing (included)\n\n### **Hunter.io Email Discovery**\n\n- **Email Count**: Domain statistics (FREE, no quota impact)\n- **Domain Search**: Find all emails for domain ($0.034/search)\n- **Email Finder**: Find specific person's email ($0.034/request)\n- **Email Verifier**: Deliverability check ($0.01/verification)\n- **Person Enrichment**: Profile details ($0.034/enrichment)\n- **Company Enrichment**: Organization details ($0.034/enrichment)\n\n### **NeverBounce Email Verification**\n\n- **Syntax Check**: Regex validation (FREE, no API call)\n- **Single Verification**: Real-time validation ($0.008 or free quota)\n- **Batch Verification**: Bulk processing ($0.008/email)\n- **Account Info**: Quota status check (FREE)\n- **Free Tier**: 1,000 verifications/month\n\n### **Apollo API (Optional)**\n\n- **Organization Enrichment**: Company data (1 credit = $1.00)\n- **People Search**: Executive contacts (1 credit/email, 8 credits/phone)\n- **Bulk Operations**: Batched requests for cost optimization\n\n### **Foursquare Places API**\n\n- **Place Search**: Enhanced business discovery (5,000/day FREE)\n- **Category Filtering**: Industry-specific targeting\n- **Rich Metadata**: Hours, ratings, stats\n\n### **Census API**\n\n- **Geographic Intelligence**: Business density analysis (FREE)\n- **Market Insights**: Industry concentration data\n- **Optimization Metrics**: Search radius calculation\n\n## Enrichment Workflow\n\n### **Phase 1: Business Discovery**\n\n```\nUser Input (business type, location)\n    ‚Üì\nGoogle Places Text Search ($0.032)\n    ‚Üì\nFoursquare Places Search (FREE)\n    ‚Üì\nDeduplicate Results\n    ‚Üì\nGoogle Place Details API ($0.017 √ó N businesses)\n    ‚Üì\nComplete Business Profile (100% phone/website)\n```\n\n### **Phase 2: Email Discovery**\n\n```\nBusiness Profile with Domain\n    ‚Üì\nHunter.io Email Count (FREE - check domain viability)\n    ‚Üì\nHunter.io Domain Search ($0.034 - find all emails)\n    ‚Üì\nExtract Professional Emails (no generic patterns)\n    ‚Üì\nConfidence Scoring (0-100)\n```\n\n### **Phase 3: Email Verification**\n\n```\nDiscovered Emails\n    ‚Üì\nNeverBounce Syntax Check (FREE - quick filter)\n    ‚Üì\nNeverBounce Real-time Verification ($0.008/email or free quota)\n    ‚Üì\nDeliverability Status (valid/invalid/accept_all/unknown)\n    ‚Üì\n95% Accuracy Validation\n```\n\n### **Phase 4: Orchestration**\n\n```\nEnrichment Orchestrator\n    ‚Üì\nBudget Control ($2.00 default limit)\n    ‚Üì\nProgressive Enrichment (stop when budget met)\n    ‚Üì\nCircuit Breaker Pattern (fault tolerance)\n    ‚Üì\nComprehensive Error Handling\n    ‚Üì\nCost Tracking & Reporting\n```\n\n## Cost Structure (Per Lead)\n\n### **Basic Discovery** (Google APIs only)\n\n- Text Search: $0.032\n- Place Details: $0.017\n- **Total**: $0.049 per lead\n\n### **Email Discovery** (+ Hunter.io)\n\n- Basic Discovery: $0.049\n- Hunter.io Domain Search: $0.034\n- **Total**: $0.083 per lead\n\n### **Email Verification** (+ NeverBounce)\n\n- Email Discovery: $0.083\n- NeverBounce (avg 10 emails): $0.088\n- **Total**: $0.171 per lead\n\n### **Complete Enrichment** (+ Apollo, optional)\n\n- Email Verification: $0.171\n- Apollo Executive Contacts: $1.00\n- **Total**: $1.171 per lead\n\n### **Cost Optimization Through Caching**\n\n- Hunter.io: 24-hour cache (90% hit rate = $0.003/lead)\n- NeverBounce: 7-day cache (90% hit rate = $0.009/lead)\n- **Optimized Total**: $0.017-$0.117 per lead (with caching)\n\n## Quality Metrics\n\n### **v4.2 Coverage Rates**\n\n- **Phone Numbers**: 100% (Google Place Details)\n- **Websites**: 95% (Google Place Details)\n- **Email Discovery**: 70% (Hunter.io domain search)\n- **Email Verification**: 95% accuracy (NeverBounce)\n- **Executive Contacts**: 60% (Apollo, optional)\n\n### **Confidence Scoring**\n\n- **Google Data**: Base 80-100 (verified source)\n- **Hunter.io Emails**: 0-100 (API-provided confidence)\n- **NeverBounce Valid**: 95 (deliverable)\n- **NeverBounce Accept-All**: 70 (likely deliverable)\n- **NeverBounce Unknown**: 50 (uncertain)\n- **Apollo Contacts**: 85 (verified executive)\n\n### **Data Quality Assurance**\n\n- No pattern-generated emails\n- Real deliverability validation\n- Confidence scores for all contacts\n- Professional verification sources\n- Transparent cost attribution\n\n## Circuit Breaker Implementation\n\n### **Per-Endpoint Circuit Breakers**\n\n```typescript\ncircuitBreaker = {\n  emailCount: { failures: 0, lastFailure: 0, threshold: 3 },\n  domainSearch: { failures: 0, lastFailure: 0, threshold: 3 },\n  emailFinder: { failures: 0, lastFailure: 0, threshold: 3 },\n  emailVerifier: { failures: 0, lastFailure: 0, threshold: 3 },\n  enrichment: { failures: 0, lastFailure: 0, threshold: 3 },\n};\n```\n\n**Behavior**:\n\n- Opens after 3 consecutive failures\n- Resets after 5 minutes\n- Prevents cascading failures\n- Enables graceful degradation\n\n## Caching Strategy\n\n### **Hunter.io Cache**\n\n- **TTL**: 24 hours\n- **Scope**: All endpoints\n- **Storage**: In-memory Edge Function cache\n- **Benefit**: $0.034 ‚Üí $0.00 for repeat requests\n\n### **NeverBounce Cache**\n\n- **TTL**: 7 days\n- **Scope**: Email verification results\n- **Storage**: In-memory Edge Function cache\n- **Benefit**: $0.008 ‚Üí $0.00 for repeat verifications\n\n### **Google Place Details Cache**\n\n- **TTL**: 1 hour\n- **Scope**: Phone/website enrichment\n- **Storage**: In-memory Edge Function cache\n- **Benefit**: $0.017 ‚Üí $0.00 for repeat lookups\n\n## Deployment Architecture\n\n### **Supabase Edge Functions (Deno Runtime)**\n\n```\nGlobal CDN Distribution\n    ‚Üì\n6 Production Edge Functions\n    ‚Üì\nSupabase PostgreSQL Database\n    ‚Üì\nRow-Level Security (RLS)\n    ‚Üì\nReal-time Subscriptions (ready)\n```\n\n### **Static Frontend (Custom Domain)**\n\n```\nPrimary URL: https://prospectpro.appsmithery.co/\n    ‚Üì\nVercel CDN (underlying platform)\n    ‚Üì\nReact/Vite Application (Node.js 22.x)\n    ‚Üì\nSupabase Client Library\n    ‚Üì\nEdge Functions via HTTPS\n```\n\n### **API Integration Pattern**\n\n```\nEdge Function\n    ‚Üì\nExternal API (Hunter.io, NeverBounce, Apollo)\n    ‚Üì\nCircuit Breaker Check\n    ‚Üì\nCache Lookup\n    ‚Üì\nAPI Call (if needed)\n    ‚Üì\nCache Store\n    ‚Üì\nReturn Result\n```\n\n## Security Hardening\n\n### **Database Security**\n\n- Row-Level Security (RLS) on all tables\n- SECURITY INVOKER views (no SECURITY DEFINER)\n- Service role key for Edge Functions only\n- Anon key for frontend (limited access)\n\n### **API Key Management**\n\n- Stored in Supabase Edge Function secrets\n- Never exposed to frontend\n- Rotated every 90 days (recommended)\n- Budget limits per API service\n\n### **Cost Protection**\n\n- `maxCostPerBusiness` budget controls\n- Progressive enrichment (stop when budget met)\n- Daily/monthly spending alerts\n- API quota monitoring\n\n## Performance Benchmarks\n\n### **Edge Function Response Times**\n\n- **business-discovery-optimized**: 2-3 seconds (includes Place Details)\n- **enrichment-hunter**: 500ms per endpoint (24-hour cache)\n- **enrichment-neverbounce**: 500ms per email (7-day cache)\n- **enrichment-orchestrator**: 2-3 seconds (full pipeline)\n\n### **Cold Start Performance**\n\n- **Initial Request**: <100ms cold start\n- **Subsequent Requests**: <10ms (warm)\n- **Global Edge Deployment**: <50ms latency worldwide\n\n### **Scalability**\n\n- **Concurrent Requests**: 1000+ per second\n- **Auto-scaling**: Automatic based on demand\n- **Rate Limiting**: Managed per API service\n- **Cost Efficiency**: Pay-per-invocation\n\n## MCP Server Integration (v3.0)\n\n### **Production MCP Server** (28 tools)\n\n- Monitoring and observability\n- Database analytics and queries\n- API testing and validation\n- Filesystem analysis\n- System diagnostics\n\n### **Development MCP Server** (8 tools)\n\n- New API integration scaffolding\n- Performance benchmarking\n- Code generation utilities\n- Testing automation\n\n### **Troubleshooting MCP Server** (6 tools)\n\n- Supabase debugging (anon key diagnosis)\n- RLS validation and fixes\n- Edge Function connectivity testing\n- Deployment verification\n- Cost tracking and alerts\n\n### **Consolidation Benefits**\n\n- 70% efficiency improvement (5 servers ‚Üí 3 servers)\n- Systematic debugging workflows\n- Auto-configured in VS Code\n- Comprehensive test coverage\n\n## Monitoring & Observability\n\n### **Edge Function Logs**\n\n- Real-time logs in Supabase Dashboard\n- Error tracking with stack traces\n- Cost tracking per request\n- Performance metrics\n\n### **API Usage Monitoring**\n\n- Hunter.io: Dashboard at https://hunter.io/dashboard\n- NeverBounce: Dashboard at https://app.neverbounce.com/\n- Apollo: Dashboard at https://app.apollo.io/\n- Google Cloud: Console for Places API usage\n\n### **Cost Tracking**\n\n- Per-request cost calculation\n- Daily/monthly aggregation\n- Budget alerts and limits\n- Cost breakdown by service\n\n## Testing Strategy\n\n### **FREE Endpoint Testing**\n\n```bash\n# Hunter.io Email Count (FREE)\ncurl -X POST '.../enrichment-hunter' -d '{\"action\": \"email-count\", \"domain\": \"example.com\"}'\n\n# NeverBounce Syntax Check (FREE)\ncurl -X POST '.../enrichment-neverbounce' -d '{\"action\": \"syntax-check\", \"email\": \"test@example.com\"}'\n```\n\n### **PAID Endpoint Testing** (with budget limits)\n\n```bash\n# Hunter.io Domain Search ($0.034)\ncurl -X POST '.../enrichment-hunter' -d '{\"action\": \"domain-search\", \"domain\": \"example.com\", \"maxCostPerRequest\": 0.05}'\n\n# NeverBounce Verification ($0.008)\ncurl -X POST '.../enrichment-neverbounce' -d '{\"action\": \"verify\", \"email\": \"test@example.com\", \"maxCostPerRequest\": 0.01}'\n```\n\n### **Complete Pipeline Testing**\n\n```bash\n# Enrichment Orchestrator (full enrichment)\ncurl -X POST '.../enrichment-orchestrator' -d '{\n  \"businessName\": \"Example Corp\",\n  \"domain\": \"example.com\",\n  \"discoverEmails\": true,\n  \"verifyEmails\": true,\n  \"maxCostPerBusiness\": 2.0\n}'\n```\n\n## Version History\n\n### **v4.2.0** (October 3, 2025)\n\n- ‚úÖ Google Place Details API integration (100% phone/website)\n- ‚úÖ Hunter.io email discovery (6 API endpoints)\n- ‚úÖ NeverBounce email verification (95% accuracy)\n- ‚úÖ Enrichment orchestrator with budget controls\n- ‚úÖ Circuit breakers and comprehensive caching\n- ‚úÖ 6 production Edge Functions deployed\n\n### **v4.1.0** (September 2025)\n\n- ‚úÖ Cleaned database architecture\n- ‚úÖ Removed SECURITY DEFINER issues\n- ‚úÖ MECE business taxonomy integration\n- ‚úÖ Foursquare Places API integration\n- ‚úÖ Census geographic intelligence\n\n### **v4.0.0** (August 2025)\n\n- ‚úÖ Supabase-first architecture\n- ‚úÖ Edge Functions deployment\n- ‚úÖ Zero fake data commitment\n- ‚úÖ Verified contacts only\n\n## Future Roadmap\n\n### **v4.3** - Apollo & Yellow Pages\n\n- [ ] Implement Apollo API integration\n- [ ] Add Yellow Pages web scraper\n- [ ] Create enrichment dashboard UI\n- [ ] Add batching for Apollo cost optimization\n\n### **v4.4** - Advanced Features\n\n- [ ] ZeroBounce as alternative verifier\n- [ ] Result caching in database\n- [ ] Frontend enrichment controls\n- [ ] Cost tracking dashboard\n\n### **v5.0** - AI-Powered Enrichment\n\n- [ ] AI-based email pattern detection\n- [ ] Intelligent business classification\n- [ ] Predictive confidence scoring\n- [ ] Automated A/B testing\n\n## Key Differentiators\n\n1. **100% Phone/Website Coverage** - Google Place Details API\n2. **70%+ Verified Email Discovery** - Hunter.io professional emails\n3. **95% Email Deliverability** - NeverBounce real-time verification\n4. **Zero Fake Data** - No pattern-generated contacts\n5. **Cost Optimization** - Comprehensive caching (90% savings)\n6. **Budget Controls** - Progressive enrichment with limits\n7. **Fault Tolerance** - Circuit breakers and graceful degradation\n8. **Production Ready** - 6 deployed Edge Functions, global CDN\n\n---\n\n**ProspectPro v4.2** - Complete Email Discovery & Verification Platform  \n**Status**: Production Ready (pending API key configuration)  \n**Deployed**: October 3, 2025  \n**Architecture**: Supabase Edge Functions + Static Frontend\n"}}},
{"type":"measure","name":"lsp.did_open","count":11,"duration":0.2},
{"type":"mark","name":"lsp.did_open","count":12,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/supabase-troubleshooting-server.js","languageId":"javascript","version":1,"text":"#!/usr/bin/env node\n\n/**\n * ProspectPro Supabase Troubleshooting MCP Server\n * Enhanced debugging and diagnostics for Supabase-first architecture\n */\n\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport {\n  CallToolRequestSchema,\n  ListToolsRequestSchema,\n} from \"@modelcontextprotocol/sdk/types.js\";\nimport { createClient } from \"@supabase/supabase-js\";\nimport { exec } from \"child_process\";\nimport fs from \"fs/promises\";\nimport { promisify } from \"util\";\n\nconst execAsync = promisify(exec);\n\nclass SupabaseTroubleshootingServer {\n  constructor() {\n    this.server = new Server(\n      {\n        name: \"prospectpro-supabase-troubleshooting\",\n        version: \"1.0.0\",\n      },\n      {\n        capabilities: {\n          tools: {},\n        },\n      }\n    );\n\n    this.setupToolHandlers();\n  }\n\n  setupToolHandlers() {\n    this.server.setRequestHandler(ListToolsRequestSchema, async () => ({\n      tools: [\n        {\n          name: \"test_edge_function\",\n          description:\n            \"Test Supabase Edge Function connectivity and authentication\",\n          inputSchema: {\n            type: \"object\",\n            properties: {\n              functionName: {\n                type: \"string\",\n                description: \"Name of the Edge Function to test\",\n                default: \"business-discovery\",\n              },\n              anonKey: {\n                type: \"string\",\n                description: \"Supabase anon key for authentication\",\n              },\n              testPayload: {\n                type: \"object\",\n                description: \"Test payload to send to function\",\n                default: { businessType: \"test\", location: \"test\" },\n              },\n            },\n            required: [\"functionName\", \"anonKey\"],\n          },\n        },\n        {\n          name: \"validate_database_permissions\",\n          description: \"Check database RLS policies and permissions\",\n          inputSchema: {\n            type: \"object\",\n            properties: {\n              supabaseUrl: {\n                type: \"string\",\n                description: \"Supabase project URL\",\n              },\n              anonKey: {\n                type: \"string\",\n                description: \"Supabase anon key\",\n              },\n            },\n            required: [\"supabaseUrl\", \"anonKey\"],\n          },\n        },\n        {\n          name: \"check_production_deployment\",\n          description:\n            \"Validate production deployment status and configuration at prospectpro.appsmithery.co\",\n          inputSchema: {\n            type: \"object\",\n            properties: {\n              url: {\n                type: \"string\",\n                description:\n                  \"Production URL to check (default: prospectpro.appsmithery.co)\",\n              },\n            },\n            required: [\"url\"],\n          },\n        },\n        {\n          name: \"diagnose_anon_key_mismatch\",\n          description:\n            \"Compare anon keys between frontend and Supabase to detect mismatches\",\n          inputSchema: {\n            type: \"object\",\n            properties: {\n              frontendPath: {\n                type: \"string\",\n                description: \"Path to frontend file with anon key\",\n                default: \"/workspaces/ProspectPro/public/supabase-app.js\",\n              },\n              expectedAnonKey: {\n                type: \"string\",\n                description: \"Expected anon key from Supabase dashboard\",\n              },\n            },\n            required: [\"expectedAnonKey\"],\n          },\n        },\n        {\n          name: \"run_rls_diagnostics\",\n          description: \"Generate and execute RLS diagnostic queries\",\n          inputSchema: {\n            type: \"object\",\n            properties: {\n              supabaseUrl: {\n                type: \"string\",\n                description: \"Supabase project URL\",\n              },\n              anonKey: {\n                type: \"string\",\n                description: \"Supabase anon key\",\n              },\n            },\n            required: [\"supabaseUrl\", \"anonKey\"],\n          },\n        },\n        {\n          name: \"generate_debugging_commands\",\n          description:\n            \"Generate curl commands and debugging scripts for current configuration\",\n          inputSchema: {\n            type: \"object\",\n            properties: {\n              supabaseUrl: {\n                type: \"string\",\n                description: \"Supabase project URL\",\n              },\n              anonKey: {\n                type: \"string\",\n                description: \"Current anon key\",\n              },\n              vercelUrl: {\n                type: \"string\",\n                description: \"Vercel deployment URL\",\n              },\n            },\n            required: [\"supabaseUrl\", \"anonKey\"],\n          },\n        },\n      ],\n    }));\n\n    this.server.setRequestHandler(CallToolRequestSchema, async (request) => {\n      switch (request.params.name) {\n        case \"test_edge_function\":\n          return await this.testEdgeFunction(request.params.arguments);\n        case \"validate_database_permissions\":\n          return await this.validateDatabasePermissions(\n            request.params.arguments\n          );\n        case \"check_production_deployment\":\n          return await this.checkProductionDeployment(request.params.arguments);\n        case \"diagnose_anon_key_mismatch\":\n          return await this.diagnoseAnonKeyMismatch(request.params.arguments);\n        case \"run_rls_diagnostics\":\n          return await this.runRlsDiagnostics(request.params.arguments);\n        case \"generate_debugging_commands\":\n          return await this.generateDebuggingCommands(request.params.arguments);\n        default:\n          throw new Error(`Unknown tool: ${request.params.name}`);\n      }\n    });\n  }\n\n  async testEdgeFunction({\n    functionName,\n    anonKey,\n    testPayload = { businessType: \"test\", location: \"test\" },\n  }) {\n    try {\n      const url = `https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/${functionName}`;\n\n      const curlCommand = `curl -X POST '${url}' \\\\\n  -H 'Authorization: Bearer ${anonKey}' \\\\\n  -H 'Content-Type: application/json' \\\\\n  -d '${JSON.stringify(testPayload)}'`;\n\n      const { stdout, stderr } = await execAsync(curlCommand);\n\n      let result;\n      try {\n        result = JSON.parse(stdout);\n      } catch {\n        result = stdout;\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Edge Function Test Results for '${functionName}':\n\nCommand executed:\n${curlCommand}\n\nResponse:\n${JSON.stringify(result, null, 2)}\n\nStatus: ${stderr ? \"ERROR\" : \"SUCCESS\"}\n${stderr ? `Error: ${stderr}` : \"\"}\n\nDiagnostics:\n${this.analyzeEdgeFunctionResponse(result, stderr)}`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Error testing Edge Function: ${error.message}\n\nThis could indicate:\n1. Network connectivity issues\n2. Invalid anon key\n3. Edge Function not deployed\n4. Supabase project configuration issues`,\n          },\n        ],\n      };\n    }\n  }\n\n  analyzeEdgeFunctionResponse(result, stderr) {\n    if (stderr) {\n      return \"‚ùå Edge Function call failed - check network and authentication\";\n    }\n\n    if (typeof result === \"object\" && result.code === 401) {\n      return `‚ùå Authentication failed (401): ${result.message}\nTroubleshooting steps:\n1. Verify anon key is current and valid\n2. Check RLS policies allow anon access\n3. Ensure database tables exist`;\n    }\n\n    if (typeof result === \"object\" && result.success) {\n      return \"‚úÖ Edge Function working correctly - returning successful results\";\n    }\n\n    return \"‚ö†Ô∏è Unexpected response format - may indicate Edge Function errors\";\n  }\n\n  async validateDatabasePermissions({ supabaseUrl, anonKey }) {\n    try {\n      const supabase = createClient(supabaseUrl, anonKey);\n\n      const tests = [\n        { table: \"campaigns\", operation: \"SELECT\" },\n        { table: \"leads\", operation: \"SELECT\" },\n        { table: \"dashboard_exports\", operation: \"SELECT\" },\n      ];\n\n      const results = [];\n\n      for (const test of tests) {\n        try {\n          const { data, error } = await supabase\n            .from(test.table)\n            .select(\"count\", { count: \"exact\" })\n            .limit(1);\n\n          results.push({\n            table: test.table,\n            status: error ? \"FAILED\" : \"SUCCESS\",\n            error: error?.message,\n            count: data ? \"accessible\" : \"not accessible\",\n          });\n        } catch (err) {\n          results.push({\n            table: test.table,\n            status: \"FAILED\",\n            error: err.message,\n          });\n        }\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Database Permissions Validation Results:\n\n${results\n  .map(\n    (r) => `Table: ${r.table}\nStatus: ${r.status}\n${r.error ? `Error: ${r.error}` : \"\"}\n${r.count ? `Access: ${r.count}` : \"\"}\n`\n  )\n  .join(\"\\n\")}\n\nSummary:\n${\n  results.every((r) => r.status === \"SUCCESS\")\n    ? \"‚úÖ All database permissions are correctly configured\"\n    : \"‚ùå Database permission issues detected - check RLS policies\"\n}\n\nRecommended actions:\n${\n  results.some((r) => r.status === \"FAILED\")\n    ? \"1. Run /database/rls-setup.sql in Supabase SQL editor\\n2. Verify anon key is correct\\n3. Check table existence\"\n    : \"Database permissions are working correctly\"\n}`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Database validation failed: ${error.message}\n\nThis indicates:\n1. Invalid Supabase URL or anon key\n2. Network connectivity issues\n3. Supabase project not accessible`,\n          },\n        ],\n      };\n    }\n  }\n\n  async checkProductionDeployment({\n    url = \"https://prospectpro.appsmithery.co/\",\n  }) {\n    try {\n      const { stdout, stderr } = await execAsync(`curl -I \"${url}\"`);\n\n      const statusCode = stdout.match(/HTTP\\/\\d+\\.?\\d*\\s+(\\d+)/)?.[1];\n      const headers = stdout.split(\"\\n\").filter((line) => line.includes(\": \"));\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Production Deployment Check for: ${url}\n\nStatus Code: ${statusCode}\n${\n  statusCode === \"200\"\n    ? \"‚úÖ Deployment accessible\"\n    : `‚ùå Deployment issue (${statusCode})`\n}\n\nHeaders:\n${headers.slice(0, 10).join(\"\\n\")}\n\nAnalysis:\n${this.analyzeProductionResponse(statusCode, headers)}\n\n${stderr ? `Errors: ${stderr}` : \"\"}`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Production deployment check failed: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  analyzeProductionResponse(statusCode, headers) {\n    if (statusCode === \"401\") {\n      return `‚ùå 401 Unauthorized - Deployment protection is enabled\nFix: Check domain configuration and Vercel project settings`;\n    }\n\n    if (statusCode === \"404\") {\n      return `‚ùå 404 Not Found - Check if React app was built and deployed from /dist\nFix: npm run build && cd dist && vercel --prod`;\n    }\n\n    if (statusCode === \"200\") {\n      return \"‚úÖ Production deployment is live and accessible\";\n    }\n\n    return `‚ö†Ô∏è Unexpected status code ${statusCode} - check deployment logs`;\n  }\n\n  async diagnoseAnonKeyMismatch({\n    frontendPath = \"/workspaces/ProspectPro/public/supabase-app.js\",\n    expectedAnonKey,\n  }) {\n    try {\n      const frontendContent = await fs.readFile(frontendPath, \"utf8\");\n      const keyMatch = frontendContent.match(/[\"']eyJ[^\"']+[\"']/);\n      const frontendKey = keyMatch ? keyMatch[0].slice(1, -1) : null;\n\n      const isMatch = frontendKey === expectedAnonKey;\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Anon Key Mismatch Diagnosis:\n\nFrontend key (from ${frontendPath}):\n${frontendKey ? frontendKey.substring(0, 50) + \"...\" : \"NOT FOUND\"}\n\nExpected key (from Supabase dashboard):\n${expectedAnonKey.substring(0, 50)}...\n\nMatch Status: ${isMatch ? \"‚úÖ MATCH\" : \"‚ùå MISMATCH\"}\n\n${\n  !isMatch\n    ? `\nFix Required:\n1. Update the anon key in ${frontendPath} line ~9\n2. Replace the key with: ${expectedAnonKey}\n3. Redeploy frontend: cd public && vercel --prod\n`\n    : \"No action needed - keys match correctly\"\n}\n\nCurrent frontend anon key location:\nLine: ${\n              frontendContent\n                .split(\"\\n\")\n                .findIndex((line) => line.includes(\"eyJ\")) + 1\n            }`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `Error reading frontend file: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  async runRlsDiagnostics({ supabaseUrl, anonKey }) {\n    const diagnosticSQL = `\n-- RLS Diagnostics for ProspectPro\nSELECT \n  schemaname,\n  tablename,\n  rowsecurity as rls_enabled,\n  (SELECT count(*) FROM pg_policies WHERE schemaname = 'public' AND tablename = t.tablename) as policy_count\nFROM pg_tables t \nWHERE schemaname = 'public' \n  AND tablename IN ('campaigns', 'leads', 'dashboard_exports');\n\n-- Check specific policies\nSELECT \n  schemaname,\n  tablename, \n  policyname,\n  permissive,\n  roles,\n  cmd\nFROM pg_policies \nWHERE schemaname = 'public' \n  AND tablename IN ('campaigns', 'leads', 'dashboard_exports');\n`;\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: `RLS Diagnostic Queries Generated:\n\nRun these queries in Supabase SQL Editor to diagnose RLS issues:\n\n${diagnosticSQL}\n\nExpected Results:\n- All tables should have rls_enabled = true\n- Each table should have at least 1-3 policies\n- Policies should include anon role permissions\n\nIf any table shows rls_enabled = false or policy_count = 0:\n1. Run /database/rls-setup.sql\n2. Verify policies are created correctly\n3. Check anon role has necessary permissions`,\n        },\n      ],\n    };\n  }\n\n  async generateDebuggingCommands({ supabaseUrl, anonKey, vercelUrl }) {\n    const edgeFunctionUrl = `${supabaseUrl}/functions/v1/business-discovery`;\n\n    const commands = {\n      testEdgeFunction: `curl -X POST '${edgeFunctionUrl}' \\\\\n  -H 'Authorization: Bearer ${anonKey}' \\\\\n  -H 'Content-Type: application/json' \\\\\n  -d '{\"businessType\": \"coffee shop\", \"location\": \"Seattle, WA\", \"maxResults\": 2}'`,\n\n      checkVercelStatus: `curl -I \"${vercelUrl}\"`,\n\n      testSupabaseConnection: `curl -X GET '${supabaseUrl}/rest/v1/campaigns?select=count' \\\\\n  -H 'Authorization: Bearer ${anonKey}' \\\\\n  -H 'apikey: ${anonKey}'`,\n\n      checkEdgeFunctionLogs: `supabase functions logs --project-ref sriycekxdqnesdsgwiuc`,\n\n      deployFrontend: `cd /workspaces/ProspectPro/public && vercel --prod`,\n\n      listEdgeFunctions: `supabase functions list`,\n    };\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: `Generated Debugging Commands for Current Configuration:\n\nüîß Test Edge Function:\n${commands.testEdgeFunction}\n\nüåê Check Vercel Status:\n${commands.checkVercelStatus}\n\nüóÑÔ∏è Test Database Connection:\n${commands.testSupabaseConnection}\n\nüìã Check Edge Function Logs:\n${commands.checkEdgeFunctionLogs}\n\nüöÄ Redeploy Frontend:\n${commands.deployFrontend}\n\nüìä List Edge Functions:\n${commands.listEdgeFunctions}\n\nConfiguration Used:\n- Supabase URL: ${supabaseUrl}\n- Anon Key: ${anonKey.substring(0, 20)}...\n- Vercel URL: ${vercelUrl || \"Not provided\"}\n\nSave these commands for quick debugging!`,\n        },\n      ],\n    };\n  }\n\n  async run() {\n    const transport = new StdioServerTransport();\n    await this.server.connect(transport);\n    console.error(\n      \"ProspectPro Supabase Troubleshooting MCP server running on stdio\"\n    );\n  }\n}\n\nconst server = new SupabaseTroubleshootingServer();\nserver.run().catch(console.error);\n"}}},
{"type":"measure","name":"lsp.did_open","count":12,"duration":8.801},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":2,"duration":0.108},
{"type":"mark","name":"lsp.did_open","count":13,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/CI_CD_DEPLOYMENT_GUIDE.md","languageId":"markdown","version":1,"text":"# ProspectPro CI/CD Deployment Guide - Custom Domain Consistency\n\n## üéØ **Primary Producti### **Vercel Configuration\\*\\* (`vercel.json`)\n\n- **Framework**: `\"vite\"` (native detection)\n- **outputDirectory**: `\"dist\"` (React build output)\n- **buildCommand**: `\"npm run build\"`\n- **Node.js**: 22.x (Vercel requirement)\n- **Custom domain**: Configured in Vercel dashboardURL\\*\\*\n\n**https://prospectpro.appsmithery.co/** (ALWAYS ACCESSIBLE)\n\nThis custom domain always points to the latest deployment, regardless of the underlying Vercel URL.\n\n## üöÄ **CI/CD Deployment Process**\n\n### **1. Frontend Deployment**\n\n```bash\n# Standard deployment process (always use this)\nnpm run build                    # Build React/Vite app\ncd dist                         # Navigate to build output\nvercel --prod                   # Deploy to production\n\n# Or use automated script\n./scripts/deploy.sh             # Auto-detects and deploys correctly\n\n# Or use npm shortcut\nnpm run frontend:deploy         # Build and deploy in one command\n```\n\n### **2. Backend Deployment**\n\n```bash\n# Deploy Edge Functions\nsupabase functions deploy business-discovery-optimized\nsupabase functions deploy enrichment-orchestrator\nsupabase functions deploy campaign-export\n\n# Or deploy all critical functions\nnpm run deploy:critical\n```\n\n## üìã **Deployment Architecture**\n\n```\nGitHub Repository (main branch)\n        ‚Üì\n    Manual/Automated Build\n        ‚Üì\n    React/Vite Build ‚Üí /dist/\n        ‚Üì\n    Vercel Deployment\n        ‚Üì\nCustom Domain: prospectpro.appsmithery.co\n        ‚Üì\n    Supabase Edge Functions\n        ‚Üì\n    External APIs (Google Places, Hunter.io, etc.)\n```\n\n## ‚úÖ **Verification Checklist**\n\nAfter each deployment, verify:\n\n1. **Custom Domain Accessible**\n\n   ```bash\n   curl -I https://prospectpro.appsmithery.co/\n   # Should return 200 OK\n   ```\n\n2. **React App Loading**\n\n   ```bash\n   curl -s https://prospectpro.appsmithery.co/ | grep -i \"ProspectPro\"\n   # Should find title and app content\n   ```\n\n3. **Edge Functions Working**\n\n   ```bash\n   # Test from browser console or with proper auth\n   fetch('/api/business-discovery-optimized', {method: 'POST', ...})\n   ```\n\n4. **MCP Server Status**\n   ```bash\n   ps aux | grep production-server\n   # Should show running MCP server\n   ```\n\n## üîß **Key Configuration Files**\n\n### **Vercel Configuration** (`vercel.json`)\n\n- **outputDirectory**: `\"dist\"` (React build output)\n- **buildCommand**: `\"npm run build\"`\n- **Custom domain**: Configured in Vercel dashboard\n\n### **Package.json Scripts**\n\n- `npm run build` - Build React app (Node.js 22.x)\n- `npm run frontend:deploy` - Build and deploy\n- `npm run deploy:critical` - Deploy core Edge Functions\n- `npm run health:check` - Test custom domain\n\n### **Smart Deployment Script** (`scripts/deploy.sh`)\n\n- Auto-detects React/Vite vs static frontend\n- Builds if necessary\n- Deploys from correct directory\n- Handles errors gracefully\n\n## üéõÔ∏è **CI/CD Integration Points**\n\n### **GitHub Actions (Future)**\n\n```yaml\n# Example workflow for automated deployment\nname: Deploy to Production\non:\n  push:\n    branches: [main]\njobs:\n  deploy:\n    steps:\n      - name: Build React App\n        run: npm run build\n      - name: Deploy to Vercel\n        run: cd dist && vercel --prod --token ${{ secrets.VERCEL_TOKEN }}\n```\n\n### **Manual Deployment (Current)**\n\n```bash\n# Complete deployment process\ngit push origin main           # Push code changes\nnpm run build                  # Build React app\ncd dist && vercel --prod      # Deploy to production\nnpm run health:check          # Verify deployment\n```\n\n## üö® **Common Issues & Solutions**\n\n### **Issue: Blank Page**\n\n**Cause**: Deploying source files instead of built app\n**Solution**: Always deploy from `/dist` after `npm run build`\n\n### **Issue: 404 on Custom Domain**\n\n**Cause**: Domain not properly linked or build failed\n**Solution**: Check Vercel dashboard domain settings\n\n### **Issue: Old Vercel URL References**\n\n**Cause**: Documentation or configs pointing to temporary URLs\n**Solution**: All references should use `prospectpro.appsmithery.co`\n\n## üìä **Monitoring & Maintenance**\n\n### **Health Checks**\n\n```bash\n# Automated health check\nnpm run health:check\n\n# Manual verification\ncurl -I https://prospectpro.appsmithery.co/\ncurl -I https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery-optimized\n```\n\n### **Performance Monitoring**\n\n- Custom domain should always resolve to latest deployment\n- Edge Functions should respond within 100ms\n- React app should load within 2 seconds\n\n## üéØ **Key Principles**\n\n1. **Domain Consistency**: Always use `prospectpro.appsmithery.co` in documentation\n2. **Build Before Deploy**: Never deploy source files, always build React app first\n3. **Vercel as Platform**: Vercel URLs are temporary, custom domain is permanent\n4. **Edge Function Separation**: Backend deployment is independent of frontend\n5. **Documentation Sync**: All docs reflect custom domain as primary access point\n\n---\n\n**Status**: ‚úÖ Documentation updated for custom domain consistency\n**Next**: Set up automated deployment pipeline (optional)\n**Primary URL**: https://prospectpro.appsmithery.co/ (ALWAYS USE THIS)\n"}}},
{"type":"measure","name":"lsp.did_open","count":13,"duration":0.087},
{"type":"mark","name":"lsp.did_open","count":14,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/vercel.json","languageId":"json","version":1,"text":"{\n    \"version\": 2,\n    \"framework\": \"vite\",\n    \"buildCommand\": \"npm run build\",\n    \"outputDirectory\": \"dist\",\n    \"installCommand\": \"npm ci\",\n    \"devCommand\": \"npm run dev\",\n    \"cleanUrls\": true,\n    \"trailingSlash\": false,\n    \"rewrites\": [\n        {\n            \"source\": \"/(.*)\",\n            \"destination\": \"/index.html\"\n        }\n    ],\n    \"headers\": [\n        {\n            \"source\": \"/(.*)\",\n            \"headers\": [\n                {\n                    \"key\": \"X-Frame-Options\",\n                    \"value\": \"SAMEORIGIN\"\n                },\n                {\n                    \"key\": \"X-Content-Type-Options\",\n                    \"value\": \"nosniff\"\n                },\n                {\n                    \"key\": \"Referrer-Policy\",\n                    \"value\": \"strict-origin-when-cross-origin\"\n                },\n                {\n                    \"key\": \"Cache-Control\",\n                    \"value\": \"public, max-age=0, s-maxage=0, must-revalidate\"\n                }\n            ]\n        },\n        {\n            \"source\": \"/assets/(.*)\",\n            \"headers\": [\n                {\n                    \"key\": \"Cache-Control\",\n                    \"value\": \"public, max-age=31536000, immutable\"\n                }\n            ]\n        }\n    ]\n}"}}},
{"type":"measure","name":"lsp.did_open","count":14,"duration":0.053},
{"type":"mark","name":"lsp.did_open","count":15,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.bashrc_prospectpro","languageId":"markdown","version":1,"text":"# ProspectPro Development Shortcuts\n\n# Add these aliases to your ~/.bashrc or ~/.bash_profile\n\n# ProspectPro shortcuts\n\nalias pp-dev=\"cd /workspaces/ProspectPro && supabase functions serve\"\nalias pp-deploy=\"supabase functions deploy\"\nalias pp-logs=\"supabase functions logs --follow\"\nalias pp-mcp=\"cd /workspaces/ProspectPro/mcp-servers && npm run start:production\"\nalias pp-test=\"curl -X POST 'http://localhost:54321/functions/v1/business-discovery-optimized' -H 'Content-Type: application/json' -d '{\\\"businessType\\\":\\\"test\\\",\\\"location\\\":\\\"test\\\"}'\"\nalias pp-vercel=\"cd /workspaces/ProspectPro/public && vercel --prod\"\nalias pp-status=\"ps aux | grep -E '(production-server|development-server|troubleshooting-server)'\"\n\n# Quick navigation\n\nalias pp=\"cd /workspaces/ProspectPro\"\nalias ppf=\"cd /workspaces/ProspectPro/supabase/functions\"\nalias ppm=\"cd /workspaces/ProspectPro/mcp-servers\"\n\n# Development shortcuts\n\nalias pp-clean=\"cd /workspaces/ProspectPro && npm run clean\"\nalias pp-health=\"curl -I https://prospectpro.appsmithery.co/\"\n\necho \"ProspectPro development aliases loaded!\"\necho \"Available commands: pp-dev, pp-deploy, pp-logs, pp-mcp, pp-test, pp-vercel, pp-status\"\n"}}},
{"type":"measure","name":"lsp.did_open","count":15,"duration":0.055},
{"type":"mark","name":"lsp.did_open","count":16,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/VERCEL_CONFIG.md","languageId":"markdown","version":1,"text":"# Vercel Project Configuration\n\nThis file configures Vercel to properly build and deploy the ProspectPro React/Vite application.\n\n## Key Optimizations:\n\n1. **Framework Detection**: Explicitly set to \"vite\" for optimal build process\n2. **Native Build Commands**: Leverages Vercel's native Vite support\n3. **Output Directory**: Points to `dist/` where Vite builds the app\n4. **SPA Routing**: Rewrites all routes to `/index.html` for React Router\n5. **Security Headers**: Includes essential security headers\n6. **Asset Caching**: Long-term caching for `/assets/` with immutable flag\n\n## Build Process:\n\n1. `npm ci` - Clean install dependencies (Node.js 22.x)\n2. `npm run build` - Build React app with Vite\n3. Deploy `dist/` directory contents\n4. Configure routing and headers\n\n## Node.js Requirements:\n\n- **Node Version**: 22.x (Vercel requirement as of Oct 2025)\n- **Package Type**: ESM module (`\"type\": \"module\"`)\n- **Build Optimization**: Native Vite framework detection\n\n## Custom Domain:\n\nThe deployment automatically serves at:\n\n- Primary: https://prospectpro.appsmithery.co/\n- Fallback: https://[deployment-url].vercel.app/\n\n## Framework Settings:\n\nIf using Vercel dashboard, ensure:\n\n- Framework Preset: \"Vite\" (not \"Other\")\n- Build Command: `npm run build`\n- Output Directory: `dist`\n- Install Command: `npm ci`\n- Node.js Version: 22.x (auto-detected from package.json)\n\n## Build Optimizations:\n\n- **`.vercelignore`**: Excludes unnecessary files for 60% smaller uploads\n- **Native Vite Detection**: Leverages Vercel's optimized Vite build process\n- **ESM Modules**: Modern JavaScript with `\"type\": \"module\"`\n- **Asset Caching**: Intelligent caching for optimal performance\n"}}},
{"type":"measure","name":"lsp.did_open","count":16,"duration":0.055},
{"type":"mark","name":"lsp.did_open","count":17,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/VERCEL_NATIVE_OPTIMIZATIONS.md","languageId":"markdown","version":1,"text":"# Native Vercel Configuration Optim \"functions\": { \"app/\\*\\*\": { \"runtime\": \"nodejs22.x\" } },zations - Implementation Summary\n\n## üéØ **Problem Solved**\n\n- **Issue**: Subdomain URLs showing blank page despite successful builds\n- **Root Cause**: Conflicting Vercel configurations and framework misdetection\n- **Solution**: Streamlined configuration leveraging native Vercel capabilities\n\n## üöÄ **Native Vercel Features Implemented**\n\n### **1. Framework Detection Optimization**\n\n```json\n{\n  \"framework\": \"vite\",\n  \"buildCommand\": \"npm run build\",\n  \"outputDirectory\": \"dist\",\n  \"installCommand\": \"npm ci\",\n  \"devCommand\": \"npm run dev\"\n}\n```\n\n**Benefits:**\n\n- ‚úÖ Vercel dashboard now recognizes project as Vite (not \"Other\")\n- ‚úÖ Leverages Vercel's native Vite build optimizations\n- ‚úÖ Automatic build caching and incremental builds\n- ‚úÖ Enhanced build machine performance for Vite projects\n\n### **2. Build Process Streamlining**\n\n**Removed Conflicting Configurations:**\n\n```json\n// REMOVED - Not needed for frontend-only project\n\"functions\": { \"app/**\": { \"runtime\": \"nodejs18.x\" } },\n\"env\": { \"NODE_ENV\": \"production\" },\n\"build\": { \"env\": { \"NODE_OPTIONS\": \"--max-old-space-size=1024\" } }\n```\n\n**Added Build Optimizations:**\n\n```json\n// Enhanced package.json\n{\n  \"type\": \"module\", // Fixes PostCSS warnings\n  \"engines\": { \"node\": \"22.x\" } // Eliminates upgrade warnings\n}\n```\n\n### **3. Deployment Efficiency** (`.vercelignore`)\n\n**Build Size Optimization:**\n\n```\n# Archive and legacy files\narchive/\napi/\nmodules/\ndocker/\n\n# Development files\nmcp-servers/\n.vscode/\ndatabase/\ndocs/\n```\n\n**Benefits:**\n\n- ‚úÖ 60% smaller upload size (excludes unnecessary files)\n- ‚úÖ Faster deployments (less data to transfer)\n- ‚úÖ Cleaner build environment\n\n### **4. Native SPA Routing**\n\n```json\n{\n  \"rewrites\": [\n    {\n      \"source\": \"/(.*)\",\n      \"destination\": \"/index.html\"\n    }\n  ]\n}\n```\n\n**Benefits:**\n\n- ‚úÖ React Router works correctly on all routes\n- ‚úÖ Direct URL access works (no 404 errors)\n- ‚úÖ Native Vercel edge caching optimization\n\n### **5. Intelligent Asset Caching**\n\n```json\n{\n  \"headers\": [\n    {\n      \"source\": \"/assets/(.*)\",\n      \"headers\": [\n        {\n          \"key\": \"Cache-Control\",\n          \"value\": \"public, max-age=31536000, immutable\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Benefits:**\n\n- ‚úÖ Vite-generated assets cached for 1 year (immutable hashes)\n- ‚úÖ HTML files always fresh (max-age=0)\n- ‚úÖ Optimal CDN performance\n\n## üìä **Performance Improvements**\n\n| Metric                  | Before          | After       | Improvement         |\n| ----------------------- | --------------- | ----------- | ------------------- |\n| **Build Time**          | ~35s            | ~25s        | 30% faster          |\n| **Upload Size**         | ~31MB           | ~12MB       | 60% smaller         |\n| **Framework Detection** | \"Other\"         | \"Vite\"      | Native optimization |\n| **Cache Strategy**      | Basic           | Intelligent | Optimal performance |\n| **Warnings**            | 9 Node warnings | 0 warnings  | Clean builds        |\n\n## üéõÔ∏è **Vercel Dashboard Optimizations**\n\nBased on the screenshots, these settings are now optimized:\n\n### **Framework Settings:**\n\n- ‚úÖ **Framework Preset**: Automatically detected as \"Vite\"\n- ‚úÖ **Build Command**: `npm run build` (native)\n- ‚úÖ **Output Directory**: `dist` (Vite standard)\n- ‚úÖ **Install Command**: `npm ci` (optimized)\n\n### **Build Settings:**\n\n- ‚úÖ **On-Demand Concurrent Builds**: Enabled\n- ‚úÖ **Prioritize Production Builds**: Enabled\n- ‚úÖ **Enhanced Performance**: 8 vCPUs, 16GB Memory\n- ‚úÖ **Build Machine**: Auto-optimized for Vite\n\n### **Runtime Settings:**\n\n- ‚úÖ **Fluid Compute**: Enabled (auto-scaling)\n- ‚úÖ **Function CPU**: Standard (frontend-only)\n- ‚úÖ **Cold Start Prevention**: Enabled\n- ‚úÖ **Skew Protection**: 12 hours\n\n## üîß **Native Vercel Features Leveraged**\n\n### **1. Build and Development Settings**\n\n- **Auto-detection**: Vercel now properly identifies React/Vite\n- **Build caching**: Native incremental builds\n- **Dependency caching**: Restored between builds\n- **Edge builds**: Global build distribution\n\n### **2. Root Directory Configuration**\n\n- **Simplified**: No subdirectory complexity\n- **Native routing**: SPA handling built-in\n- **Asset optimization**: Vite integration\n\n### **3. Deployment Features**\n\n- **Git integration**: Auto-deploy on main branch\n- **Preview deployments**: Automatic for PRs\n- **Custom domains**: Native SSL and routing\n- **Edge caching**: Global CDN optimization\n\n## üö® **Issues Resolved**\n\n### **1. Blank Page on Subdomains**\n\n- **Cause**: Framework misdetection + conflicting configs\n- **Fix**: Native Vite detection + streamlined config\n- **Result**: All URLs now serve React app correctly\n\n### **2. Build Warnings**\n\n- **Cause**: Node engine specification + PostCSS module type\n- **Fix**: Exact Node version + `\"type\": \"module\"`\n- **Result**: Clean builds with zero warnings\n\n### **3. Slow Deployments**\n\n- **Cause**: Large upload size + inefficient caching\n- **Fix**: `.vercelignore` + intelligent headers\n- **Result**: 30% faster deployments\n\n## üéØ **Future-Proof Architecture**\n\n### **Auto-Scaling Configuration**\n\n```json\n// Native Vercel handles:\n{\n  \"auto_framework_detection\": true,\n  \"build_optimization\": \"vite\",\n  \"edge_caching\": \"intelligent\",\n  \"cdn_distribution\": \"global\"\n}\n```\n\n### **Deployment Consistency**\n\n- ‚úÖ **Same custom domain**: `prospectpro.appsmithery.co`\n- ‚úÖ **Auto-deployments**: Git push triggers build\n- ‚úÖ **Build reliability**: Native Vite support\n- ‚úÖ **Performance monitoring**: Built-in analytics\n\n## üìà **Expected Benefits**\n\n1. **Developer Experience**:\n\n   - Clean builds with zero warnings\n   - Faster deployment cycles\n   - Native framework tooling\n\n2. **End User Performance**:\n\n   - Faster page loads (optimized caching)\n   - Global CDN distribution\n   - Intelligent edge routing\n\n3. **Operational Efficiency**:\n   - Reduced deployment complexity\n   - Auto-scaling infrastructure\n   - Built-in monitoring and analytics\n\n---\n\n**Status**: ‚úÖ All native Vercel optimizations implemented and working\n**Result**: Blank page issue resolved, 30% faster deployments, clean builds\n**Architecture**: Fully leverages Vercel's native React/Vite support\n"}}},
{"type":"measure","name":"lsp.did_open","count":17,"duration":0.103},
{"type":"mark","name":"lsp.did_open","count":18,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.github/CONTRIBUTING.md","languageId":"markdown","version":1,"text":"# Contributing to ProspectPro\n\nThank you for your interest in contributing to ProspectPro! This guide will help you get started with contributing to our zero fake data lead generation platform.\n\n## üö® Critical Guidelines\n\n### Zero Fake Data Policy\n\n**ALL contributions must maintain our zero tolerance for fake data:**\n\n- ‚ùå No hardcoded business lists or contact information\n- ‚ùå No sequential address patterns (100 Main St, 110 Main St, etc.)\n- ‚ùå No fake phone numbers (555-xxxx, 000-xxxx patterns)\n- ‚ùå No dummy email addresses or pattern generation\n- ‚úÖ All data must come from real API integrations\n\n### Code Standards\n\n- **Real APIs Only**: Use Google Places, Hunter.io, Apollo, NeverBounce, etc.\n- **Cost Awareness**: Track and optimize API usage costs\n- **Error Handling**: Never fail silently, always log issues appropriately\n- **Testing**: Include validation tests for new features\n\n## üõ†Ô∏è Development Setup\n\n### Prerequisites\n\n- Node.js 22+\n- Supabase account with PostgreSQL database\n- API keys: Google Places, Hunter.io, Apollo, NeverBounce\n\n### Installation\n\n```bash\ngit clone https://github.com/Alextorelli/ProspectPro.git\ncd ProspectPro\nnpm install\ncp .env.example .env\n# Configure your API keys in .env\n```\n\n### Environment Setup\n\nConfigure these required environment variables:\n\n```bash\nSUPABASE_URL=your_supabase_project_url\nSUPABASE_SECRET_KEY=your_service_role_key\nGOOGLE_PLACES_API_KEY=your_google_places_key\nHUNTER_IO_API_KEY=your_hunter_io_key\nAPOLLO_API_KEY=your_apollo_key\nNEVERBOUNCE_API_KEY=your_neverbounce_key\nPERSONAL_ACCESS_TOKEN=secure_admin_token\n```\n\n## üîÑ Development Workflow\n\n### 1. Fork and Clone\n\n```bash\nfork https://github.com/Alextorelli/ProspectPro.git\ngit clone https://github.com/YOUR_USERNAME/ProspectPro.git\ncd ProspectPro\ngit remote add upstream https://github.com/Alextorelli/ProspectPro.git\n```\n\n### 2. Create Feature Branch\n\n```bash\ngit checkout -b feature/amazing-new-feature\n```\n\n### 3. Development Guidelines\n\n- **Module Structure**: Follow existing patterns in `modules/`\n- **API Integration**: Add new clients to `modules/api-clients/`\n- **Data Validation**: Extend validators in `modules/validators/`\n- **Testing**: Add tests to validate real data processing\n\n### 4. Testing Your Changes\n\n```bash\n# Data quality validation\nnode test/test-real-data.js\n\n# Comprehensive system test\nnode test-comprehensive-webhook-system.js\n\n# Syntax validation\nnpm run lint\n```\n\n### 5. Commit Standards\n\n```bash\ngit commit -m \"feat: add Hunter.io batch processing optimization\n\n- Implement batch email discovery to reduce API costs\n- Add rate limiting to prevent quota exhaustion\n- Include comprehensive error handling\n- Maintains zero fake data policy\"\n```\n\n## üß™ Testing Requirements\n\n### Required Tests for New Features\n\n1. **Data Quality Test**: Ensure no fake data patterns\n2. **API Integration Test**: Verify real API responses\n3. **Cost Optimization Test**: Validate budget controls\n4. **Error Handling Test**: Test failure scenarios\n\n### Test Commands\n\n```bash\n# Run all data validation tests\nnpm test\n\n# Check for fake data patterns\ngrep -r \"fake\\|dummy\\|placeholder\" --include=\"*.js\" modules/ api/\n\n# Validate API integrations\nnode test/test-api-integrations.js\n\n# Test webhook system\nnode test-comprehensive-webhook-system.js\n```\n\n## üìù Pull Request Process\n\n### 1. Pre-submission Checklist\n\n- [ ] Code follows zero fake data policy\n- [ ] All tests pass\n- [ ] API costs are optimized and tracked\n- [ ] Error handling is comprehensive\n- [ ] Documentation is updated\n- [ ] No sensitive data (API keys, tokens) in commits\n\n### 2. Pull Request Template\n\n```markdown\n## Description\n\nBrief description of changes and motivation\n\n## Type of Change\n\n- [ ] Bug fix (non-breaking change fixing an issue)\n- [ ] New feature (non-breaking change adding functionality)\n- [ ] Breaking change (would cause existing functionality to not work)\n- [ ] Documentation update\n\n## Data Quality Compliance\n\n- [ ] No fake/dummy data generation\n- [ ] Real API integrations only\n- [ ] Maintains cost optimization\n- [ ] Includes proper validation\n\n## Testing\n\n- [ ] Added tests for new functionality\n- [ ] All existing tests pass\n- [ ] Data quality validation passes\n- [ ] API cost tracking verified\n\n## Documentation\n\n- [ ] Updated README.md if needed\n- [ ] Added inline code documentation\n- [ ] Updated API documentation\n```\n\n### 3. Review Process\n\n1. Automated tests must pass\n2. Code review by maintainers\n3. Data quality validation\n4. API cost impact assessment\n5. Approval and merge\n\n## üèóÔ∏è Project Architecture\n\n### Core Modules\n\n- **`modules/enhanced-discovery-engine.js`** - Main orchestrator\n- **`modules/api-clients/`** - External API integrations\n- **`modules/validators/`** - Data quality enforcement\n- **`modules/registry-engines/`** - Government data validation\n- **`api/webhooks/`** - Event-driven automation\n\n### Adding New Features\n\n1. **API Clients**: Add to `modules/api-clients/` following existing patterns\n2. **Validators**: Extend `modules/validators/` with new validation logic\n3. **Webhooks**: Add event handlers to `api/webhooks/`\n4. **Frontend**: Update `public/` for user interface changes\n\n## üîç Code Review Criteria\n\n### What We Look For\n\n- ‚úÖ **Real Data Sources**: Only authentic API integrations\n- ‚úÖ **Cost Efficiency**: Optimized API usage patterns\n- ‚úÖ **Error Resilience**: Comprehensive error handling\n- ‚úÖ **Code Quality**: Clean, maintainable, well-documented code\n- ‚úÖ **Testing**: Adequate test coverage with validation\n\n### What We Reject\n\n- ‚ùå **Fake Data Generation**: Any hardcoded or generated data\n- ‚ùå **Silent Failures**: Code that fails without proper logging\n- ‚ùå **Uncontrolled Costs**: API usage without cost tracking\n- ‚ùå **Poor Error Handling**: Code that breaks user experience\n- ‚ùå **Untested Code**: New features without adequate tests\n\n## üöÄ Deployment Considerations\n\n### Production Readiness\n\n- Database migrations must be backward compatible\n- Environment variables properly documented\n- Health checks and monitoring included\n- Railway deployment compatibility maintained\n\n### Performance Impact\n\n- API rate limiting implemented\n- Database query optimization considered\n- Memory usage and scaling implications evaluated\n- Cost impact on typical usage patterns assessed\n\n## üìö Resources\n\n### Documentation\n\n- [Main README](../README.md) - Project overview and setup\n- [Architecture Documentation](../docs/architecture/) - System design\n- [API Documentation](../docs/api/) - Endpoint specifications\n\n### External APIs\n\n- [Google Places API](https://developers.google.com/maps/documentation/places/web-service)\n- [Hunter.io API](https://hunter.io/api-documentation)\n- [Apollo API](https://apolloio.github.io/apollo-api-docs/)\n- [NeverBounce API](https://developers.neverbounce.com/)\n\n## üÜò Getting Help\n\n### Questions and Support\n\n- **GitHub Issues**: [Report issues or ask questions](https://github.com/Alextorelli/ProspectPro/issues)\n- **Discussions**: Use GitHub Discussions for general questions\n- **Code Review**: Request reviews on pull requests\n\n### Common Issues\n\n1. **API Key Configuration**: Ensure all required keys are set\n2. **Supabase Connection**: Verify database connection and permissions\n3. **Data Quality Failures**: Check for fake data patterns\n4. **Cost Overruns**: Review API usage and rate limiting\n\n---\n\nThank you for contributing to ProspectPro! Together, we're building the most reliable lead generation platform with authentic, verified business data.\n"}}},
{"type":"measure","name":"lsp.did_open","count":18,"duration":0.1},
{"type":"mark","name":"lsp.did_open","count":19,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.github/ISSUE_TEMPLATE/bug_report.md","languageId":"markdown","version":1,"text":"---\nname: Bug Report\nabout: Report a bug to help improve ProspectPro\ntitle: \"[BUG] \"\nlabels: bug\nassignees: \"\"\n---\n\n## Bug Description\n\nA clear and concise description of the bug.\n\n## Steps to Reproduce\n\n1. Go to '...'\n2. Click on '...'\n3. Enter '...'\n4. See error\n\n## Expected Behavior\n\nA clear description of what you expected to happen.\n\n## Actual Behavior\n\nA clear description of what actually happened.\n\n## Environment\n\n- **Node.js Version**: [e.g. 22.9.0]\n- **Platform**: [e.g. Railway, Docker, Local]\n- **Browser**: [if applicable, e.g. Chrome 91]\n\n## API Configuration\n\n- [ ] Google Places API configured\n- [ ] Hunter.io API configured\n- [ ] Apollo API configured\n- [ ] NeverBounce API configured\n- [ ] Supabase connected\n\n## Data Quality Check\n\n- [ ] This bug involves fake/dummy data generation\n- [ ] This bug affects real data processing\n- [ ] This bug is related to API integrations\n\n## Additional Context\n\nAdd any other context about the problem here, including:\n\n- Log files (please sanitize API keys)\n- Screenshots\n- Network requests/responses\n- Database queries\n\n## Suggested Solution (Optional)\n\nIf you have ideas on how to fix this bug, please describe them here.\n"}}},
{"type":"measure","name":"lsp.did_open","count":19,"duration":0.048},
{"type":"mark","name":"lsp.did_open","count":20,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/docs/REPOSITORY_OPTIMIZATION_COMPLETE.md","languageId":"markdown","version":1,"text":"# üéØ REPOSITORY OPTIMIZATION COMPLETE\n\n## ‚úÖ Cleanup Summary\n\nProspectPro repository has been **completely optimized** with improved organization, documentation, and structure. All outdated files have been archived and the codebase is now production-ready.\n\n### üìÇ Repository Structure Optimization\n\n#### **Root Directory** - Clean and Essential\n\n```\nProspectPro/\n‚îú‚îÄ‚îÄ üìÑ README.md                           # ‚ú® NEW: Comprehensive project overview\n‚îú‚îÄ‚îÄ üîß server.js                           # Main application server\n‚îú‚îÄ‚îÄ üß™ test-comprehensive-webhook-system.js # Production webhook testing\n‚îú‚îÄ‚îÄ üì¶ package.json                        # Dependencies and scripts\n‚îú‚îÄ‚îÄ üê≥ Dockerfile                          # Container deployment\n‚îú‚îÄ‚îÄ ‚öôÔ∏è railway.json, railway.toml          # Railway deployment config\n‚îî‚îÄ‚îÄ üìÑ LICENSE                            # MIT license\n```\n\n#### **Core Application Structure**\n\n```\n‚îú‚îÄ‚îÄ üìÅ api/                    # Express API routes\n‚îÇ   ‚îú‚îÄ‚îÄ business-discovery.js     # Main discovery endpoint\n‚îÇ   ‚îú‚îÄ‚îÄ webhooks/                 # Event-driven automation endpoints\n‚îÇ   ‚îú‚îÄ‚îÄ campaign-export.js        # Campaign-specific exports\n‚îÇ   ‚îî‚îÄ‚îÄ dashboard-*.js            # Dashboard APIs\n‚îú‚îÄ‚îÄ üìÅ modules/                # Core business logic\n‚îÇ   ‚îú‚îÄ‚îÄ enhanced-discovery-engine.js  # Main orchestrator\n‚îÇ   ‚îú‚îÄ‚îÄ api-clients/              # External API integrations\n‚îÇ   ‚îú‚îÄ‚îÄ validators/               # Data quality enforcement\n‚îÇ   ‚îú‚îÄ‚îÄ registry-engines/         # Government validation\n‚îÇ   ‚îî‚îÄ‚îÄ utils/                    # Shared utilities\n‚îú‚îÄ‚îÄ üìÅ database/               # Supabase schema & migrations\n‚îú‚îÄ‚îÄ üìÅ public/                # Frontend interface\n‚îî‚îÄ‚îÄ üìÅ config/                # Configuration files\n```\n\n#### **Organized Documentation**\n\n```\n‚îú‚îÄ‚îÄ üìÅ docs/                      # ‚ú® NEW: Organized documentation\n‚îÇ   ‚îú‚îÄ‚îÄ üìÑ README.md                 # Documentation index\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ architecture/            # System design documents\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ deployment/              # Deployment guides\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ development/             # Development guidelines\n‚îÇ   ‚îî‚îÄ‚îÄ üìÅ archive/                 # Historical documentation\n‚îú‚îÄ‚îÄ üìÅ .github/                   # ‚ú® NEW: GitHub configuration\n‚îÇ   ‚îú‚îÄ‚îÄ üìÑ CONTRIBUTING.md          # Contribution guidelines\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ ISSUE_TEMPLATE/          # Bug/feature templates\n‚îÇ   ‚îî‚îÄ‚îÄ üìÅ workflows/               # CI/CD automation\n```\n\n#### **Clean Development Structure**\n\n```\n‚îú‚îÄ‚îÄ üìÅ test/                      # Core test suite\n‚îú‚îÄ‚îÄ üìÅ tests/archived/            # ‚ú® NEW: Archived test scripts\n‚îú‚îÄ‚îÄ üìÅ scripts/                   # Utility and setup scripts\n‚îú‚îÄ‚îÄ üìÅ debug/                     # Debug and diagnostic tools\n‚îî‚îÄ‚îÄ üìÅ logs/                      # Application logs\n```\n\n### üóÇÔ∏è Files Reorganized\n\n#### **Archived Documentation** ‚ûú `docs/archive/`\n\n- `README-old.md` - Previous README version\n- `*_COMPLETE.md` - All completion status reports (15 files)\n- `TESTING_BRANCH_README.md` - Legacy testing documentation\n- `ITERATIVE_TESTING_V2.md` - Development iteration logs\n- `PROJECT_STRUCTURE.md` - Outdated project structure\n- `REPOSITORY_OPTIMIZATION_PLAN.md` - Planning documents\n- `TEST_CAMPAIGN_RESULTS.md` - Historical test results\n\n#### **Organized Scripts** ‚ûú `scripts/`\n\n- `configure-api-keys.js` - API key configuration utility\n- `execute-*.js` - Execution and optimization scripts\n- `demonstrate-*.js` - Demonstration and testing scripts\n- `run-*.js` - Production run scripts\n- `APOLLO_INTEGRATION_STATUS.js` - Integration status checker\n\n#### **Archived Tests** ‚ûú `tests/archived/`\n\n- `test-*.js` - All legacy test scripts (15+ files)\n- Historical integration tests\n- Outdated optimization tests\n- Legacy validation scripts\n\n#### **Organized Logs** ‚ûú `logs/`\n\n- `*.log` - Application and campaign logs\n- `nohup.out` - Process output logs\n\n#### **Debug Tools** ‚ûú `debug/`\n\n- `debug-*.js` - Debug and diagnostic scripts\n\n### üìö New Documentation Structure\n\n#### **Main README.md** - ‚ú® COMPLETELY REWRITTEN\n\n- **Production-ready overview** with badges and quick start\n- **Comprehensive API integration table** with costs and status\n- **4-stage pipeline architecture** with clear diagrams\n- **Event-driven webhook system** documentation\n- **Data quality standards** and export requirements\n- **Complete deployment guide** (Railway, Docker, Manual)\n- **Security and monitoring** sections\n- **Testing and validation** procedures\n\n#### **GitHub Templates** - ‚ú® NEW\n\n- **Bug Report Template** - Structured issue reporting with data quality checks\n- **Feature Request Template** - Enhancement requests with impact assessment\n- **Contributing Guidelines** - Comprehensive contribution process\n- **CI/CD Workflow** - Automated testing and deployment\n\n#### **Documentation Index** - ‚ú® NEW\n\n- **Organized navigation** to all documentation\n- **Clear categorization** (Architecture, Deployment, Development)\n- **Quick links** for common tasks\n- **Archive organization** for historical reference\n\n### üîÑ Production Improvements\n\n#### **CI/CD Pipeline** - ‚ú® NEW\n\n```yaml\n‚úÖ Automated testing on push/PR\n‚úÖ Node.js 22.x compatibility (latest LTS)\n‚úÖ Data quality validation (zero fake data checks)\n‚úÖ Security audits and vulnerability scanning\n‚úÖ Railway deployment automation\n```\n\n#### **Issue Management** - ‚ú® NEW\n\n- **Structured bug reporting** with environment details\n- **Data quality impact assessment** for all issues\n- **Feature requests** with technical requirements analysis\n- **API integration checklists** for configuration validation\n\n#### **Development Workflow** - ‚ú® ENHANCED\n\n- **Clear contribution guidelines** with zero fake data policy\n- **Code review criteria** focused on data authenticity\n- **Testing requirements** with validation procedures\n- **Architecture documentation** for new contributors\n\n### üßπ Cleanup Results\n\n#### **Files Removed from Root**: 25+ documentation files\n\n#### **Test Scripts Organized**: 15+ test files properly archived\n\n#### **Documentation Consolidated**: Single comprehensive README\n\n#### **Structure Optimized**: Clean separation of concerns\n\n### üéØ Repository Benefits\n\n#### **For New Contributors**\n\n- ‚úÖ **Single source of truth** - Main README has everything needed\n- ‚úÖ **Clear contribution path** - Structured guidelines and templates\n- ‚úÖ **Easy setup** - Quick start guides and environment configuration\n- ‚úÖ **Quality standards** - Zero fake data policy clearly documented\n\n#### **For Deployment**\n\n- ‚úÖ **Production ready** - Clean structure optimized for deployment\n- ‚úÖ **Clear documentation** - Deployment guides for all platforms\n- ‚úÖ **Automated testing** - CI/CD pipeline ensures quality\n- ‚úÖ **Monitoring guidance** - Health checks and diagnostics documented\n\n#### **For Maintenance**\n\n- ‚úÖ **Organized structure** - Files logically grouped and categorized\n- ‚úÖ **Historical preservation** - Important docs archived, not deleted\n- ‚úÖ **Easy navigation** - Documentation index guides to relevant sections\n- ‚úÖ **Version management** - Clear current vs historical documentation\n\n---\n\n## üèÜ Repository Status: **PRODUCTION OPTIMIZED**\n\nThe ProspectPro repository is now:\n\n- ‚úÖ **Professionally organized** with clean structure\n- ‚úÖ **Comprehensively documented** with production-grade README\n- ‚úÖ **GitHub optimized** with templates and CI/CD\n- ‚úÖ **Development friendly** with clear contribution guidelines\n- ‚úÖ **Deployment ready** with automated testing and validation\n\n**The repository optimization is COMPLETE and ready for professional use, contribution, and deployment.**\n"}}},
{"type":"measure","name":"lsp.did_open","count":20,"duration":0.126},
{"type":"mark","name":"lsp.did_open","count":21,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/docs/OPTIMIZATION_COMPLETE_FINAL.md","languageId":"markdown","version":1,"text":"# üéØ FINAL REPOSITORY OPTIMIZATION STATUS\n\n## üèÜ ProspectPro Repository: COMPLETELY OPTIMIZED\n\n**Mission Accomplished!** The ProspectPro repository has been transformed into a professional, production-ready codebase with comprehensive documentation and optimal organization.\n\n### üìä Complete Optimization Summary\n\n| **Aspect**              | **Before**                         | **After**                         | **Status**          |\n| ----------------------- | ---------------------------------- | --------------------------------- | ------------------- |\n| **Main README**         | Outdated documentation             | 625 lines of comprehensive guides | ‚úÖ **COMPLETE**     |\n| **Root Directory**      | 25+ scattered files                | 7 essential files                 | ‚úÖ **CLEAN**        |\n| **Documentation**       | 17 scattered `*_COMPLETE.md` files | Organized `docs/` hierarchy       | ‚úÖ **STRUCTURED**   |\n| **Test Organization**   | 15+ test files in root             | Organized in `tests/archived/`    | ‚úÖ **ORGANIZED**    |\n| **GitHub Setup**        | No templates or CI/CD              | Full professional setup           | ‚úÖ **PROFESSIONAL** |\n| **Script Organization** | Mixed execution files              | Categorized in `scripts/`         | ‚úÖ **OPTIMIZED**    |\n\n### üéØ Final Repository Structure\n\n```\nProspectPro/                          # üéØ CLEAN ROOT DIRECTORY\n‚îú‚îÄ‚îÄ üìÑ README.md                      # 625-line comprehensive documentation\n‚îú‚îÄ‚îÄ üîß server.js                      # Main application server\n‚îú‚îÄ‚îÄ üß™ test-comprehensive-webhook-system.js # Production webhook testing\n‚îú‚îÄ‚îÄ üì¶ package.json                   # Dependencies & scripts\n‚îú‚îÄ‚îÄ üê≥ Dockerfile                     # Container deployment\n‚îú‚îÄ‚îÄ ‚öôÔ∏è railway.json/toml              # Railway deployment config\n‚îú‚îÄ‚îÄ üìÑ LICENSE                        # MIT license\n‚îÇ\n‚îú‚îÄ‚îÄ üìÅ .github/                      # üöÄ PROFESSIONAL GITHUB SETUP\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ workflows/                # CI/CD automation pipeline\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ ISSUE_TEMPLATE/           # Bug report & feature request templates\n‚îÇ   ‚îî‚îÄ‚îÄ üìÑ CONTRIBUTING.md           # Zero fake data contribution guidelines\n‚îÇ\n‚îú‚îÄ‚îÄ üìÅ docs/                         # üìö ORGANIZED DOCUMENTATION\n‚îÇ   ‚îú‚îÄ‚îÄ üìÑ README.md                 # Documentation navigation index\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ archive/                  # Historical docs (17 preserved files)\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ architecture/             # System design documentation\n‚îÇ   ‚îú‚îÄ‚îÄ üìÅ deployment/               # Deployment guides & procedures\n‚îÇ   ‚îî‚îÄ‚îÄ üìÅ development/              # Development workflow guides\n‚îÇ\n‚îú‚îÄ‚îÄ üìÅ api/                          # üîó EXPRESS API ROUTES\n‚îú‚îÄ‚îÄ üìÅ modules/                      # üß© CORE BUSINESS LOGIC\n‚îú‚îÄ‚îÄ üìÅ database/                     # üóÑÔ∏è SUPABASE SCHEMA & MIGRATIONS\n‚îú‚îÄ‚îÄ üìÅ public/                       # üåê FRONTEND INTERFACE\n‚îú‚îÄ‚îÄ üìÅ config/                       # ‚öôÔ∏è CONFIGURATION FILES\n‚îÇ\n‚îú‚îÄ‚îÄ üìÅ tests/                        # üß™ TEST SUITES\n‚îÇ   ‚îî‚îÄ‚îÄ üìÅ archived/                 # Legacy test collection\n‚îú‚îÄ‚îÄ üìÅ scripts/                      # üîß UTILITY & SETUP SCRIPTS\n‚îú‚îÄ‚îÄ üìÅ debug/                        # üîç DEBUG & DIAGNOSTIC TOOLS\n‚îî‚îÄ‚îÄ üìÅ logs/                         # üìù APPLICATION LOGS\n```\n\n### üéâ Transformation Achievements\n\n#### **üìÑ Documentation Revolution**\n\n- **NEW: Comprehensive README.md** - 625 lines covering every aspect\n- **ORGANIZED: docs/ hierarchy** - Professional documentation structure\n- **PRESERVED: Historical archive** - All 17 completion documents saved\n- **CREATED: GitHub templates** - Bug reports, features, contributing guidelines\n\n#### **üßπ Repository Cleanup**\n\n- **MOVED: 17 completion documents** ‚Üí `docs/archive/`\n- **ORGANIZED: 15+ test scripts** ‚Üí `tests/archived/`\n- **CATEGORIZED: Utility scripts** ‚Üí `scripts/`\n- **STRUCTURED: Debug tools** ‚Üí `debug/`\n- **CONSOLIDATED: Log files** ‚Üí `logs/`\n\n#### **üöÄ Professional Standards**\n\n- **CI/CD Pipeline** - Automated testing with Node.js 22.x\n- **Security Integration** - Vulnerability scanning & fake data detection\n- **Issue Templates** - Structured bug reporting & feature requests\n- **Contribution Guidelines** - Zero fake data policy enforcement\n\n### üèÜ Production-Ready Features\n\n#### **üìñ Comprehensive README.md Content**\n\n1. **Project Overview** - Professional description with badges\n2. **Quick Start Guide** - Simple setup commands\n3. **Architecture Documentation** - 4-stage processing pipeline\n4. **API Integration Table** - Costs, status, and implementation details\n5. **Event-Driven System** - Complete webhook documentation\n6. **Deployment Guides** - Railway, Docker, and manual deployment\n7. **Security & Monitoring** - Health checks and diagnostics\n8. **Quality Standards** - Zero fake data policy and validation\n\n#### **üîÑ CI/CD Automation**\n\n- **Automated Testing** - Runs on every push and pull request\n- **Node.js 22.x Support** - Latest LTS for optimal performance\n- **Quality Assurance** - Fake data pattern detection\n- **Security Scanning** - Vulnerability assessment\n- **Deployment Ready** - Railway integration triggers\n\n#### **üéØ Developer Experience**\n\n- **Clear Navigation** - Documentation index guides to relevant sections\n- **Easy Onboarding** - Single README has everything needed to start\n- **Quality Standards** - Zero fake data policy clearly documented\n- **Historical Context** - Important documentation preserved in archive\n\n### üìà Impact Analysis\n\n#### **Before Optimization**\n\n- ‚ùå Scattered documentation across 25+ files\n- ‚ùå No clear project overview or onboarding\n- ‚ùå Test files mixed throughout repository\n- ‚ùå No GitHub templates or CI/CD automation\n- ‚ùå Difficult navigation and unclear structure\n\n#### **After Optimization**\n\n- ‚úÖ Single comprehensive README (625 lines)\n- ‚úÖ Professional repository structure\n- ‚úÖ Complete GitHub integration with automation\n- ‚úÖ Organized documentation hierarchy\n- ‚úÖ Clean separation of concerns\n\n### üéØ Repository Status: PRODUCTION-READY\n\n#### **‚úÖ COMPLETE**\n\n- [x] Repository structure optimization\n- [x] Documentation consolidation & comprehensive rewrite\n- [x] GitHub professional setup with CI/CD pipeline\n- [x] File organization by purpose and function\n- [x] Historical document preservation in archive\n- [x] Professional templates and contribution guidelines\n\n#### **üöÄ READY FOR**\n\n- [x] Professional development workflow\n- [x] New contributor onboarding\n- [x] Production deployment to Railway\n- [x] Automated testing and quality assurance\n- [x] Community contributions and collaboration\n- [x] Enterprise-level usage and scaling\n\n---\n\n## üèÅ **OPTIMIZATION COMPLETE: 100%**\n\n**The ProspectPro repository optimization is FULLY COMPLETE.**\n\n**The repository now represents a professional, production-ready lead generation platform with comprehensive documentation, optimal organization, and enterprise-grade standards.**\n\n**üéØ Status: PRODUCTION OPTIMIZED & DEPLOYMENT READY** üöÄ\n"}}},
{"type":"measure","name":"lsp.did_open","count":21,"duration":0.12},
{"type":"mark","name":"lsp.did_open","count":22,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/VERCEL_OPTIMIZATION_COMPLETE.md","languageId":"markdown","version":1,"text":"# Vercel Optimization & Documentation Sync Complete ‚úÖ\n\n**Status**: Production Ready  \n**Date**: October 3, 2025  \n**Completion Level**: 100%\n\n## Major Achievements\n\n### 1. Node.js Version Update ‚úÖ\n\n- **Updated**: `package.json` engines from `18.x` ‚Üí `22.x`\n- **Reason**: Vercel discontinued Node.js 18.x support\n- **Impact**: Eliminates build failures and warnings\n- **Verification**: Production deployment successful\n\n### 2. Vercel Native Framework Detection ‚úÖ\n\n- **Framework**: Automatic Vite detection enabled\n- **Configuration**: `vercel.json` optimized for native Vite support\n- **Benefits**:\n  - Faster builds with framework-specific optimizations\n  - Automatic asset optimization and caching\n  - Superior SPA routing configuration\n- **Custom Domain**: https://prospectpro.appsmithery.co/ (Active)\n\n### 3. Build Optimization ‚úÖ\n\n- **File Size Reduction**: 60% smaller uploads via `.vercelignore`\n- **Cache Strategy**: Intelligent asset caching with must-revalidate headers\n- **Bundle Size**: Optimized through native Vite integration\n- **Load Time**: <100ms first contentful paint\n\n### 4. Documentation Consistency ‚úÖ\n\n- **Updated Files**: 15+ documentation files for Node.js 22.x\n- **Repository Consistency**: All references aligned to current tech stack\n- **Developer Experience**: Clear setup instructions with correct versions\n- **Issue Templates**: Updated with current Node.js version examples\n\n### 5. Cost Optimization Integration ‚úÖ\n\n- **VS Code Settings**: 40% token reduction through optimized context\n- **MCP Server Memory**: Reduced from 5 servers to 3 optimized instances\n- **Build Efficiency**: Native framework detection reduces compute time\n- **Hosting Costs**: Static hosting maintains minimal overhead\n\n## Technical Configuration\n\n### Current Stack\n\n### Current Stack\n\n```json\n{\n  \"framework\": \"vite\",\n  \"node\": \"22.x\",\n  \"deployment\": \"static\",\n  \"domain\": \"prospectpro.appsmithery.co\",\n  \"hosting\": \"vercel\",\n  \"discovery_apis\": [\"google_places\", \"foursquare\"],\n  \"build_time\": \"<30s\",\n  \"cold_start\": \"<100ms\"\n}\n```\n\n### Build Process\n\n```bash\n# Automated via Vercel\nnpm run build    # Vite production build\n# ‚Üí /dist directory automatically detected and deployed\n# ‚Üí Custom domain updated within 60 seconds\n```\n\n### Deployment Validation\n\n- ‚úÖ **Status**: 200 OK responses\n- ‚úÖ **SSL**: Valid certificate\n- ‚úÖ **Performance**: A+ grade caching\n- ‚úÖ **Framework**: Native Vite detection\n- ‚úÖ **Domain**: Custom domain functional\n- ‚úÖ **Business Discovery**: Google Places + Foursquare dual-source integration\n\n## MCP Server Status\n\n### Production Server (Memory Optimized)\n\n- **Tools**: 28 monitoring and analytics tools\n- **Memory**: Reduced to essential dependencies only\n- **Status**: Active and responsive\n- **Command**: `npm run mcp:prod`\n\n### Development Server\n\n- **Tools**: 8 specialized development tools\n- **Focus**: API integration and performance testing\n- **Status**: Ready for feature development\n- **Command**: `npm run mcp:dev`\n\n### Troubleshooting Server\n\n- **Tools**: 6 debugging and diagnostics tools\n- **Purpose**: Supabase and deployment diagnostics\n- **Status**: Standby for issue resolution\n- **Command**: `npm run mcp:debug`\n\n## Deployment Pipeline\n\n### Current Process (Optimized)\n\n1. **Local Development**: `npm run dev` (Supabase functions serve)\n2. **Build**: `npm run build` (Vite production bundle)\n3. **Deploy**: Automatic via Git push to main branch\n4. **Domain Update**: Custom domain reflects changes within 60s\n5. **Verification**: `npm run health:check`\n\n### Performance Metrics\n\n- **Build Time**: ~25 seconds (60% improvement)\n- **Upload Size**: 2.1MB (60% reduction via .vercelignore)\n- **Cold Start**: <100ms (native framework detection)\n- **Cache Hit Rate**: 95%+ (optimized headers)\n\n## Quality Assurance\n\n### Verified Components\n\n- ‚úÖ **Frontend Loading**: React app renders correctly\n- ‚úÖ **API Integration**: Supabase Edge Functions responsive\n- ‚úÖ **Dual-Source Discovery**: Google Places + Foursquare APIs integrated\n- ‚úÖ **Database**: RLS policies functional\n- ‚úÖ **Authentication**: Anon key synchronized\n- ‚úÖ **Custom Domain**: SSL certificate valid\n- ‚úÖ **Mobile Responsive**: UI adapts to all screen sizes\n\n### Performance Validation\n\n- ‚úÖ **Lighthouse Score**: 95+ Performance\n- ‚úÖ **First Contentful Paint**: <1s\n- ‚úÖ **Time to Interactive**: <2s\n- ‚úÖ **Cumulative Layout Shift**: <0.1\n\n## Cost Analysis\n\n### Optimization Results\n\n| Component       | Before     | After      | Savings |\n| --------------- | ---------- | ---------- | ------- |\n| VS Code Context | 500 tokens | 150 tokens | 70%     |\n| MCP Memory      | 5 servers  | 3 servers  | 40%     |\n| Build Time      | 45s        | 25s        | 44%     |\n| Upload Size     | 5.2MB      | 2.1MB      | 60%     |\n\n### Monthly Cost Projection\n\n- **Vercel Hosting**: $0 (within free tier limits)\n- **Custom Domain**: $0 (existing domain)\n- **Supabase**: $0 (within free tier limits)\n- **Total Infrastructure**: $0/month\n\n## Next Steps\n\n### Immediate Maintenance\n\n- Monitor Vercel deployment logs for any issues\n- Track Node.js 22.x compatibility across dependencies\n- Validate Edge Function performance under load\n\n### Future Optimizations\n\n- Consider Vercel Edge Runtime for additional performance\n- Implement Vercel Analytics for detailed performance metrics\n- Explore Vercel Image Optimization for asset delivery\n\n### Documentation Maintenance\n\n- Keep Node.js version references current\n- Update performance benchmarks quarterly\n- Maintain deployment guide accuracy\n\n## Troubleshooting Quick Reference\n\n### Common Issues & Solutions\n\n1. **Blank Page**: Check custom domain cache, may need 5-10 minutes\n2. **Build Errors**: Verify Node.js 22.x in environment\n3. **API Errors**: Validate Supabase anon key synchronization\n4. **Performance**: Check .vercelignore for unnecessary uploads\n\n### Emergency Commands\n\n```bash\n# Health check\ncurl -I https://prospectpro.appsmithery.co/\n\n# Force redeploy\ngit commit --allow-empty -m \"Force redeploy\" && git push\n\n# Local testing\nnpm run build && npm run preview\n\n# MCP diagnostics\nnpm run mcp:debug\n```\n\n## Completion Verification\n\n**All optimization targets achieved:**\n\n- ‚úÖ 40% reduction in development costs (VS Code + MCP)\n- ‚úÖ 60% improvement in build efficiency (.vercelignore)\n- ‚úÖ 100% documentation consistency (Node.js 22.x)\n- ‚úÖ Native framework optimization (Vercel Vite detection)\n- ‚úÖ Production deployment stability (custom domain functional)\n\n**Project Status**: Ready for production workloads with optimized cost structure and enhanced performance.\n"}}},
{"type":"measure","name":"lsp.did_open","count":22,"duration":0.095},
{"type":"mark","name":"lsp.did_open","count":23,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/components/TierSelector.tsx","languageId":"typescriptreact","version":1,"text":"import React from \"react\";\nimport { ENRICHMENT_TIERS } from \"../lib/supabase\";\n\ninterface TierSelectorProps {\n  selectedTier: keyof typeof ENRICHMENT_TIERS;\n  onTierChange: (tier: keyof typeof ENRICHMENT_TIERS) => void;\n  numberOfLeads: number;\n}\n\nconst tierDataImprovements = {\n  STARTER: [\n    \"Business verification\",\n    \"Company data\",\n    \"Phone & website validation\",\n  ],\n  PROFESSIONAL: [\n    \"Business verification\",\n    \"Company data\",\n    \"Phone & website validation\",\n    \"Professional email discovery\",\n  ],\n  ENTERPRISE: [\n    \"Business verification\",\n    \"Company data\",\n    \"Phone & website validation\",\n    \"Professional email discovery\",\n    \"Email deliverability verification\",\n  ],\n  COMPLIANCE: [\n    \"Business verification\",\n    \"Company data\",\n    \"Phone & website validation\",\n    \"Professional email discovery\",\n    \"Email deliverability verification\",\n    \"Executive contact enrichment\",\n  ],\n};\n\nexport const TierSelector: React.FC<TierSelectorProps> = ({\n  selectedTier,\n  onTierChange,\n  numberOfLeads,\n}) => {\n  const formatUnitCost = (price: number): string => {\n    if (price >= 1) return `$${price.toFixed(2)}`;\n    if (price >= 0.01) return `$${price.toFixed(3)}`;\n    return `$${price.toFixed(4)}`;\n  };\n\n  return (\n    <div>\n      <label className=\"block text-sm font-medium text-gray-700 mb-3\">\n        Progressive Enrichment Tiers\n      </label>\n\n      {/* Single column, table-style layout */}\n      <div className=\"space-y-2\">\n        {Object.entries(ENRICHMENT_TIERS).map(([key, tier]) => {\n          const tierKey = key as keyof typeof ENRICHMENT_TIERS;\n          const totalCost = numberOfLeads * tier.price;\n          const improvements = tierDataImprovements[tierKey];\n\n          return (\n            <div\n              key={key}\n              className={`rounded-lg p-4 cursor-pointer transition-all border-l-4 ${\n                selectedTier === key\n                  ? \"bg-blue-50 border-l-blue-500 shadow-md\"\n                  : \"bg-gray-50 border-l-gray-200 hover:bg-gray-100 hover:border-l-gray-300\"\n              }`}\n              onClick={() => onTierChange(tierKey)}\n            >\n              <div className=\"flex items-center justify-between mb-3\">\n                <div className=\"flex items-center space-x-3\">\n                  <h3 className=\"text-lg font-semibold text-gray-900\">\n                    {tier.name}\n                  </h3>\n                  <div className=\"text-sm text-gray-500\">\n                    {formatUnitCost(tier.price)} per lead\n                  </div>\n                  {selectedTier === key && (\n                    <div className=\"flex items-center text-sm text-blue-600\">\n                      <svg\n                        className=\"w-4 h-4 mr-1\"\n                        fill=\"currentColor\"\n                        viewBox=\"0 0 20 20\"\n                      >\n                        <path\n                          fillRule=\"evenodd\"\n                          d=\"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z\"\n                          clipRule=\"evenodd\"\n                        />\n                      </svg>\n                      Selected\n                    </div>\n                  )}\n                </div>\n                <div className=\"text-right\">\n                  <div className=\"text-2xl font-bold text-blue-600\">\n                    ${totalCost.toFixed(2)}\n                  </div>\n                  <div className=\"text-xs text-gray-500\">Total cost</div>\n                </div>\n              </div>\n\n              <div className=\"flex items-start justify-between\">\n                <div className=\"flex-1\">\n                  <div className=\"text-sm text-gray-600 mb-2\">\n                    {tier.description}\n                  </div>\n\n                  {/* Data Improvements in horizontal layout */}\n                  <div className=\"flex flex-wrap gap-2\">\n                    {improvements.map((improvement, index) => (\n                      <div\n                        key={index}\n                        className=\"flex items-center text-xs bg-white rounded-full px-2 py-1 border\"\n                      >\n                        <svg\n                          className=\"w-3 h-3 text-green-500 mr-1 flex-shrink-0\"\n                          fill=\"currentColor\"\n                          viewBox=\"0 0 20 20\"\n                        >\n                          <path\n                            fillRule=\"evenodd\"\n                            d=\"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z\"\n                            clipRule=\"evenodd\"\n                          />\n                        </svg>\n                        <span className=\"text-gray-700\">{improvement}</span>\n                      </div>\n                    ))}\n                  </div>\n                </div>\n              </div>\n            </div>\n          );\n        })}\n      </div>\n\n      <div className=\"mt-4 p-3 bg-yellow-50 border border-yellow-200 rounded-md\">\n        <div className=\"flex items-center\">\n          <svg\n            className=\"w-5 h-5 text-yellow-500 mr-2\"\n            fill=\"currentColor\"\n            viewBox=\"0 0 20 20\"\n          >\n            <path\n              fillRule=\"evenodd\"\n              d=\"M8.257 3.099c.765-1.36 2.722-1.36 3.486 0l5.58 9.92c.75 1.334-.213 2.98-1.742 2.98H4.42c-1.53 0-2.493-1.646-1.743-2.98l5.58-9.92zM11 13a1 1 0 11-2 0 1 1 0 012 0zm-1-8a1 1 0 00-1 1v3a1 1 0 002 0V6a1 1 0 00-1-1z\"\n              clipRule=\"evenodd\"\n            />\n          </svg>\n          <div className=\"text-sm text-yellow-700\">\n            <strong>Actual API costs</strong> - Pricing may vary based on API\n            response complexity and data availability\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n"}}},
{"type":"measure","name":"lsp.did_open","count":23,"duration":3.381},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":3,"duration":0.119},
{"type":"mark","name":"lsp.did_open","count":24,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/pages/BusinessDiscovery.tsx","languageId":"typescriptreact","version":1,"text":"import React, { useEffect, useState } from \"react\";\nimport { useNavigate } from \"react-router-dom\";\nimport { ProgressDisplay } from \"../components/ProgressDisplay\";\nimport { TierSelector } from \"../components/TierSelector\";\nimport { useBusinessDiscovery } from \"../hooks/useBusinessDiscovery\";\nimport { ENRICHMENT_TIERS } from \"../lib/supabase\";\n\nconst businessCategories = [\n  \"Automotive Services\",\n  \"Education & Training\",\n  \"Entertainment & Recreation\",\n  \"Financial Services\",\n  \"Food & Dining\",\n  \"Government & Public Services\",\n  \"Healthcare & Medical\",\n  \"Home & Property Services\",\n  \"Hospitality & Lodging\",\n  \"Personal Care & Beauty\",\n  \"Professional Services\",\n  \"Religious & Community\",\n  \"Retail & Shopping\",\n  \"Technology & IT Services\",\n  \"Transportation & Transit\",\n];\n\nconst businessTypesByCategory: Record<string, string[]> = {\n  \"Automotive Services\": [\n    \"Auto Body Shop\",\n    \"Auto Detailing\",\n    \"Auto Parts Store\",\n    \"Automotive Glass Service\",\n    \"Car Dealer\",\n    \"Car Rental\",\n    \"Car Repair\",\n    \"Car Wash\",\n    \"Electric Vehicle Charging Station\",\n    \"Gas Station\",\n    \"Motorcycle Dealer\",\n    \"Oil Change Service\",\n    \"Rv Dealer\",\n    \"Smog Check Station\",\n    \"Tire Shop\",\n    \"Towing Service\",\n    \"Transmission Shop\",\n    \"Truck Dealer\",\n  ],\n  \"Education & Training\": [\n    \"Art School\",\n    \"Charter School\",\n    \"College\",\n    \"Community College\",\n    \"Cooking School\",\n    \"Dance Studio\",\n    \"Daycare\",\n    \"Driving School\",\n    \"Kindergarten\",\n    \"Language School\",\n    \"Library\",\n    \"Music School\",\n    \"Preschool\",\n    \"Primary School\",\n    \"Private School\",\n    \"Public School\",\n    \"School\",\n    \"Secondary School\",\n    \"Summer Camp Organizer\",\n    \"Technical School\",\n    \"Training Center\",\n    \"Tutoring Center\",\n    \"University\",\n    \"Vocational School\",\n  ],\n  \"Entertainment & Recreation\": [\n    \"Amusement Park\",\n    \"Aquarium\",\n    \"Arcade\",\n    \"Arena\",\n    \"Art Gallery\",\n    \"Banquet Hall\",\n    \"Beach\",\n    \"Botanical Garden\",\n    \"Bowling Alley\",\n    \"Casino\",\n    \"Comedy Club\",\n    \"Concert Hall\",\n    \"Convention Center\",\n    \"Escape Room\",\n    \"Event Venue\",\n    \"Fitness Center\",\n    \"Golf Course\",\n    \"Gym\",\n    \"Karaoke Venue\",\n    \"Marina\",\n    \"Mini Golf\",\n    \"Movie Theater\",\n    \"Museum\",\n    \"Night Club\",\n    \"Paintball\",\n    \"Park\",\n    \"Rock Climbing Gym\",\n    \"Ski Resort\",\n    \"Sports Complex\",\n    \"Stadium\",\n    \"Swimming Pool\",\n    \"Tennis Court\",\n    \"Theater\",\n    \"Tourist Attraction\",\n    \"Trampoline Park\",\n    \"Wedding Venue\",\n    \"Yoga Studio\",\n    \"Zoo\",\n  ],\n  \"Financial Services\": [\n    \"Atm\",\n    \"Bank\",\n    \"Check Cashing Service\",\n    \"Credit Union\",\n    \"Cryptocurrency Exchange\",\n    \"Financial Planner\",\n    \"Investment Firm\",\n    \"Money Transfer Service\",\n    \"Mortgage Broker\",\n    \"Payday Lender\",\n    \"Stock Broker\",\n  ],\n  \"Food & Dining\": [\n    \"Bakery\",\n    \"Bar\",\n    \"Barbecue Restaurant\",\n    \"Brewery\",\n    \"Brunch Restaurant\",\n    \"Buffet\",\n    \"Burger Joint\",\n    \"Cafe\",\n    \"Catering Service\",\n    \"Chinese Restaurant\",\n    \"Cocktail Bar\",\n    \"Coffee Shop\",\n    \"Deli\",\n    \"Dessert Shop\",\n    \"Distillery\",\n    \"Donut Shop\",\n    \"Fast Food Restaurant\",\n    \"Food Court\",\n    \"Food Stand\",\n    \"Food Truck\",\n    \"Ice Cream Shop\",\n    \"Indian Restaurant\",\n    \"Italian Restaurant\",\n    \"Japanese Restaurant\",\n    \"Juice Bar\",\n    \"Meal Delivery\",\n    \"Meal Takeaway\",\n    \"Mexican Restaurant\",\n    \"Pizza Restaurant\",\n    \"Pub\",\n    \"Restaurant\",\n    \"Sandwich Shop\",\n    \"Seafood Restaurant\",\n    \"Smoothie Shop\",\n    \"Steakhouse\",\n    \"Sushi Restaurant\",\n    \"Taco Place\",\n    \"Tea House\",\n    \"Wine Bar\",\n    \"Winery\",\n  ],\n  \"Government & Public Services\": [\n    \"City Hall\",\n    \"Consulate\",\n    \"Courthouse\",\n    \"County Office\",\n    \"Dmv\",\n    \"Embassy\",\n    \"Fire Station\",\n    \"Government Office\",\n    \"Municipal Building\",\n    \"Passport Office\",\n    \"Police Station\",\n    \"Post Office\",\n    \"Public Library\",\n    \"Public School\",\n    \"Public Works\",\n    \"Social Services Office\",\n    \"Tax Office\",\n    \"Voter Registration Office\",\n  ],\n  \"Healthcare & Medical\": [\n    \"Acupuncture Clinic\",\n    \"Chiropractor\",\n    \"Dental Clinic\",\n    \"Dentist\",\n    \"Doctor\",\n    \"Drugstore\",\n    \"Health Insurance Office\",\n    \"Hospital\",\n    \"Medical Center\",\n    \"Medical Equipment Supplier\",\n    \"Medical Lab\",\n    \"Mental Health Clinic\",\n    \"Occupational Therapist\",\n    \"Optical Clinic\",\n    \"Optometrist\",\n    \"Orthodontist\",\n    \"Pharmacy\",\n    \"Physical Therapy\",\n    \"Physiotherapist\",\n    \"Psychiatrist\",\n    \"Psychologist\",\n    \"Skin Care Clinic\",\n    \"Speech Therapist\",\n    \"Urgent Care\",\n    \"Veterinary Care\",\n    \"Wellness Center\",\n  ],\n  \"Home & Property Services\": [\n    \"Appliance Repair\",\n    \"Carpet Cleaning\",\n    \"Cleaning Service\",\n    \"Dry Cleaning\",\n    \"Electrician\",\n    \"Fence Contractor\",\n    \"Flooring Contractor\",\n    \"Gardener\",\n    \"General Contractor\",\n    \"Gutter Service\",\n    \"Handyman\",\n    \"Home Inspector\",\n    \"Hvac Contractor\",\n    \"Landscaping\",\n    \"Laundry\",\n    \"Locksmith\",\n    \"Moving Company\",\n    \"Painter\",\n    \"Pest Control\",\n    \"Plumber\",\n    \"Pool Service\",\n    \"Property Management\",\n    \"Roofing Contractor\",\n    \"Storage\",\n    \"Window Cleaning\",\n  ],\n  \"Hospitality & Lodging\": [\n    \"Bed And Breakfast\",\n    \"Boutique Hotel\",\n    \"Campground\",\n    \"Extended Stay Hotel\",\n    \"Guest House\",\n    \"Hostel\",\n    \"Hotel\",\n    \"Inn\",\n    \"Lodge\",\n    \"Motel\",\n    \"Resort\",\n    \"Rv Park\",\n    \"Vacation Rental\",\n  ],\n  \"Personal Care & Beauty\": [\n    \"Barber Shop\",\n    \"Beauty Salon\",\n    \"Beautician\",\n    \"Body Art Service\",\n    \"Cosmetics Store\",\n    \"Day Spa\",\n    \"Eyebrow Threading\",\n    \"Facial Spa\",\n    \"Hair Care\",\n    \"Hair Salon\",\n    \"Makeup Artist\",\n    \"Massage\",\n    \"Nail Salon\",\n    \"Piercing Shop\",\n    \"Sauna\",\n    \"Spa\",\n    \"Tanning Studio\",\n    \"Tattoo Parlor\",\n    \"Waxing Salon\",\n  ],\n  \"Professional Services\": [\n    \"Accounting\",\n    \"Advertising Agency\",\n    \"Architecture Firm\",\n    \"Attorney\",\n    \"Business Center\",\n    \"Consultant\",\n    \"Corporate Office\",\n    \"Employment Agency\",\n    \"Engineering Office\",\n    \"Financial Advisor\",\n    \"Insurance Agency\",\n    \"Lawyer\",\n    \"Marketing Agency\",\n    \"Notary\",\n    \"Real Estate Agency\",\n    \"Recruiter\",\n    \"Tax Preparation\",\n  ],\n  \"Religious & Community\": [\n    \"Cemetery\",\n    \"Church\",\n    \"Civic Organization\",\n    \"Community Center\",\n    \"Crematorium\",\n    \"Funeral Home\",\n    \"Meditation Center\",\n    \"Mosque\",\n    \"Non-Profit Organization\",\n    \"Place Of Worship\",\n    \"Religious Center\",\n    \"Social Club\",\n    \"Spiritual Center\",\n    \"Synagogue\",\n    \"Temple\",\n  ],\n  \"Retail & Shopping\": [\n    \"Antique Shop\",\n    \"Art Supply Store\",\n    \"Bicycle Store\",\n    \"Book Store\",\n    \"Boutique\",\n    \"Clothing Store\",\n    \"Convenience Store\",\n    \"Craft Store\",\n    \"Department Store\",\n    \"Discount Store\",\n    \"Dollar Store\",\n    \"Electronics Store\",\n    \"Florist\",\n    \"Furniture Store\",\n    \"Garden Center\",\n    \"Gift Shop\",\n    \"Grocery Store\",\n    \"Hardware Store\",\n    \"Hobby Shop\",\n    \"Home Goods Store\",\n    \"Jewelry Store\",\n    \"Liquor Store\",\n    \"Music Store\",\n    \"Office Supply Store\",\n    \"Optical Store\",\n    \"Outlet Store\",\n    \"Party Supply Store\",\n    \"Pet Store\",\n    \"Second Hand Store\",\n    \"Shoe Store\",\n    \"Shopping Mall\",\n    \"Sporting Goods Store\",\n    \"Supermarket\",\n    \"Thrift Store\",\n    \"Tobacco Shop\",\n    \"Toy Store\",\n    \"Vape Shop\",\n  ],\n  \"Technology & IT Services\": [\n    \"App Development\",\n    \"Cell Phone Store\",\n    \"Co-Working Space\",\n    \"Computer Repair\",\n    \"Cybersecurity Firm\",\n    \"Data Center\",\n    \"Internet Cafe\",\n    \"It Services\",\n    \"Managed Services Provider\",\n    \"Software Company\",\n    \"Tech Support\",\n    \"Telecommunications Service Provider\",\n    \"Web Design\",\n  ],\n  \"Transportation & Transit\": [\n    \"Airport\",\n    \"Bike Rental\",\n    \"Bus Station\",\n    \"Bus Tour Agency\",\n    \"Car Sharing\",\n    \"Cruise Agency\",\n    \"Ferry Terminal\",\n    \"Limousine Service\",\n    \"Parking Garage\",\n    \"Parking Lot\",\n    \"Rest Area\",\n    \"Ride Share Location\",\n    \"Scooter Rental\",\n    \"Shuttle Service\",\n    \"Subway Station\",\n    \"Taxi Stand\",\n    \"Train Station\",\n    \"Travel Agency\",\n    \"Truck Stop\",\n  ],\n};\n\nexport const BusinessDiscovery: React.FC = () => {\n  const navigate = useNavigate();\n  const {\n    startDiscovery,\n    isDiscovering,\n    progress,\n    currentStage,\n    cacheStats,\n    error,\n  } = useBusinessDiscovery();\n\n  const [selectedCategory, setSelectedCategory] = useState(\n    \"Home & Property Services\"\n  );\n  const [selectedBusinessType, setSelectedBusinessType] =\n    useState(\"Electrician\");\n  const [keywords, setKeywords] = useState(\"\");\n  const [location, setLocation] = useState(\"New York, NY\");\n  const [searchRadius, setSearchRadius] = useState(\"10 miles\");\n  const [expandGeography, setExpandGeography] = useState(false);\n  const [numberOfLeads, setNumberOfLeads] = useState(3);\n\n  // Progressive enrichment tier selection\n  const [selectedTier, setSelectedTier] =\n    useState<keyof typeof ENRICHMENT_TIERS>(\"PROFESSIONAL\");\n\n  // Navigate to campaign page when discovery starts\n  useEffect(() => {\n    if (isDiscovering) {\n      console.log(\"üöÄ Campaign started, navigating to campaign page...\");\n      navigate(\"/campaign\");\n    }\n  }, [isDiscovering, navigate]);\n\n  const availableBusinessTypes =\n    businessTypesByCategory[selectedCategory] || [];\n\n  const currentTierConfig = ENRICHMENT_TIERS[selectedTier];\n  const estimatedCost = numberOfLeads * currentTierConfig.price;\n\n  const handleSearch = () => {\n    if (!location.trim()) {\n      alert(\"Please enter a location\");\n      return;\n    }\n\n    const config = {\n      search_terms: `${selectedBusinessType} ${keywords}`.trim(),\n      location: location.trim(),\n      business_type: selectedBusinessType,\n      budget_limit: estimatedCost,\n      max_results: numberOfLeads,\n      include_email_validation:\n        selectedTier === \"ENTERPRISE\" || selectedTier === \"COMPLIANCE\",\n      include_website_validation: true,\n      min_confidence_score: 70,\n      chamber_verification: true, // Always enabled based on tier\n      trade_association: true, // Always enabled based on tier\n      professional_license: true, // Always enabled based on tier\n      selectedTier: selectedTier,\n    };\n\n    console.log(\"üöÄ Starting campaign:\", config);\n    startDiscovery(config);\n  };\n\n  return (\n    <div className=\"bg-white rounded-lg shadow-sm\">\n      <div className=\"p-6 space-y-6\">\n        {/* Business Category */}\n        <div>\n          <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n            Business Category\n          </label>\n          <select\n            value={selectedCategory}\n            onChange={(e) => {\n              setSelectedCategory(e.target.value);\n              const types = businessTypesByCategory[e.target.value];\n              if (types && types.length > 0) {\n                setSelectedBusinessType(types[0]);\n              }\n            }}\n            className=\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-blue-500 focus:border-blue-500\"\n          >\n            {businessCategories.map((category) => (\n              <option key={category} value={category}>\n                {category}\n              </option>\n            ))}\n          </select>\n        </div>\n\n        {/* Business Type */}\n        <div>\n          <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n            Business Type\n          </label>\n          <select\n            value={selectedBusinessType}\n            onChange={(e) => setSelectedBusinessType(e.target.value)}\n            className=\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-blue-500 focus:border-blue-500\"\n          >\n            {availableBusinessTypes.map((type) => (\n              <option key={type} value={type}>\n                {type}\n              </option>\n            ))}\n          </select>\n        </div>\n\n        {/* Additional Keywords */}\n        <div>\n          <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n            Additional Keywords (Optional)\n          </label>\n          <input\n            type=\"text\"\n            value={keywords}\n            onChange={(e) => setKeywords(e.target.value)}\n            placeholder=\"e.g., luxury, organic, 24-hour (comma-separated)\"\n            className=\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-blue-500 focus:border-blue-500\"\n          />\n          <p className=\"text-xs text-gray-500 mt-1\">\n            Add comma-separated keywords to refine your search\n          </p>\n        </div>\n\n        {/* Location */}\n        <div>\n          <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n            Location\n          </label>\n          <input\n            type=\"text\"\n            value={location}\n            onChange={(e) => setLocation(e.target.value)}\n            placeholder=\"e.g., San Francisco, CA or New York, NY\"\n            className=\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-blue-500 focus:border-blue-500 bg-blue-50\"\n          />\n\n          <div className=\"mt-4 space-y-3\">\n            <div>\n              <label className=\"block text-sm font-medium text-gray-700 mb-1\">\n                Search Radius:\n              </label>\n              <select\n                value={searchRadius}\n                onChange={(e) => setSearchRadius(e.target.value)}\n                className=\"px-3 py-2 border border-gray-300 rounded-md focus:ring-blue-500 focus:border-blue-500\"\n              >\n                <option value=\"5 miles\">5 miles</option>\n                <option value=\"10 miles\">10 miles</option>\n                <option value=\"25 miles\">25 miles</option>\n                <option value=\"50 miles\">50 miles</option>\n                <option value=\"100 miles\">100 miles</option>\n              </select>\n            </div>\n\n            <div className=\"flex items-center\">\n              <input\n                type=\"checkbox\"\n                id=\"expandGeography\"\n                checked={expandGeography}\n                onChange={(e) => setExpandGeography(e.target.checked)}\n                className=\"h-4 w-4 text-blue-600 focus:ring-blue-500 border-gray-300 rounded\"\n              />\n              <label\n                htmlFor=\"expandGeography\"\n                className=\"ml-2 text-sm text-gray-700\"\n              >\n                Expand geography automatically if initial results are limited\n              </label>\n            </div>\n          </div>\n        </div>\n\n        {/* Progressive Enrichment Tier Selection */}\n        <TierSelector\n          selectedTier={selectedTier}\n          onTierChange={setSelectedTier}\n          numberOfLeads={numberOfLeads}\n        />\n\n        {/* Number of Leads */}\n        <div>\n          <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n            Number of Leads\n          </label>\n          <div className=\"flex items-center space-x-4\">\n            <input\n              type=\"range\"\n              min=\"1\"\n              max=\"10\"\n              value={numberOfLeads}\n              onChange={(e) => setNumberOfLeads(parseInt(e.target.value))}\n              className=\"flex-1 h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer slider\"\n              style={{\n                background: `linear-gradient(to right, #f59e0b 0%, #f59e0b ${\n                  numberOfLeads * 10\n                }%, #e5e7eb ${numberOfLeads * 10}%, #e5e7eb 100%)`,\n              }}\n            />\n            <div className=\"bg-blue-500 text-white px-3 py-1 rounded-full text-sm font-medium min-w-fit\">\n              {numberOfLeads} leads\n            </div>\n          </div>\n        </div>\n\n        {/* Actual Cost Display */}\n        <div className=\"bg-gradient-to-r from-blue-50 to-green-50 p-4 rounded-lg border border-blue-200\">\n          <div className=\"flex items-center justify-between\">\n            <div>\n              <h3 className=\"text-sm font-medium text-gray-900 mb-1\">\n                Actual Cost ({currentTierConfig.name} Tier)\n              </h3>\n              <div className=\"text-xs text-gray-600\">\n                {numberOfLeads} leads √ó ${currentTierConfig.price} per lead\n              </div>\n            </div>\n            <div className=\"text-right\">\n              <div className=\"text-2xl font-bold text-blue-600\">\n                ${estimatedCost.toFixed(2)}\n              </div>\n              <div className=\"text-xs text-gray-600\">Transparent pricing</div>\n            </div>\n          </div>\n        </div>\n\n        {/* Progress Display */}\n        <ProgressDisplay\n          isDiscovering={isDiscovering}\n          progress={progress}\n          currentStage={currentStage}\n          cacheStats={cacheStats}\n        />\n\n        {/* Start Discovery Button */}\n        <div className=\"pt-4\">\n          <button\n            type=\"button\"\n            onClick={handleSearch}\n            disabled={isDiscovering}\n            className=\"w-full bg-blue-600 hover:bg-blue-700 text-white font-medium py-3 px-4 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 disabled:opacity-50 disabled:cursor-not-allowed\"\n          >\n            {isDiscovering ? (\n              <>\n                <svg\n                  className=\"animate-spin -ml-1 mr-3 h-5 w-5 text-white inline\"\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                  fill=\"none\"\n                  viewBox=\"0 0 24 24\"\n                >\n                  <circle\n                    className=\"opacity-25\"\n                    cx=\"12\"\n                    cy=\"12\"\n                    r=\"10\"\n                    stroke=\"currentColor\"\n                    strokeWidth=\"4\"\n                  ></circle>\n                  <path\n                    className=\"opacity-75\"\n                    fill=\"currentColor\"\n                    d=\"M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z\"\n                  ></path>\n                </svg>\n                Running Campaign ({progress}%)\n              </>\n            ) : (\n              \"Run Campaign\"\n            )}\n          </button>\n        </div>\n\n        {/* Error Display */}\n        {error && (\n          <div className=\"mt-4 p-4 bg-red-50 border border-red-200 rounded-md\">\n            <div className=\"flex\">\n              <div className=\"flex-shrink-0\">\n                <svg\n                  className=\"h-5 w-5 text-red-400\"\n                  viewBox=\"0 0 20 20\"\n                  fill=\"currentColor\"\n                >\n                  <path\n                    fillRule=\"evenodd\"\n                    d=\"M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z\"\n                    clipRule=\"evenodd\"\n                  />\n                </svg>\n              </div>\n              <div className=\"ml-3\">\n                <h3 className=\"text-sm font-medium text-red-800\">\n                  Discovery Failed\n                </h3>\n                <div className=\"mt-2 text-sm text-red-700\">\n                  <p>\n                    {error instanceof Error ? error.message : String(error)}\n                  </p>\n                </div>\n              </div>\n            </div>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n};\n"}}},
{"type":"measure","name":"lsp.did_open","count":24,"duration":5.95},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":4,"duration":0.142},
{"type":"mark","name":"lsp.did_open","count":25,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/pages/Campaign.tsx","languageId":"typescriptreact","version":1,"text":"import React, { useEffect, useState } from \"react\";\nimport { useNavigate, useSearchParams } from \"react-router-dom\";\nimport { ProgressDisplay } from \"../components/ProgressDisplay\";\nimport { useBusinessDiscovery } from \"../hooks/useBusinessDiscovery\";\nimport { useCampaignStore } from \"../stores/campaignStore\";\nimport type { BusinessLead } from \"../types\";\n\nexport const Campaign: React.FC = () => {\n  const navigate = useNavigate();\n  const [searchParams] = useSearchParams();\n  const campaignId = searchParams.get(\"id\");\n  const { currentCampaign, campaigns, leads, setCurrentCampaign } =\n    useCampaignStore();\n  const { isDiscovering, progress, currentStage, cacheStats, error } =\n    useBusinessDiscovery();\n  const [showResults, setShowResults] = useState(false);\n\n  // Filter leads for current campaign\n  const campaignLeads = currentCampaign\n    ? leads.filter((lead) => lead.campaign_id === currentCampaign.campaign_id)\n    : [];\n\n  // Load specific campaign from URL parameter\n  useEffect(() => {\n    if (campaignId && !currentCampaign) {\n      const campaign = campaigns.find((c) => c.campaign_id === campaignId);\n      if (campaign) {\n        setCurrentCampaign(campaign);\n        setShowResults(true);\n      }\n    }\n  }, [campaignId, campaigns, currentCampaign, setCurrentCampaign]);\n\n  // Show results when campaign completes\n  useEffect(() => {\n    if (\n      currentCampaign &&\n      currentCampaign.status === \"completed\" &&\n      campaignLeads.length > 0\n    ) {\n      setShowResults(true);\n    }\n  }, [currentCampaign, campaignLeads]);\n\n  // If no campaign is running or found, redirect to discovery\n  useEffect(() => {\n    if (!isDiscovering && !currentCampaign && !campaignId) {\n      navigate(\"/discovery\");\n    } else if (\n      campaignId &&\n      !campaigns.find((c) => c.campaign_id === campaignId)\n    ) {\n      // Campaign ID provided but not found\n      navigate(\"/discovery\");\n    }\n  }, [isDiscovering, currentCampaign, campaignId, campaigns, navigate]);\n\n  const exportToCsv = () => {\n    if (!campaignLeads.length) return;\n\n    // Determine if this campaign has ownership data\n    const hasOwnershipData =\n      currentCampaign?.tier_used === \"Compliance\" ||\n      campaignLeads.some((lead) => lead.enrichment_tier === \"Compliance\");\n\n    // Base CSV headers\n    const baseHeaders = [\n      \"Business Name\",\n      \"Address\",\n      \"Phone\",\n      \"Website\",\n      \"Email\",\n      \"Confidence Score\",\n      \"Validation Status\",\n      \"Cost to Acquire\",\n      \"Data Sources\",\n      \"Enrichment Tier\",\n    ];\n\n    // Add ownership columns for Compliance tier\n    const headers = hasOwnershipData\n      ? [\n          ...baseHeaders,\n          \"Owner Name\",\n          \"Owner Email\",\n          \"Owner Phone\",\n          \"Owner Confidence Score\",\n        ]\n      : baseHeaders;\n\n    // Convert leads to CSV format with conditional ownership data\n    const csvContent = [\n      headers.join(\",\"),\n      ...campaignLeads.map((lead: BusinessLead) => {\n        const baseRow = [\n          `\"${lead.business_name || \"\"}\"`,\n          `\"${lead.address || \"\"}\"`,\n          `\"${lead.phone || \"\"}\"`,\n          `\"${lead.website || \"\"}\"`,\n          `\"${lead.email || \"\"}\"`,\n          lead.confidence_score || 0,\n          `\"${lead.validation_status || \"\"}\"`,\n          `$${(lead.cost_to_acquire || 0).toFixed(3)}`,\n          `\"${(lead.data_sources || []).join(\"; \")}\"`,\n          `\"${lead.enrichment_tier || \"\"}\"`,\n        ];\n\n        // Add ownership data if available\n        if (hasOwnershipData) {\n          const ownerData = (lead as any).owner_data || {};\n          baseRow.push(\n            `\"${ownerData.name || \"\"}\"`,\n            `\"${ownerData.email || \"\"}\"`,\n            `\"${ownerData.phone || \"\"}\"`,\n            ownerData.confidence_score || 0\n          );\n        }\n\n        return baseRow.join(\",\");\n      }),\n    ].join(\"\\n\");\n\n    // Download CSV file\n    const blob = new Blob([csvContent], { type: \"text/csv;charset=utf-8;\" });\n    const link = document.createElement(\"a\");\n    const url = URL.createObjectURL(blob);\n    link.setAttribute(\"href\", url);\n    link.setAttribute(\n      \"download\",\n      `campaign-${currentCampaign?.campaign_id || Date.now()}-results.csv`\n    );\n    link.style.visibility = \"hidden\";\n    document.body.appendChild(link);\n    link.click();\n    document.body.removeChild(link);\n  };\n\n  return (\n    <div className=\"space-y-6\">\n      {/* Campaign Header */}\n      <div className=\"bg-white rounded-lg shadow-sm p-6\">\n        <div className=\"flex items-center justify-between\">\n          <div>\n            <h1 className=\"text-2xl font-bold text-gray-900\">\n              Campaign Progress\n            </h1>\n            <p className=\"text-gray-600 mt-1\">\n              {currentCampaign\n                ? `Campaign ${currentCampaign.campaign_id}`\n                : \"Running campaign...\"}\n            </p>\n          </div>\n          <div className=\"flex space-x-3\">\n            <button\n              onClick={() => navigate(\"/discovery\")}\n              className=\"px-4 py-2 text-gray-600 bg-gray-100 rounded-md hover:bg-gray-200\"\n            >\n              Back to Discovery\n            </button>\n            {showResults && (\n              <button\n                onClick={exportToCsv}\n                className=\"px-4 py-2 bg-green-600 text-white rounded-md hover:bg-green-700\"\n              >\n                Export CSV\n              </button>\n            )}\n          </div>\n        </div>\n      </div>\n\n      {/* Progress Display */}\n      {isDiscovering && (\n        <div className=\"bg-white rounded-lg shadow-sm p-6\">\n          <ProgressDisplay\n            isDiscovering={isDiscovering}\n            progress={progress}\n            currentStage={currentStage}\n            cacheStats={cacheStats}\n          />\n        </div>\n      )}\n\n      {/* Campaign Summary */}\n      {currentCampaign && (\n        <div className=\"bg-white rounded-lg shadow-sm p-6\">\n          <h2 className=\"text-lg font-semibold text-gray-900 mb-4\">\n            Campaign Summary\n          </h2>\n          <div className=\"grid grid-cols-1 md:grid-cols-4 gap-4\">\n            <div className=\"bg-blue-50 p-4 rounded-lg\">\n              <div className=\"text-sm text-blue-600 font-medium\">Status</div>\n              <div className=\"text-lg font-bold text-blue-900 capitalize\">\n                {currentCampaign.status}\n              </div>\n            </div>\n            <div className=\"bg-green-50 p-4 rounded-lg\">\n              <div className=\"text-sm text-green-600 font-medium\">\n                Leads Found\n              </div>\n              <div className=\"text-lg font-bold text-green-900\">\n                {currentCampaign.leads_found || 0}\n              </div>\n            </div>\n            <div className=\"bg-yellow-50 p-4 rounded-lg\">\n              <div className=\"text-sm text-yellow-600 font-medium\">\n                Qualified\n              </div>\n              <div className=\"text-lg font-bold text-yellow-900\">\n                {currentCampaign.leads_qualified || 0}\n              </div>\n            </div>\n            <div className=\"bg-purple-50 p-4 rounded-lg\">\n              <div className=\"text-sm text-purple-600 font-medium\">\n                Total Cost\n              </div>\n              <div className=\"text-lg font-bold text-purple-900\">\n                ${(currentCampaign.total_cost || 0).toFixed(2)}\n              </div>\n            </div>\n          </div>\n        </div>\n      )}\n\n      {/* Results Table */}\n      {showResults && campaignLeads.length > 0 && (\n        <div className=\"bg-white rounded-lg shadow-sm overflow-hidden\">\n          <div className=\"px-6 py-4 border-b border-gray-200\">\n            <div className=\"flex items-center justify-between\">\n              <h2 className=\"text-lg font-semibold text-gray-900\">\n                Campaign Results\n              </h2>\n              <div className=\"text-sm text-gray-500\">\n                {campaignLeads.length} leads found\n              </div>\n            </div>\n          </div>\n\n          <div className=\"overflow-x-auto\">\n            <table className=\"min-w-full divide-y divide-gray-200\">\n              <thead className=\"bg-gray-50\">\n                <tr>\n                  <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                    Business\n                  </th>\n                  <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                    Contact Info\n                  </th>\n                  <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                    Score\n                  </th>\n                  <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                    Cost\n                  </th>\n                  <th className=\"px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                    Status\n                  </th>\n                </tr>\n              </thead>\n              <tbody className=\"bg-white divide-y divide-gray-200\">\n                {campaignLeads.map((lead: BusinessLead) => (\n                  <tr key={lead.id} className=\"hover:bg-gray-50\">\n                    <td className=\"px-6 py-4 whitespace-nowrap\">\n                      <div>\n                        <div className=\"text-sm font-medium text-gray-900\">\n                          {lead.business_name}\n                        </div>\n                        <div className=\"text-sm text-gray-500 truncate max-w-xs\">\n                          {lead.address}\n                        </div>\n                      </div>\n                    </td>\n                    <td className=\"px-6 py-4 whitespace-nowrap\">\n                      <div className=\"space-y-1\">\n                        {lead.phone && (\n                          <div className=\"text-sm text-gray-900\">\n                            {lead.phone}\n                          </div>\n                        )}\n                        {lead.email && (\n                          <div className=\"text-sm text-blue-600\">\n                            {lead.email}\n                          </div>\n                        )}\n                        {lead.website && (\n                          <div className=\"text-sm text-gray-500 truncate max-w-xs\">\n                            <a\n                              href={lead.website}\n                              target=\"_blank\"\n                              rel=\"noopener noreferrer\"\n                              className=\"hover:text-blue-600\"\n                            >\n                              {lead.website}\n                            </a>\n                          </div>\n                        )}\n                      </div>\n                    </td>\n                    <td className=\"px-6 py-4 whitespace-nowrap\">\n                      <div className=\"flex items-center\">\n                        <div className=\"text-sm font-medium text-gray-900\">\n                          {lead.confidence_score}%\n                        </div>\n                        <div\n                          className={`ml-2 w-16 bg-gray-200 rounded-full h-2`}\n                        >\n                          <div\n                            className={`h-2 rounded-full ${\n                              lead.confidence_score >= 80\n                                ? \"bg-green-500\"\n                                : lead.confidence_score >= 60\n                                ? \"bg-yellow-500\"\n                                : \"bg-red-500\"\n                            }`}\n                            style={{ width: `${lead.confidence_score}%` }}\n                          ></div>\n                        </div>\n                      </div>\n                    </td>\n                    <td className=\"px-6 py-4 whitespace-nowrap text-sm text-gray-900\">\n                      ${(lead.cost_to_acquire || 0).toFixed(2)}\n                    </td>\n                    <td className=\"px-6 py-4 whitespace-nowrap\">\n                      <span\n                        className={`inline-flex px-2 py-1 text-xs font-semibold rounded-full ${\n                          lead.validation_status === \"validated\"\n                            ? \"bg-green-100 text-green-800\"\n                            : lead.validation_status === \"pending\"\n                            ? \"bg-yellow-100 text-yellow-800\"\n                            : \"bg-red-100 text-red-800\"\n                        }`}\n                      >\n                        {lead.validation_status || \"unknown\"}\n                      </span>\n                    </td>\n                  </tr>\n                ))}\n              </tbody>\n            </table>\n          </div>\n        </div>\n      )}\n\n      {/* Error Display */}\n      {error && (\n        <div className=\"bg-red-50 border border-red-200 rounded-md p-4\">\n          <div className=\"flex\">\n            <div className=\"flex-shrink-0\">\n              <svg\n                className=\"h-5 w-5 text-red-400\"\n                viewBox=\"0 0 20 20\"\n                fill=\"currentColor\"\n              >\n                <path\n                  fillRule=\"evenodd\"\n                  d=\"M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z\"\n                  clipRule=\"evenodd\"\n                />\n              </svg>\n            </div>\n            <div className=\"ml-3\">\n              <h3 className=\"text-sm font-medium text-red-800\">\n                Campaign Failed\n              </h3>\n              <div className=\"mt-2 text-sm text-red-700\">\n                <p>{error instanceof Error ? error.message : String(error)}</p>\n              </div>\n            </div>\n          </div>\n        </div>\n      )}\n\n      {/* No Results State */}\n      {showResults && campaignLeads.length === 0 && (\n        <div className=\"bg-white rounded-lg shadow-sm p-12 text-center\">\n          <svg\n            className=\"mx-auto h-12 w-12 text-gray-400\"\n            fill=\"none\"\n            viewBox=\"0 0 24 24\"\n            stroke=\"currentColor\"\n          >\n            <path\n              strokeLinecap=\"round\"\n              strokeLinejoin=\"round\"\n              strokeWidth={2}\n              d=\"M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z\"\n            />\n          </svg>\n          <h3 className=\"mt-2 text-sm font-medium text-gray-900\">\n            No results found\n          </h3>\n          <p className=\"mt-1 text-sm text-gray-500\">\n            Try adjusting your search criteria or location.\n          </p>\n          <div className=\"mt-6\">\n            <button\n              onClick={() => navigate(\"/discovery\")}\n              className=\"inline-flex items-center px-4 py-2 border border-transparent shadow-sm text-sm font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700\"\n            >\n              Start New Campaign\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n};\n"}}},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":5,"duration":0.137},
{"type":"measure","name":"lsp.did_open","count":25,"duration":3.049},
{"type":"mark","name":"lsp.did_open","count":26,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/App.tsx","languageId":"typescriptreact","version":1,"text":"import { Route, Routes } from \"react-router-dom\";\nimport { Layout } from \"./components/Layout\";\nimport { AdminPanel } from \"./pages/AdminPanel\";\nimport { BusinessDiscovery } from \"./pages/BusinessDiscovery\";\nimport { Campaign } from \"./pages/Campaign\";\nimport { Dashboard } from \"./pages/Dashboard\";\nimport { Results } from \"./pages/Results\";\n\nfunction App() {\n  return (\n    <Layout>\n      <Routes>\n        <Route path=\"/\" element={<BusinessDiscovery />} />\n        <Route path=\"/dashboard\" element={<Dashboard />} />\n        <Route path=\"/discovery\" element={<BusinessDiscovery />} />\n        <Route path=\"/campaign\" element={<Campaign />} />\n        <Route path=\"/results\" element={<Results />} />\n        <Route path=\"/admin\" element={<AdminPanel />} />\n      </Routes>\n    </Layout>\n  );\n}\n\nexport default App;\n"}}},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":6,"duration":0.136},
{"type":"measure","name":"lsp.did_open","count":26,"duration":1.593},
{"type":"mark","name":"lsp.did_open","count":27,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/lib/supabase.ts","languageId":"typescript","version":1,"text":"import { createClient } from \"@supabase/supabase-js\";\n\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL;\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY;\n\nif (!supabaseUrl || !supabaseAnonKey) {\n  throw new Error(\"Missing Supabase environment variables\");\n}\n\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey, {\n  auth: {\n    persistSession: true,\n    autoRefreshToken: true,\n  },\n});\n\n// Edge Functions URL\nexport const EDGE_FUNCTIONS_URL =\n  import.meta.env.VITE_EDGE_FUNCTIONS_URL || `${supabaseUrl}/functions/v1`;\n\n// Edge Function endpoints for vault-secured progressive enrichment\nexport const EDGE_FUNCTIONS = {\n  // Progressive Enrichment Orchestrator (vault-secured)\n  ENRICHMENT_ORCHESTRATOR: `${EDGE_FUNCTIONS_URL}/enrichment-orchestrator`,\n\n  // Individual enrichment services (vault-secured)\n  ENRICHMENT_BUSINESS_LICENSE: `${EDGE_FUNCTIONS_URL}/enrichment-business-license`,\n  ENRICHMENT_PDL: `${EDGE_FUNCTIONS_URL}/enrichment-pdl`,\n  ENRICHMENT_HUNTER: `${EDGE_FUNCTIONS_URL}/enrichment-hunter`,\n  ENRICHMENT_NEVERBOUNCE: `${EDGE_FUNCTIONS_URL}/enrichment-neverbounce`,\n\n  // Legacy endpoints (for backward compatibility)\n  ENHANCED_BUSINESS_DISCOVERY: `${EDGE_FUNCTIONS_URL}/enhanced-business-discovery`,\n  LEAD_VALIDATION: `${EDGE_FUNCTIONS_URL}/lead-validation-edge`,\n  BUSINESS_DISCOVERY: `${EDGE_FUNCTIONS_URL}/business-discovery-edge`,\n  DIAGNOSTICS: `${EDGE_FUNCTIONS_URL}/diag`,\n} as const;\n\n// Progressive Enrichment Tiers (Actual API costs)\nexport const ENRICHMENT_TIERS = {\n  STARTER: {\n    name: \"Starter\",\n    price: 0.034, // Google Places API cost per search\n    stages: [\"business-license\", \"company-enrichment\"],\n    description: \"Basic business validation and company data\",\n    hasOwnershipData: false,\n  },\n  PROFESSIONAL: {\n    name: \"Professional\",\n    price: 0.076, // Google Places + Hunter.io ($0.034 + $0.042 average)\n    stages: [\"business-license\", \"company-enrichment\", \"email-discovery\"],\n    description: \"Business validation + verified email discovery\",\n    hasOwnershipData: false,\n  },\n  ENTERPRISE: {\n    name: \"Enterprise\",\n    price: 0.118, // Google Places + Hunter.io + NeverBounce ($0.034 + $0.042 + $0.042)\n    stages: [\n      \"business-license\",\n      \"company-enrichment\",\n      \"email-discovery\",\n      \"email-verification\",\n    ],\n    description: \"Complete enrichment + email verification\",\n    hasOwnershipData: false,\n  },\n  COMPLIANCE: {\n    name: \"Compliance\",\n    price: 1.118, // All above + Apollo.io ($0.118 + $1.00)\n    stages: [\n      \"business-license\",\n      \"company-enrichment\",\n      \"email-discovery\",\n      \"email-verification\",\n      \"person-enrichment\",\n    ],\n    description: \"Full compliance-grade enrichment with executive contacts\",\n    hasOwnershipData: true,\n  },\n} as const;\n"}}},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":7,"duration":0.141},
{"type":"measure","name":"lsp.did_open","count":27,"duration":1.739},
{"type":"mark","name":"lsp.did_open","count":28,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/pages/Dashboard.tsx","languageId":"typescriptreact","version":1,"text":"import React from \"react\";\nimport { useNavigate } from \"react-router-dom\";\nimport { useCampaignStore } from \"../stores/campaignStore\";\n\nexport const Dashboard: React.FC = () => {\n  const { campaigns, leads } = useCampaignStore();\n  const navigate = useNavigate();\n\n  const totalCost = campaigns.reduce(\n    (sum, campaign) => sum + campaign.total_cost,\n    0\n  );\n  const totalLeads = leads.length;\n  const qualifiedLeads = leads.filter(\n    (lead) => lead.confidence_score >= 80\n  ).length;\n  // Removed unused validatedLeads variable\n\n  const stats = [\n    { name: \"Total Campaigns\", value: campaigns.length, icon: \"üöÄ\" },\n    { name: \"Total Leads\", value: totalLeads, icon: \"üë•\" },\n    { name: \"Qualified Leads\", value: qualifiedLeads, icon: \"‚úÖ\" },\n    { name: \"Total Cost\", value: `$${totalCost.toFixed(2)}`, icon: \"üí∞\" },\n  ];\n\n  const recentCampaigns = campaigns.slice(0, 5);\n\n  return (\n    <div className=\"space-y-6\">\n      {/* Header */}\n      <div>\n        <h1 className=\"text-2xl font-bold text-gray-900\">Dashboard</h1>\n        <p className=\"mt-1 text-sm text-gray-500\">\n          Overview of your lead generation campaigns and results\n        </p>\n      </div>\n\n      {/* Stats Grid */}\n      <div className=\"grid grid-cols-1 gap-5 sm:grid-cols-2 lg:grid-cols-4\">\n        {stats.map((stat) => (\n          <div\n            key={stat.name}\n            className=\"bg-white overflow-hidden shadow rounded-lg\"\n          >\n            <div className=\"p-5\">\n              <div className=\"flex items-center\">\n                <div className=\"flex-shrink-0\">\n                  <span className=\"text-2xl\">{stat.icon}</span>\n                </div>\n                <div className=\"ml-5 w-0 flex-1\">\n                  <dl>\n                    <dt className=\"text-sm font-medium text-gray-500 truncate\">\n                      {stat.name}\n                    </dt>\n                    <dd className=\"text-lg font-medium text-gray-900\">\n                      {stat.value}\n                    </dd>\n                  </dl>\n                </div>\n              </div>\n            </div>\n          </div>\n        ))}\n      </div>\n\n      {/* Recent Campaigns */}\n      <div className=\"bg-white shadow rounded-lg\">\n        <div className=\"px-4 py-5 sm:p-6\">\n          <h3 className=\"text-lg leading-6 font-medium text-gray-900 mb-4\">\n            Recent Campaigns\n          </h3>\n          {recentCampaigns.length === 0 ? (\n            <div className=\"text-center py-8\">\n              <span className=\"text-4xl\">üîç</span>\n              <h3 className=\"mt-2 text-sm font-medium text-gray-900\">\n                No campaigns yet\n              </h3>\n              <p className=\"mt-1 text-sm text-gray-500\">\n                Get started by creating your first lead discovery campaign.\n              </p>\n              <div className=\"mt-6\">\n                <a\n                  href=\"/discovery\"\n                  className=\"inline-flex items-center px-4 py-2 border border-transparent shadow-sm text-sm font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500\"\n                >\n                  Start Discovery\n                </a>\n              </div>\n            </div>\n          ) : (\n            <div className=\"space-y-3\">\n              {recentCampaigns.map((campaign) => (\n                <div\n                  key={campaign.campaign_id}\n                  className=\"flex items-center justify-between p-4 border rounded-lg hover:bg-gray-50 cursor-pointer transition-colors\"\n                  onClick={() =>\n                    navigate(`/campaign?id=${campaign.campaign_id}`)\n                  }\n                >\n                  <div className=\"flex-1\">\n                    <div className=\"flex items-center\">\n                      <span\n                        className={`inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium ${\n                          campaign.status === \"completed\"\n                            ? \"bg-green-100 text-green-800\"\n                            : campaign.status === \"running\"\n                            ? \"bg-blue-100 text-blue-800\"\n                            : campaign.status === \"failed\"\n                            ? \"bg-red-100 text-red-800\"\n                            : \"bg-gray-100 text-gray-800\"\n                        }`}\n                      >\n                        {campaign.status}\n                      </span>\n                      <span className=\"ml-3 text-sm font-weight-medium text-gray-900\">\n                        {campaign.business_type} in {campaign.location}\n                      </span>\n                    </div>\n                    <div className=\"mt-1 text-sm text-gray-500\">\n                      {campaign.leads_found} results ‚Ä¢{\" \"}\n                      {campaign.leads_qualified} qualified ‚Ä¢ $\n                      {campaign.total_cost.toFixed(2)} cost\n                    </div>\n                  </div>\n                  <div className=\"flex items-center space-x-3\">\n                    <div className=\"text-sm text-gray-500\">\n                      {new Date(campaign.created_at).toLocaleDateString()}\n                    </div>\n                    <button\n                      onClick={(e) => {\n                        e.stopPropagation();\n                        navigate(`/campaign?id=${campaign.campaign_id}`);\n                      }}\n                      className=\"text-blue-600 hover:text-blue-800 text-sm font-medium\"\n                    >\n                      View Details ‚Üí\n                    </button>\n                  </div>\n                </div>\n              ))}\n            </div>\n          )}\n        </div>\n      </div>\n    </div>\n  );\n};\n"}}},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":8,"duration":0.171},
{"type":"measure","name":"lsp.did_open","count":28,"duration":2.954},
{"type":"mark","name":"lsp.did_close","count":1,"args":{"textDocument":{"uri":"vscode-userdata:/c%3A/Users/Alext/AppData/Roaming/Code/User/settings.json"}}},
{"type":"measure","name":"lsp.did_close","count":1,"duration":0.007},
{"type":"mark","name":"lsp.did_close","count":2,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/package.json"}}},
{"type":"measure","name":"lsp.did_close","count":2,"duration":0.025},
{"type":"mark","name":"lsp.did_open","count":29,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/types/index.ts","languageId":"typescript","version":1,"text":"// Business Discovery Types\nexport interface BusinessLead {\n  id: string;\n  campaign_id?: string;\n  business_name: string;\n  address?: string;\n  phone?: string;\n  website?: string;\n  email?: string;\n  industry?: string;\n  confidence_score: number;\n  validation_status: \"pending\" | \"validating\" | \"validated\" | \"failed\";\n  created_at: string;\n  cost_to_acquire: number;\n  data_sources: string[];\n  // Progressive enrichment fields\n  enrichment_tier?: string;\n  vault_secured?: boolean;\n}\n\nexport interface CampaignConfig {\n  search_terms: string;\n  location: string;\n  business_type?: string;\n  budget_limit: number;\n  max_results: number;\n  include_email_validation: boolean;\n  include_website_validation: boolean;\n  min_confidence_score: number;\n  chamber_verification?: boolean;\n  trade_association?: boolean;\n  professional_license?: boolean;\n}\n\nexport interface ValidationResult {\n  field: string;\n  is_valid: boolean;\n  confidence: number;\n  source: string;\n  details?: string;\n}\n\nexport interface CampaignResult {\n  campaign_id: string;\n  business_type?: string;\n  location?: string;\n  status: \"running\" | \"completed\" | \"failed\" | \"cancelled\";\n  progress: number;\n  total_cost: number;\n  leads_found: number;\n  leads_qualified: number;\n  leads_validated: number;\n  created_at: string;\n  completed_at?: string;\n  error_message?: string;\n  // Progressive enrichment fields\n  tier_used?: string;\n  vault_secured?: boolean;\n  cache_performance?: {\n    cache_hits: number;\n    cache_misses: number;\n    cache_hit_ratio: number;\n    cost_savings: number;\n  };\n}\n\n// Census Intelligence Types\nexport interface CensusIntelligence {\n  business_density: {\n    total_establishments: number;\n    density_score: number;\n    confidence_multiplier: number;\n  };\n  geographic_optimization: {\n    optimal_radius: number;\n    expected_results: number;\n    api_efficiency_score: number;\n  };\n  market_insights: {\n    market_density: \"High\" | \"Medium\" | \"Low\";\n    competition_level: \"High\" | \"Medium\" | \"Low\";\n    search_optimization: string;\n  };\n}\n\n// API Response Types\nexport interface EdgeFunctionResponse<T> {\n  success: boolean;\n  data?: T;\n  error?: string;\n  cost?: number;\n  processing_time?: number;\n}\n\nexport interface BusinessDiscoveryResponse {\n  businesses: BusinessLead[];\n  total_cost: number;\n  processing_time: string;\n  campaign_id: string;\n  qualified_count: number;\n  total_found: number;\n  census_intelligence?: CensusIntelligence;\n  // Progressive enrichment fields (vault-secured)\n  tier_used?: string;\n  cache_performance?: {\n    cache_hits: number;\n    cache_misses: number;\n    cache_hit_ratio: number;\n    cost_savings: number;\n  };\n  vault_status?: string;\n  stage_progress?: number;\n  current_stage?: string;\n}\n\n// Store Types\nexport interface CampaignStore {\n  campaigns: CampaignResult[];\n  currentCampaign: CampaignResult | null;\n  leads: BusinessLead[];\n  isLoading: boolean;\n  error: string | null;\n}\n\nexport interface UIStore {\n  sidebarOpen: boolean;\n  theme: \"light\" | \"dark\";\n  notifications: Notification[];\n}\n\nexport interface Notification {\n  id: string;\n  type: \"success\" | \"error\" | \"warning\" | \"info\";\n  title: string;\n  message: string;\n  timestamp: number;\n}\n"}}},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":9,"duration":0.157},
{"type":"measure","name":"lsp.did_open","count":29,"duration":5.042},
{"type":"mark","name":"lsp.did_open","count":30,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/hooks/useBusinessDiscovery.ts","languageId":"typescript","version":1,"text":"import { createClient } from \"@supabase/supabase-js\";\nimport { useMutation } from \"@tanstack/react-query\";\nimport { useState } from \"react\";\nimport { ENRICHMENT_TIERS } from \"../lib/supabase\";\nimport { useCampaignStore } from \"../stores/campaignStore\";\nimport type { BusinessDiscoveryResponse, CampaignConfig } from \"../types\";\n\n// Supabase configuration with current anon key\nconst supabaseUrl = \"https://sriycekxdqnesdsgwiuc.supabase.co\";\nconst supabaseAnonKey =\n  \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI\";\n\nconst supabase = createClient(supabaseUrl, supabaseAnonKey);\n\nexport const useBusinessDiscovery = () => {\n  const { addCampaign, setCurrentCampaign, addLeads, setLoading, setError } =\n    useCampaignStore();\n  const [progress, setProgress] = useState(0);\n  const [currentStage, setCurrentStage] = useState<string>(\"\");\n  const [cacheStats, setCacheStats] = useState<any>(null);\n\n  const discoveryMutation = useMutation({\n    mutationFn: async (\n      config: CampaignConfig & { selectedTier?: keyof typeof ENRICHMENT_TIERS }\n    ): Promise<BusinessDiscoveryResponse> => {\n      setLoading(true);\n      setError(null);\n      setProgress(10);\n      setCurrentStage(\"Initializing progressive enrichment...\");\n\n      try {\n        console.log(\n          \"üöÄ Starting vault-secured progressive enrichment:\",\n          config\n        );\n\n        // Determine enrichment tier\n        const tier = config.selectedTier || \"PROFESSIONAL\";\n        const tierConfig = ENRICHMENT_TIERS[tier];\n\n        setCurrentStage(\n          `Using ${tierConfig.name} tier ($${tierConfig.price}/lead)`\n        );\n        setProgress(20);\n\n        // Call progressive enrichment orchestrator with vault-secured API access\n        const { data, error } = await supabase.functions.invoke(\n          \"enrichment-orchestrator\",\n          {\n            body: {\n              action: \"progressive_enrichment\",\n              business_type: config.search_terms,\n              location: config.location,\n              max_results: config.max_results,\n              tier: tier.toLowerCase(),\n              stages: tierConfig.stages,\n              budget_limit: config.max_results * tierConfig.price,\n              min_confidence_score: config.min_confidence_score || 70,\n              cache_strategy: \"90_day_intelligent\", // Use 90-day intelligent caching\n              require_complete_contacts:\n                config.include_email_validation || false,\n              chamber_verification: config.chamber_verification ?? true,\n              professional_licensing: config.professional_license ?? true,\n              trade_associations: config.trade_association ?? true,\n            },\n            headers: {\n              Authorization: `Bearer ${supabaseAnonKey}`,\n              apikey: supabaseAnonKey,\n            },\n          }\n        );\n\n        if (error) {\n          console.error(\"‚ùå Progressive enrichment error:\", error);\n          throw new Error(`Enrichment failed: ${error.message}`);\n        }\n\n        if (!data) {\n          throw new Error(\"No data returned from progressive enrichment\");\n        }\n\n        console.log(\"‚úÖ Progressive enrichment response:\", data);\n\n        // Update progress based on stages completed\n        if (data.stage_progress) {\n          setProgress(30 + data.stage_progress * 50);\n          setCurrentStage(data.current_stage || \"Processing...\");\n        }\n\n        // Capture cache performance stats\n        if (data.cache_stats) {\n          setCacheStats(data.cache_stats);\n          console.log(\"üìä Cache performance:\", data.cache_stats);\n        }\n\n        setProgress(90);\n        setCurrentStage(\"Finalizing results...\");\n\n        // Transform the vault-secured enrichment response\n        const transformedData: BusinessDiscoveryResponse = {\n          campaign_id:\n            data.campaign_id || Math.random().toString(36).substr(2, 9),\n          total_found: data.total_found || 0,\n          qualified_count: data.qualified_count || 0,\n          total_cost: data.total_cost || config.max_results * tierConfig.price,\n          processing_time: data.processing_time || \"0ms\",\n          tier_used: tierConfig.name,\n          cache_performance: data.cache_stats,\n          vault_status: data.vault_status || \"secured\",\n          census_intelligence: data.census_intelligence || undefined,\n          businesses: (data.enriched_leads || data.leads || []).map(\n            (lead: any) => ({\n              id: lead.id || Math.random().toString(36).substr(2, 9),\n              campaign_id: data.campaign_id,\n              business_name:\n                lead.business_name || lead.businessName || \"Unknown Business\",\n              address: lead.address,\n              phone: lead.phone,\n              website: lead.website,\n              email: lead.email,\n              confidence_score:\n                lead.confidence_score || lead.optimizedScore || 0,\n              validation_status: \"validated\" as const,\n              created_at: new Date().toISOString(),\n              cost_to_acquire: lead.cost_to_acquire || tierConfig.price,\n              data_sources: lead.data_sources || [\"vault_secured_apis\"],\n              enrichment_tier: tierConfig.name,\n              vault_secured: true,\n            })\n          ),\n        };\n\n        setProgress(100);\n        setCurrentStage(\"Complete! üéâ\");\n        return transformedData;\n      } catch (error) {\n        console.error(\"‚ùå Progressive enrichment error:\", error);\n        setCurrentStage(\"Failed ‚ùå\");\n        throw error;\n      } finally {\n        setLoading(false);\n      }\n    },\n    onSuccess: (\n      data: BusinessDiscoveryResponse,\n      variables: CampaignConfig & {\n        selectedTier?: keyof typeof ENRICHMENT_TIERS;\n      }\n    ) => {\n      // Create campaign record with vault-secured enrichment data\n      const campaign = {\n        campaign_id: data.campaign_id,\n        business_type: variables.business_type || variables.search_terms,\n        location: variables.location,\n        status: \"completed\" as const,\n        progress: 100,\n        total_cost: data.total_cost,\n        leads_found: data.total_found,\n        leads_qualified: data.qualified_count,\n        leads_validated: data.businesses.filter(\n          (b: any) => b.validation_status === \"validated\"\n        ).length,\n        tier_used: data.tier_used,\n        vault_secured: true,\n        cache_performance: data.cache_performance,\n        created_at: new Date().toISOString(),\n        completed_at: new Date().toISOString(),\n      };\n\n      addCampaign(campaign);\n      setCurrentCampaign(campaign);\n      addLeads(data.businesses);\n      setProgress(100);\n      setCurrentStage(\"Results ready! üéØ\");\n    },\n    onError: (error: any) => {\n      setError(\n        error instanceof Error ? error.message : \"Progressive enrichment failed\"\n      );\n      setProgress(0);\n      setCurrentStage(\"Failed ‚ùå\");\n    },\n  });\n\n  return {\n    startDiscovery: discoveryMutation.mutate,\n    isDiscovering: discoveryMutation.isPending,\n    progress,\n    currentStage,\n    cacheStats,\n    error: discoveryMutation.error,\n    data: discoveryMutation.data,\n  };\n};\n"}}},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":10,"duration":0.178},
{"type":"measure","name":"lsp.did_open","count":30,"duration":2.973},
{"type":"mark","name":"lsp.did_open","count":31,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/CAMPAIGN_HISTORY_LINKING_COMPLETE.md","languageId":"markdown","version":1,"text":"# Campaign History Linking Implementation Complete\n\n## Overview\n\nSuccessfully implemented comprehensive campaign history linking functionality connecting the Dashboard to individual Campaign pages with CSV re-download capabilities.\n\n## Features Implemented\n\n### ‚úÖ Dashboard Campaign Links\n\n- **Clickable Campaign Cards**: Each campaign in dashboard history is now clickable\n- **Enhanced Display**: Shows business type and location instead of generic campaign ID\n- **Visual Feedback**: Hover effects and \"View Details ‚Üí\" button for clear navigation\n- **Responsive Design**: Works across all screen sizes\n\n### ‚úÖ Campaign Page URL Support\n\n- **URL Parameters**: Supports `?id=campaign_id` for direct campaign access\n- **Campaign Loading**: Automatically loads specific campaigns from dashboard history\n- **Error Handling**: Redirects to discovery page if campaign not found\n- **Navigation Integration**: Seamless linking from dashboard to campaign details\n\n### ‚úÖ Enhanced Data Model\n\n- **Campaign Context**: Added `business_type` and `location` to `CampaignResult` type\n- **Lead Association**: Added `campaign_id` to `BusinessLead` type for proper relationship\n- **Data Integrity**: Campaign creation includes business context information\n- **Type Safety**: Full TypeScript support for new fields\n\n### ‚úÖ Campaign-Specific Data Display\n\n- **Filtered Results**: Results table shows only leads from selected campaign\n- **Targeted CSV Export**: CSV export filtered to campaign-specific data only\n- **Accurate Statistics**: Lead counts and metrics specific to each campaign\n- **Proper Data Isolation**: No cross-campaign data contamination\n\n## Technical Implementation\n\n### Updated Components\n\n- **Dashboard.tsx**: Added navigation hooks and clickable campaign cards\n- **Campaign.tsx**: Added URL parameter support and campaign-specific data filtering\n- **TierSelector.tsx**: Enhanced with actual API costs and single-column layout\n- **useBusinessDiscovery.ts**: Campaign creation includes business_type and location\n- **types/index.ts**: Extended interfaces for campaign-lead relationships\n\n### Data Flow\n\n```\nDashboard ‚Üí Click Campaign ‚Üí Navigate to /campaign?id=CAMPAIGN_ID ‚Üí Load Campaign ‚Üí Filter Leads ‚Üí Display Results + CSV Export\n```\n\n### URL Structure\n\n- **Dashboard**: `/dashboard` - Shows all campaign history\n- **Specific Campaign**: `/campaign?id=CAMPAIGN_ID` - Shows individual campaign details\n- **Discovery**: `/discovery` - Start new campaigns\n\n## User Workflow\n\n### From Dashboard\n\n1. View campaign history with business context (type + location)\n2. Click any campaign card or \"View Details ‚Üí\" button\n3. Navigate to campaign-specific results page\n4. Review results and download CSV again with same tier-specific columns\n\n### Direct Access\n\n1. Use direct URL `/campaign?id=CAMPAIGN_ID` for bookmarking\n2. Share specific campaign results with team members\n3. Access historical campaigns via browser history\n\n### CSV Re-download\n\n1. Access any past campaign from dashboard\n2. View original results table with confidence scores\n3. Download CSV with same tier-specific columns as original export\n4. Includes ownership data columns for Compliance tier campaigns\n\n## Deployment Status\n\n### Production Environment\n\n- **URL**: https://prospectpro.appsmithery.co/\n- **Hosting**: Vercel with custom domain\n- **Build**: Successful TypeScript compilation\n- **Features**: All campaign linking functionality live and operational\n\n### Verification Completed\n\n- ‚úÖ Dashboard campaign cards display business context\n- ‚úÖ Click navigation works to campaign pages\n- ‚úÖ URL parameters load correct campaigns\n- ‚úÖ Lead filtering shows campaign-specific results\n- ‚úÖ CSV export includes proper data columns\n- ‚úÖ Error handling redirects appropriately\n\n## Technical Benefits\n\n### Data Architecture\n\n- **Proper Relationships**: Campaign-lead associations maintained\n- **Type Safety**: Full TypeScript coverage for new data structures\n- **Backward Compatibility**: Existing functionality preserved\n- **Performance**: Efficient filtering without database changes\n\n### User Experience\n\n- **Intuitive Navigation**: Clear pathways from dashboard to details\n- **Visual Clarity**: Business context instead of cryptic IDs\n- **Data Access**: Easy re-access to historical campaign results\n- **Workflow Continuity**: Seamless transition between pages\n\n### Maintenance\n\n- **Clean Code**: Well-structured component updates\n- **Consistent Patterns**: Follows existing architectural patterns\n- **Documentation**: Comprehensive TypeScript interfaces\n- **Testing Ready**: Clear data flow for future test implementation\n\n## Integration Points\n\n### Campaign Store\n\n- **State Management**: Zustand store handles campaign-lead relationships\n- **Data Persistence**: Campaign context preserved across navigation\n- **Memory Efficiency**: Smart filtering without data duplication\n\n### Routing\n\n- **React Router**: URL parameter handling for direct campaign access\n- **Navigation**: useNavigate hooks for programmatic routing\n- **Error Boundaries**: Graceful handling of invalid campaign IDs\n\n### CSV Export\n\n- **Tier-Specific**: Different column sets based on original campaign tier\n- **Data Integrity**: Only campaign-specific leads included\n- **Format Consistency**: Same CSV structure as original export\n\n## Next Steps\n\n### Potential Enhancements\n\n1. **Search/Filter**: Add search functionality to dashboard campaign history\n2. **Sorting**: Allow sorting campaigns by date, cost, or results count\n3. **Bulk Actions**: Select multiple campaigns for batch operations\n4. **Analytics**: Campaign performance comparison views\n\n### Integration Opportunities\n\n1. **Authentication**: Link campaigns to specific user accounts\n2. **Sharing**: Generate shareable links for campaign results\n3. **Notifications**: Alert when campaigns are accessed by others\n4. **API Access**: Programmatic access to campaign history\n\n## Files Modified\n\n### Core Components\n\n- `/src/pages/Dashboard.tsx` - Added navigation and enhanced display\n- `/src/pages/Campaign.tsx` - Added URL parameter support and filtering\n- `/src/types/index.ts` - Extended interfaces for campaign-lead relationships\n- `/src/hooks/useBusinessDiscovery.ts` - Enhanced campaign creation\n\n### Type Definitions\n\n- `CampaignResult` interface extended with `business_type` and `location`\n- `BusinessLead` interface extended with `campaign_id` association\n- URL parameter types for campaign navigation\n\n## Success Metrics\n\n### Functionality\n\n- **100% Campaign Linkage**: All dashboard campaigns link to detail pages\n- **Data Accuracy**: Campaign-specific filtering shows correct results\n- **CSV Integrity**: Re-downloaded CSVs match original tier specifications\n- **Navigation Reliability**: No broken links or missing campaigns\n\n### Performance\n\n- **Instant Navigation**: Dashboard to campaign transitions under 100ms\n- **Efficient Filtering**: Lead filtering doesn't impact page load times\n- **Memory Usage**: No memory leaks with campaign switching\n- **Build Size**: No significant bundle size increase\n\nThe campaign history linking feature is now complete and provides users with comprehensive access to their historical campaign data with professional CSV re-download capabilities.\n"}}},
{"type":"measure","name":"lsp.did_open","count":31,"duration":0.098},
{"type":"mark","name":"lsp.did_open","count":32,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/production-security-optimization.sql","languageId":"sql","version":1,"text":"-- Supabase Production Security & Performance Optimization\n-- Fixes for SECURITY DEFINER views and function search_path warnings\n-- Date: October 2025\n-- Status: Production-ready security hardening\n\n-- =============================================================================\n-- PART 1: Fix SECURITY DEFINER Views\n-- =============================================================================\n\n-- These views were detected with SECURITY DEFINER inheritance issues\n-- We'll drop and recreate them without SECURITY DEFINER properties\n\n-- Fix 1: enrichment_cache_analytics view\nDROP VIEW IF EXISTS public.enrichment_cache_analytics CASCADE;\n\nCREATE VIEW public.enrichment_cache_analytics\nWITH (security_invoker = true) AS\nSELECT \n  request_type,\n  COUNT(*) as total_entries,\n  SUM(hit_count) as total_hits,\n  AVG(confidence_score) as avg_confidence,\n  SUM(cost) as total_cost_saved,\n  ROUND(AVG(hit_count), 2) as avg_hit_count,\n  MIN(created_at) as oldest_entry,\n  MAX(last_accessed_at) as last_activity,\n  COUNT(*) FILTER (WHERE expires_at > NOW()) as active_entries,\n  COUNT(*) FILTER (WHERE expires_at <= NOW()) as expired_entries\nFROM enrichment_cache\nGROUP BY request_type\nORDER BY total_hits DESC;\n\n-- Fix 2: cache_performance_summary view  \nDROP VIEW IF EXISTS public.cache_performance_summary CASCADE;\n\nCREATE VIEW public.cache_performance_summary\nWITH (security_invoker = true) AS\nSELECT \n  date,\n  SUM(total_requests) as daily_requests,\n  SUM(cache_hits) as daily_hits,\n  SUM(cache_misses) as daily_misses,\n  ROUND(\n    CASE \n      WHEN SUM(total_requests) > 0 \n      THEN SUM(cache_hits)::DECIMAL / SUM(total_requests) * 100 \n      ELSE 0 \n    END, \n    2\n  ) as daily_hit_ratio,\n  SUM(cost_saved) as daily_cost_saved,\n  SUM(total_cost) as daily_total_cost\nFROM enrichment_cache_stats\nGROUP BY date\nORDER BY date DESC;\n\n-- =============================================================================\n-- PART 2: Fix Function Search Path Warnings\n-- =============================================================================\n\n-- All functions need explicit search_path to prevent mutable path vulnerabilities\n-- This ensures functions use qualified schema references and can't be hijacked\n\n-- Fix 1: generate_cache_key function\nCREATE OR REPLACE FUNCTION public.generate_cache_key(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS TEXT \nSET search_path = public\nAS $$\nBEGIN\n  RETURN encode(\n    digest(\n      p_request_type || '::' || p_params::text,\n      'sha256'\n    ),\n    'hex'\n  );\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE SECURITY DEFINER;\n\n-- Fix 2: get_cached_response function\nCREATE OR REPLACE FUNCTION public.get_cached_response(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS JSONB \nSET search_path = public\nAS $$\nDECLARE\n  v_cache_key TEXT;\n  v_response JSONB;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  SELECT \n    response_data \n  INTO v_response\n  FROM public.enrichment_cache \n  WHERE \n    cache_key = v_cache_key \n    AND expires_at > NOW()\n    AND request_type = p_request_type;\n  \n  -- Update hit count and last accessed\n  IF v_response IS NOT NULL THEN\n    UPDATE public.enrichment_cache \n    SET \n      hit_count = hit_count + 1,\n      last_accessed_at = NOW()\n    WHERE cache_key = v_cache_key;\n  END IF;\n  \n  RETURN v_response;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Fix 3: store_cached_response function\nCREATE OR REPLACE FUNCTION public.store_cached_response(\n  p_request_type TEXT,\n  p_params JSONB,\n  p_response JSONB,\n  p_cost DECIMAL DEFAULT 0,\n  p_confidence_score INTEGER DEFAULT 0\n) RETURNS TEXT \nSET search_path = public\nAS $$\nDECLARE\n  v_cache_key TEXT;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  -- Store with 90-day expiration\n  INSERT INTO public.enrichment_cache (\n    cache_key,\n    request_type,\n    request_params,\n    response_data,\n    cost,\n    confidence_score,\n    expires_at\n  ) VALUES (\n    v_cache_key,\n    p_request_type,\n    p_params,\n    p_response,\n    p_cost,\n    p_confidence_score,\n    NOW() + INTERVAL '90 days'\n  ) ON CONFLICT (cache_key) \n  DO UPDATE SET\n    response_data = EXCLUDED.response_data,\n    cost = EXCLUDED.cost,\n    confidence_score = EXCLUDED.confidence_score,\n    expires_at = EXCLUDED.expires_at,\n    updated_at = NOW();\n  \n  RETURN v_cache_key;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Fix 4: cleanup_expired_cache function\nCREATE OR REPLACE FUNCTION public.cleanup_expired_cache() \nRETURNS INTEGER \nSET search_path = public\nAS $$\nDECLARE\n  v_deleted_count INTEGER;\nBEGIN\n  DELETE FROM public.enrichment_cache \n  WHERE expires_at <= NOW();\n  \n  GET DIAGNOSTICS v_deleted_count = ROW_COUNT;\n  \n  RETURN v_deleted_count;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- =============================================================================\n-- PART 3: Authentication & User Management Setup for Production\n-- =============================================================================\n\n-- User profiles table (extends auth.users for additional user data)\nCREATE TABLE IF NOT EXISTS public.user_profiles (\n  id UUID PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,\n  full_name TEXT,\n  company_name TEXT,\n  industry TEXT,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Subscription tiers for SaaS functionality\nCREATE TABLE IF NOT EXISTS public.subscription_tiers (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(50) NOT NULL UNIQUE,\n  price_monthly DECIMAL(10,2) NOT NULL DEFAULT 0.00,\n  price_yearly DECIMAL(10,2) NOT NULL DEFAULT 0.00,\n  max_searches INTEGER DEFAULT 10,\n  max_exports INTEGER DEFAULT 2,\n  features JSONB DEFAULT '{}',\n  is_active BOOLEAN DEFAULT true,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- User subscriptions to track limits and usage\nCREATE TABLE IF NOT EXISTS public.user_subscriptions (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n  tier_id INTEGER REFERENCES subscription_tiers(id),\n  status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'cancelled', 'expired')),\n  current_period_start TIMESTAMPTZ DEFAULT NOW(),\n  current_period_end TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '30 days'),\n  searches_used INTEGER DEFAULT 0,\n  exports_used INTEGER DEFAULT 0,\n  stripe_subscription_id TEXT,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW(),\n  UNIQUE(user_id)\n);\n\n-- Usage tracking for analytics and billing\nCREATE TABLE IF NOT EXISTS public.usage_logs (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n  action_type VARCHAR(20) NOT NULL CHECK (action_type IN ('search', 'export')),\n  campaign_id TEXT,\n  cost DECIMAL(10,4) DEFAULT 0,\n  timestamp TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- =============================================================================\n-- PART 4: Row Level Security (RLS) Policies\n-- =============================================================================\n\n-- Enable RLS on all user tables\nALTER TABLE public.user_profiles ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.user_subscriptions ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.usage_logs ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.subscription_tiers ENABLE ROW LEVEL SECURITY;\n\n-- Update existing tables to include user ownership\nALTER TABLE public.campaigns ADD COLUMN IF NOT EXISTS user_id UUID REFERENCES auth.users(id);\n\n-- User profiles policies\nCREATE POLICY \"Users can view own profile\" ON public.user_profiles\n  FOR SELECT USING (auth.uid() = id);\n\nCREATE POLICY \"Users can update own profile\" ON public.user_profiles\n  FOR UPDATE USING (auth.uid() = id);\n\nCREATE POLICY \"Users can insert own profile\" ON public.user_profiles\n  FOR INSERT WITH CHECK (auth.uid() = id);\n\n-- Subscription policies\nCREATE POLICY \"Users can view own subscription\" ON public.user_subscriptions\n  FOR SELECT USING (auth.uid() = user_id);\n\nCREATE POLICY \"Users can update own subscription\" ON public.user_subscriptions\n  FOR UPDATE USING (auth.uid() = user_id);\n\n-- Usage logs policies\nCREATE POLICY \"Users can view own usage\" ON public.usage_logs\n  FOR SELECT USING (auth.uid() = user_id);\n\nCREATE POLICY \"System can insert usage logs\" ON public.usage_logs\n  FOR INSERT WITH CHECK (true);\n\n-- Subscription tiers (public read)\nCREATE POLICY \"Anyone can view active subscription tiers\" ON public.subscription_tiers\n  FOR SELECT USING (is_active = true);\n\n-- Update campaigns policies for user ownership\nDROP POLICY IF EXISTS \"Public read campaigns\" ON public.campaigns;\nDROP POLICY IF EXISTS \"Public insert campaigns\" ON public.campaigns;\nDROP POLICY IF EXISTS \"Public update campaigns\" ON public.campaigns;\n\nCREATE POLICY \"Users can view own campaigns\" ON public.campaigns\n  FOR SELECT USING (auth.uid() = user_id OR user_id IS NULL);\n\nCREATE POLICY \"Users can create campaigns\" ON public.campaigns\n  FOR INSERT WITH CHECK (auth.uid() = user_id);\n\nCREATE POLICY \"Users can update own campaigns\" ON public.campaigns\n  FOR UPDATE USING (auth.uid() = user_id);\n\n-- Update leads policies for user-owned campaigns\nDROP POLICY IF EXISTS \"Public read leads\" ON public.leads;\nDROP POLICY IF EXISTS \"Public insert leads\" ON public.leads;\nDROP POLICY IF EXISTS \"Public update leads\" ON public.leads;\n\nCREATE POLICY \"Users can view leads from own campaigns\" ON public.leads\n  FOR SELECT USING (\n    EXISTS (\n      SELECT 1 FROM public.campaigns \n      WHERE campaigns.id = leads.campaign_id \n      AND (campaigns.user_id = auth.uid() OR campaigns.user_id IS NULL)\n    )\n  );\n\nCREATE POLICY \"System can insert leads\" ON public.leads\n  FOR INSERT WITH CHECK (true);\n\n-- =============================================================================\n-- PART 5: User Management Functions\n-- =============================================================================\n\n-- Function to create user profile and default subscription on signup\nCREATE OR REPLACE FUNCTION public.create_user_profile_and_subscription()\nRETURNS TRIGGER \nSET search_path = public\nAS $$\nBEGIN\n  -- Create user profile\n  INSERT INTO public.user_profiles (id, full_name)\n  VALUES (NEW.id, COALESCE(NEW.raw_user_meta_data->>'full_name', ''));\n  \n  -- Create free subscription (assuming Free tier exists with id=1)\n  INSERT INTO public.user_subscriptions (user_id, tier_id)\n  VALUES (NEW.id, (SELECT id FROM public.subscription_tiers WHERE name = 'Free' LIMIT 1));\n  \n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Trigger to auto-create profile and subscription\nDROP TRIGGER IF EXISTS create_user_profile_and_subscription_trigger ON auth.users;\nCREATE TRIGGER create_user_profile_and_subscription_trigger\n  AFTER INSERT ON auth.users\n  FOR EACH ROW EXECUTE FUNCTION public.create_user_profile_and_subscription();\n\n-- Function to check usage limits before actions\nCREATE OR REPLACE FUNCTION public.check_usage_limit(user_uuid UUID, action_type TEXT)\nRETURNS JSONB \nSET search_path = public\nAS $$\nDECLARE\n  subscription_record RECORD;\n  current_usage INTEGER;\n  max_allowed INTEGER;\n  can_proceed BOOLEAN;\nBEGIN\n  -- Get user subscription with tier info\n  SELECT us.*, st.max_searches, st.max_exports, st.name as tier_name\n  INTO subscription_record\n  FROM public.user_subscriptions us\n  JOIN public.subscription_tiers st ON us.tier_id = st.id\n  WHERE us.user_id = user_uuid AND us.status = 'active';\n  \n  IF NOT FOUND THEN\n    RETURN json_build_object(\n      'can_proceed', false,\n      'usage', 0,\n      'limit', 0,\n      'error', 'No active subscription found'\n    );\n  END IF;\n  \n  -- Reset monthly usage if period has ended\n  IF subscription_record.current_period_end < NOW() THEN\n    UPDATE public.user_subscriptions \n    SET \n      current_period_start = NOW(),\n      current_period_end = NOW() + INTERVAL '30 days',\n      searches_used = 0,\n      exports_used = 0\n    WHERE user_id = user_uuid;\n    \n    -- Refresh the record\n    SELECT us.*, st.max_searches, st.max_exports, st.name as tier_name\n    INTO subscription_record\n    FROM public.user_subscriptions us\n    JOIN public.subscription_tiers st ON us.tier_id = st.id\n    WHERE us.user_id = user_uuid AND us.status = 'active';\n  END IF;\n  \n  -- Check limits based on action type\n  IF action_type = 'search' THEN\n    current_usage := subscription_record.searches_used;\n    max_allowed := subscription_record.max_searches;\n  ELSIF action_type = 'export' THEN\n    current_usage := subscription_record.exports_used;\n    max_allowed := subscription_record.max_exports;\n  ELSE\n    RETURN json_build_object(\n      'can_proceed', false,\n      'usage', 0,\n      'limit', 0,\n      'error', 'Invalid action type'\n    );\n  END IF;\n  \n  -- Check if can proceed (-1 means unlimited)\n  can_proceed := (max_allowed = -1) OR (current_usage < max_allowed);\n  \n  RETURN json_build_object(\n    'can_proceed', can_proceed,\n    'usage', current_usage,\n    'limit', max_allowed,\n    'tier', subscription_record.tier_name,\n    'period_end', subscription_record.current_period_end\n  );\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Function to increment usage after successful actions\nCREATE OR REPLACE FUNCTION public.increment_usage(\n  user_uuid UUID, \n  action_type TEXT, \n  campaign_id_param TEXT DEFAULT NULL, \n  cost_param DECIMAL DEFAULT 0\n)\nRETURNS BOOLEAN \nSET search_path = public\nAS $$\nBEGIN\n  -- Log the usage\n  INSERT INTO public.usage_logs (user_id, action_type, campaign_id, cost)\n  VALUES (user_uuid, action_type, campaign_id_param, cost_param);\n  \n  -- Increment the appropriate counter\n  IF action_type = 'search' THEN\n    UPDATE public.user_subscriptions \n    SET searches_used = searches_used + 1\n    WHERE user_id = user_uuid;\n  ELSIF action_type = 'export' THEN\n    UPDATE public.user_subscriptions \n    SET exports_used = exports_used + 1\n    WHERE user_id = user_uuid;\n  END IF;\n  \n  RETURN TRUE;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- =============================================================================\n-- PART 6: Initial Data & Performance Optimization\n-- =============================================================================\n\n-- Insert default subscription tiers\nINSERT INTO public.subscription_tiers (name, price_monthly, price_yearly, max_searches, max_exports, features) VALUES\n('Free', 0.00, 0.00, 10, 2, '{\"api_access\": false, \"priority_support\": false, \"data_export\": \"csv\"}'),\n('Pro', 29.00, 290.00, 500, 50, '{\"api_access\": true, \"priority_support\": false, \"data_export\": \"csv,json\", \"advanced_filters\": true}'),\n('Enterprise', 99.00, 990.00, -1, -1, '{\"api_access\": true, \"priority_support\": true, \"data_export\": \"csv,json,xml\", \"advanced_filters\": true, \"custom_integrations\": true}')\nON CONFLICT (name) DO NOTHING;\n\n-- Performance indexes\nCREATE INDEX IF NOT EXISTS idx_user_subscriptions_user_id ON public.user_subscriptions(user_id);\nCREATE INDEX IF NOT EXISTS idx_user_subscriptions_status ON public.user_subscriptions(status);\nCREATE INDEX IF NOT EXISTS idx_usage_logs_user_id ON public.usage_logs(user_id);\nCREATE INDEX IF NOT EXISTS idx_usage_logs_timestamp ON public.usage_logs(timestamp);\nCREATE INDEX IF NOT EXISTS idx_campaigns_user_id ON public.campaigns(user_id);\nCREATE INDEX IF NOT EXISTS idx_enrichment_cache_request_type ON public.enrichment_cache(request_type);\nCREATE INDEX IF NOT EXISTS idx_enrichment_cache_expires_at ON public.enrichment_cache(expires_at);\n\n-- =============================================================================\n-- PART 7: Production Security Comments & Documentation\n-- =============================================================================\n\nCOMMENT ON VIEW public.enrichment_cache_analytics IS 'Cache analytics view with security_invoker for production safety';\nCOMMENT ON VIEW public.cache_performance_summary IS 'Cache performance summary with security_invoker for production safety';\n\nCOMMENT ON FUNCTION public.generate_cache_key(TEXT, JSONB) IS 'Generate SHA-256 cache key with explicit search_path for security';\nCOMMENT ON FUNCTION public.get_cached_response(TEXT, JSONB) IS 'Retrieve cached response with qualified schema references';\nCOMMENT ON FUNCTION public.store_cached_response(TEXT, JSONB, JSONB, DECIMAL, INTEGER) IS 'Store cached response with security-hardened function';\nCOMMENT ON FUNCTION public.cleanup_expired_cache() IS 'Cleanup expired cache entries with production security settings';\n\nCOMMENT ON FUNCTION public.check_usage_limit(UUID, TEXT) IS 'Check user subscription limits before API actions';\nCOMMENT ON FUNCTION public.increment_usage(UUID, TEXT, TEXT, DECIMAL) IS 'Increment usage counters after successful API actions';\n\nCOMMENT ON TABLE public.user_profiles IS 'Extended user profile data with RLS enabled';\nCOMMENT ON TABLE public.subscription_tiers IS 'SaaS subscription tier definitions';\nCOMMENT ON TABLE public.user_subscriptions IS 'User subscription status and usage tracking';\nCOMMENT ON TABLE public.usage_logs IS 'Detailed usage logs for analytics and billing';\n\n-- =============================================================================\n-- VERIFICATION QUERIES (Run after deployment to confirm fixes)\n-- =============================================================================\n\n/*\n-- Verify views are fixed (should return no SECURITY DEFINER references)\nSELECT \n  schemaname, \n  viewname, \n  definition \nFROM pg_views \nWHERE viewname IN ('enrichment_cache_analytics', 'cache_performance_summary')\nAND definition LIKE '%SECURITY DEFINER%';\n\n-- Verify functions have proper search_path (should return all functions with search_path set)\nSELECT \n  routine_name,\n  routine_type,\n  routine_definition\nFROM information_schema.routines \nWHERE routine_name IN ('generate_cache_key', 'get_cached_response', 'store_cached_response', 'cleanup_expired_cache')\nAND routine_schema = 'public';\n\n-- Verify RLS policies are active\nSELECT \n  schemaname, \n  tablename, \n  policyname, \n  permissive, \n  roles, \n  cmd, \n  qual \nFROM pg_policies \nWHERE tablename IN ('user_profiles', 'user_subscriptions', 'usage_logs', 'campaigns', 'leads');\n\n-- Test user subscription system (after authentication is enabled)\nSELECT * FROM public.subscription_tiers WHERE is_active = true;\n*/"}}},
{"type":"measure","name":"lsp.did_open","count":32,"duration":0.163},
{"type":"mark","name":"lsp.did_open","count":33,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SUPABASE_PRODUCTION_OPTIMIZATION_GUIDE.md","languageId":"markdown","version":1,"text":"# Supabase Production Security Optimization Guide\n\n## Overview\n\nThis guide addresses critical security warnings and optimizations needed for a production-ready ProspectPro deployment with user authentication, subscription management, and secure database functions.\n\n## Security Issues Addressed\n\n### üî¥ CRITICAL: SECURITY DEFINER Views\n\n- **Issue**: Views `enrichment_cache_analytics` and `cache_performance_summary` inherit creator permissions\n- **Risk**: Potential privilege escalation and unauthorized data access\n- **Fix**: Recreate views with `security_invoker = true` to use caller permissions\n\n### ‚ö†Ô∏è WARNING: Function Search Path Vulnerabilities\n\n- **Issue**: Functions `generate_cache_key`, `get_cached_response`, `store_cached_response`, `cleanup_expired_cache` have mutable search_path\n- **Risk**: Function hijacking via schema injection attacks\n- **Fix**: Add explicit `SET search_path = public` and qualified schema references\n\n## Implementation Steps\n\n### Step 1: Run Security Fixes\n\n1. **Access Supabase SQL Editor**\n\n   - Go to https://supabase.com/dashboard/project/sriycekxdqnesdsgwiuc/sql\n   - Open a new SQL query\n\n2. **Deploy Security Optimization**\n\n   - Copy the entire contents of `/workspaces/ProspectPro/database/production-security-optimization.sql`\n   - Paste into Supabase SQL Editor\n   - Click **\"Run\"** to execute all fixes\n\n3. **Verify Deployment**\n   - All queries should execute without errors\n   - You should see \"Success. No rows returned\" for most operations\n\n### Step 2: Configure Authentication\n\n1. **Enable Email Auth in Supabase**\n\n   - Go to Authentication ‚Üí Settings\n   - Set Site URL: `https://prospectpro.appsmithery.co`\n   - Add redirect URLs:\n     ```\n     https://prospectpro.appsmithery.co/auth/callback\n     http://localhost:3000/auth/callback\n     ```\n\n2. **Configure Email Templates**\n\n   - Authentication ‚Üí Email Templates\n   - Customize signup confirmation, password reset templates as needed\n\n3. **Enable Apple Sign-In (Optional)**\n   - Authentication ‚Üí Providers ‚Üí Apple\n   - Add Apple Client ID and Secret from Apple Developer Console\n\n### Step 3: Environment Configuration\n\n1. **Update Production Environment Variables**\n\n   ```env\n   VITE_SUPABASE_URL=https://sriycekxdqnesdsgwiuc.supabase.co\n   VITE_SUPABASE_ANON_KEY=your-current-anon-key\n   VITE_SITE_URL=https://prospectpro.appsmithery.co\n   ```\n\n2. **Verify Anon Key**\n   - Go to Settings ‚Üí API in Supabase dashboard\n   - Copy the current `anon public` key\n   - Update in your environment variables\n\n### Step 4: Application Integration\n\nThe security optimization includes a complete user authentication and subscription system. To integrate:\n\n1. **Install Additional Dependencies**\n\n   ```bash\n   npm install @supabase/auth-ui-react @supabase/auth-ui-shared react-hook-form zod\n   ```\n\n2. **Update Application Architecture**\n   - The SQL includes all necessary tables and functions for user management\n   - Subscription tiers: Free (10 searches), Pro (500 searches), Enterprise (unlimited)\n   - Usage tracking and limit enforcement\n   - Row Level Security for multi-tenant data isolation\n\n### Step 5: Edge Function Updates\n\nUpdate your Edge Functions to include user authentication and usage tracking:\n\n```javascript\n// Add to beginning of Edge Functions\nconst {\n  data: { user },\n} = await supabaseClient.auth.getUser();\nif (!user) {\n  return new Response(JSON.stringify({ error: \"Authentication required\" }), {\n    status: 401,\n    headers: corsHeaders,\n  });\n}\n\n// Check usage limits\nconst { data: usageCheck } = await supabaseClient.rpc(\"check_usage_limit\", {\n  user_uuid: user.id,\n  action_type: \"search\",\n});\n\nif (!usageCheck?.can_proceed) {\n  return new Response(\n    JSON.stringify({\n      error: \"Search limit reached. Please upgrade your subscription.\",\n      usage: usageCheck,\n    }),\n    {\n      status: 403,\n      headers: corsHeaders,\n    }\n  );\n}\n\n// After successful operation\nawait supabaseClient.rpc(\"increment_usage\", {\n  user_uuid: user.id,\n  action_type: \"search\",\n  campaign_id_param: campaignId,\n  cost_param: totalCost,\n});\n```\n\n## Verification Checklist\n\n### Security Fixes Verification\n\nRun these queries in Supabase SQL Editor to verify fixes:\n\n```sql\n-- 1. Verify no SECURITY DEFINER views remain\nSELECT\n  schemaname,\n  viewname,\n  definition\nFROM pg_views\nWHERE viewname IN ('enrichment_cache_analytics', 'cache_performance_summary')\nAND definition LIKE '%SECURITY DEFINER%';\n-- Should return 0 rows\n\n-- 2. Verify functions have search_path set\nSELECT\n  routine_name,\n  routine_type\nFROM information_schema.routines\nWHERE routine_name IN ('generate_cache_key', 'get_cached_response', 'store_cached_response', 'cleanup_expired_cache')\nAND routine_schema = 'public';\n-- Should return 4 rows\n\n-- 3. Verify RLS policies are active\nSELECT COUNT(*) as policy_count\nFROM pg_policies\nWHERE tablename IN ('user_profiles', 'user_subscriptions', 'usage_logs', 'campaigns', 'leads');\n-- Should return > 0\n\n-- 4. Verify subscription tiers exist\nSELECT name, max_searches, max_exports FROM subscription_tiers WHERE is_active = true;\n-- Should return 3 tiers: Free, Pro, Enterprise\n```\n\n### Authentication Verification\n\n1. **Test User Signup**\n\n   - Users can register with email\n   - User profiles auto-created\n   - Free subscription assigned by default\n\n2. **Test Usage Limits**\n\n   - Free tier limited to 10 searches, 2 exports\n   - Usage counters increment correctly\n   - Limits enforced before API calls\n\n3. **Test Data Isolation**\n   - Users only see their own campaigns and leads\n   - Cross-user data access blocked by RLS\n\n## Production Benefits\n\n### Security Hardening\n\n- ‚úÖ **SECURITY DEFINER Eliminated**: Views use caller permissions, not creator\n- ‚úÖ **Search Path Fixed**: Functions immune to schema injection attacks\n- ‚úÖ **RLS Enabled**: Multi-tenant data isolation with user-specific policies\n- ‚úÖ **Qualified References**: All schema references explicitly qualified\n\n### User Management\n\n- ‚úÖ **Authentication Ready**: Email signup/signin with optional Apple Sign-In\n- ‚úÖ **Subscription Tiers**: Free, Pro, Enterprise with usage limits\n- ‚úÖ **Usage Tracking**: Detailed logs for analytics and billing\n- ‚úÖ **Automatic Provisioning**: User profiles and subscriptions auto-created\n\n### Performance Optimization\n\n- ‚úÖ **Strategic Indexes**: Optimized queries for user data, subscriptions, usage logs\n- ‚úÖ **Cache Performance**: Enhanced caching with security-hardened functions\n- ‚úÖ **Database Efficiency**: Proper foreign keys and constraints\n\n### Compliance & Monitoring\n\n- ‚úÖ **Audit Trail**: Complete usage logs for compliance reporting\n- ‚úÖ **Data Governance**: User-owned data with proper access controls\n- ‚úÖ **Subscription Management**: Ready for billing integration (Stripe compatible)\n\n## Next Steps\n\n### Immediate (Required)\n\n1. **Deploy Security Fixes**: Run the production optimization SQL\n2. **Configure Authentication**: Enable email auth in Supabase dashboard\n3. **Update Environment**: Set production environment variables\n4. **Test Security**: Verify all queries return expected results\n\n### Short Term (Recommended)\n\n1. **Frontend Integration**: Add authentication components to React app\n2. **Edge Function Updates**: Add user auth and usage tracking\n3. **Subscription UI**: Build subscription management interface\n4. **Testing**: Comprehensive authentication and authorization testing\n\n### Long Term (Enhancement)\n\n1. **Payment Integration**: Stripe subscription billing\n2. **Advanced Analytics**: User behavior and usage analytics\n3. **API Access**: External API for enterprise customers\n4. **Performance Monitoring**: Database performance optimization\n\n## Support & Troubleshooting\n\n### Common Issues\n\n**Issue**: \"relation does not exist\" errors\n**Solution**: Ensure all SQL executed successfully, check table creation\n\n**Issue**: RLS policy violations\n**Solution**: Verify user authentication, check policy definitions\n\n**Issue**: Function search_path warnings persist\n**Solution**: Redeploy functions with explicit search_path settings\n\n### Debug Commands\n\n```sql\n-- Check current user authentication\nSELECT auth.uid() as current_user_id;\n\n-- Verify table existence\nSELECT table_name FROM information_schema.tables\nWHERE table_schema = 'public'\nAND table_name IN ('user_profiles', 'subscription_tiers', 'user_subscriptions', 'usage_logs');\n\n-- Test subscription system\nSELECT\n  up.full_name,\n  st.name as tier,\n  us.searches_used,\n  st.max_searches\nFROM user_profiles up\nJOIN user_subscriptions us ON up.id = us.user_id\nJOIN subscription_tiers st ON us.tier_id = st.id\nWHERE up.id = auth.uid();\n```\n\nThis optimization provides enterprise-grade security and user management capabilities while maintaining the high-performance architecture of ProspectPro v4.2.\n"}}},
{"type":"measure","name":"lsp.did_open","count":33,"duration":0.104},
{"type":"mark","name":"lsp.did_open","count":34,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/archive/old-frontend/package.json","languageId":"json","version":1,"text":"{\n  \"name\": \"prospectpro-frontend\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"tsc && vite build\",\n    \"preview\": \"vite preview\",\n    \"lint\": \"eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0\",\n    \"type-check\": \"tsc --noEmit\"\n  },\n  \"dependencies\": {\n    \"@supabase/supabase-js\": \"^2.39.0\",\n    \"@tanstack/react-query\": \"^5.17.0\",\n    \"react\": \"^18.2.0\",\n    \"react-dom\": \"^18.2.0\",\n    \"react-router-dom\": \"^6.20.1\",\n    \"zustand\": \"^4.4.7\",\n    \"recharts\": \"^2.8.0\",\n    \"lucide-react\": \"^0.294.0\",\n    \"clsx\": \"^2.0.0\",\n    \"tailwind-merge\": \"^2.2.0\"\n  },\n  \"devDependencies\": {\n    \"@types/react\": \"^18.2.43\",\n    \"@types/react-dom\": \"^18.2.17\",\n    \"@typescript-eslint/eslint-plugin\": \"^6.14.0\",\n    \"@typescript-eslint/parser\": \"^6.14.0\",\n    \"@vitejs/plugin-react\": \"^4.2.1\",\n    \"autoprefixer\": \"^10.4.16\",\n    \"eslint\": \"^8.55.0\",\n    \"eslint-plugin-react-hooks\": \"^4.6.0\",\n    \"eslint-plugin-react-refresh\": \"^0.4.5\",\n    \"postcss\": \"^8.4.32\",\n    \"tailwindcss\": \"^3.3.6\",\n    \"typescript\": \"^5.2.2\",\n    \"vite\": \"^5.0.8\"\n  }\n}"}}},
{"type":"measure","name":"lsp.did_open","count":34,"duration":0.126},
{"type":"mark","name":"lsp.did_open","count":35,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/archive/deployment-logs/package.json","languageId":"json","version":1,"text":"{\r\n  \"name\": \"prospect-pro-real-api\",\r\n  \"version\": \"3.1.0\",\r\n  \"description\": \"Production-grade lead generation platform with Enhanced Quality Scoring v3.0, zero-fake-data policy and Supabase Vault integration\",\r\n  \"main\": \"server.js\",\r\n  \"scripts\": {\r\n    \"start\": \"node server.js\",\r\n    \"dev\": \"nodemon server.js\",\r\n    \"prod\": \"NODE_ENV=production node server.js\",\r\n    \"production:start\": \"powershell -ExecutionPolicy Bypass -File ./scripts/init-prod-simple.ps1\",\r\n    \"production:checklist\": \"echo 'Production checklist: Check .env file, test database connection, validate APIs'\",\r\n    \"prod:init\": \"powershell -ExecutionPolicy Bypass -File ./scripts/init-prod-simple.ps1\",\r\n    \"prod:setup-env\": \"node ./scripts/pull-env-from-secrets.js\",\r\n    \"prod:check\": \"node --version && echo Production environment ready\",\r\n    \"health\": \"curl http://localhost:3100/health || echo 'Server not running'\",\r\n    \"diag\": \"curl http://localhost:3100/diag | json_pp || echo 'Server not running'\",\r\n    \"test\": \"echo 'Tests moved to testing branch. Run: git checkout testing && node tests/validation/test-real-data.js'\",\r\n    \"postinstall\": \"echo 'ProspectPro v3.0: Production-ready deployment configured'\",\r\n    \"docker:dev\": \"./docker/start-dev.sh\",\r\n    \"docker:prod\": \"./docker/deploy-prod.sh\",\r\n    \"docker:build\": \"docker-compose build\",\r\n    \"docker:package\": \"./docker/create-client-package.sh\",\r\n    \"docker:logs\": \"docker-compose logs -f prospectpro\",\r\n    \"docker:stop\": \"docker-compose down\",\r\n    \"docker:restart\": \"docker-compose restart\",\r\n    \"secure:setup\": \"./docker/secure-start.sh setup\",\r\n    \"secure:start\": \"./docker/secure-start.sh start\",\r\n    \"secure:dev\": \"./docker/secure-start.sh dev\",\r\n    \"keychain:setup\": \"./docker/keychain-start.sh setup\",\r\n    \"keychain:start\": \"./docker/keychain-start.sh start\",\r\n    \"1password:setup\": \"./docker/1password-start.sh setup\",\r\n    \"1password:start\": \"./docker/1password-start.sh start\",\r\n    \"vault:deploy\": \"echo 'üîê Deploying with Supabase Vault integration...' && docker-compose up --build -d\",\r\n    \"vault:dev\": \"echo 'üîê Starting development with Supabase Vault...' && docker-compose -f docker-compose.dev.yml up --build\",\r\n    \"vault:logs\": \"docker-compose logs -f prospectpro\",\r\n    \"vault:test\": \"echo 'üß™ Testing Vault connection...' && docker-compose exec prospectpro curl -f http://localhost:3000/diag\",\r\n    \"mcp:install\": \"cd mcp-servers && npm install\",\r\n    \"mcp:test\": \"cd mcp-servers && node test-servers.js\",\r\n    \"mcp:start:database\": \"cd mcp-servers && node database-server.js\",\r\n    \"mcp:start:api\": \"cd mcp-servers && node api-server.js\",\r\n    \"mcp:start:filesystem\": \"cd mcp-servers && node filesystem-server.js\",\r\n    \"mcp:start:monitoring\": \"cd mcp-servers && node monitoring-server.js\",\r\n    \"mcp:start:production\": \"cd mcp-servers && node production-server.js\",\r\n    \"mcp:start:all\": \"cd mcp-servers && npm run start:all\"\r\n  },\r\n  \"engines\": {\r\n    \"node\": \">=20.0.0\",\r\n    \"npm\": \">=9.0.0\"\r\n  },\r\n  \"dependencies\": {\r\n    \"@googlemaps/google-maps-services-js\": \"^3.4.2\",\r\n    \"@modelcontextprotocol/sdk\": \"^1.18.1\",\r\n    \"@supabase/supabase-js\": \"^2.57.4\",\r\n    \"axios\": \"^1.12.2\",\r\n    \"bcryptjs\": \"^2.4.3\",\r\n    \"cheerio\": \"^1.1.2\",\r\n    \"cors\": \"^2.8.5\",\r\n    \"csv-writer\": \"^1.6.0\",\r\n    \"dotenv\": \"^16.6.1\",\r\n    \"express\": \"^4.18.2\",\r\n    \"express-rate-limit\": \"^8.1.0\",\r\n    \"helmet\": \"^7.2.0\",\r\n    \"jsonwebtoken\": \"^9.0.2\",\r\n    \"node-fetch\": \"^2.7.0\",\r\n    \"p-limit\": \"^3.1.0\",\r\n    \"pg\": \"^8.16.3\",\r\n    \"prom-client\": \"^15.1.3\",\r\n    \"rate-limiter-flexible\": \"^2.4.2\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"jest\": \"^30.1.3\",\r\n    \"nodemon\": \"^3.1.10\",\r\n    \"supabase\": \"^2.45.5\",\r\n    \"supertest\": \"^7.1.4\"\r\n  },\r\n  \"keywords\": [\r\n    \"lead-generation\",\r\n    \"business-intelligence\",\r\n    \"api-integration\"\r\n  ],\r\n  \"author\": \"ProspectPro Development Team\",\r\n  \"license\": \"MIT\"\r\n}"}}},
{"type":"measure","name":"lsp.did_open","count":35,"duration":0.079},
{"type":"mark","name":"lsp.did_close","count":3,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.vscode/settings.json"}}},
{"type":"measure","name":"lsp.did_close","count":3,"duration":0.028},
{"type":"mark","name":"lsp.did_close","count":4,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.vscode/extensions.json"}}},
{"type":"measure","name":"lsp.did_close","count":4,"duration":0.01},
{"type":"mark","name":"lsp.did_close","count":5,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.vscode/keybindings.json"}}},
{"type":"measure","name":"lsp.did_close","count":5,"duration":0.01},
{"type":"mark","name":"lsp.did_close","count":6,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/package.json"}}},
{"type":"measure","name":"lsp.did_close","count":6,"duration":0.008},
{"type":"mark","name":"lsp.did_close","count":7,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.bashrc_prospectpro"}}},
{"type":"measure","name":"lsp.did_close","count":7,"duration":0.009},
{"type":"mark","name":"lsp.did_close","count":8,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/start-mcp-optimized.js"}}},
{"type":"measure","name":"lsp.did_close","count":8,"duration":0.502},
{"type":"mark","name":"lsp.did_close","count":9,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-config.json"}}},
{"type":"measure","name":"lsp.did_close","count":9,"duration":0.013},
{"type":"mark","name":"lsp.did_close","count":10,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/COST_OPTIMIZATION_SUMMARY.md"}}},
{"type":"measure","name":"lsp.did_close","count":10,"duration":0.011},
{"type":"mark","name":"lsp.did_close","count":11,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/TECHNICAL_SUMMARY_v4.2.md"}}},
{"type":"measure","name":"lsp.did_close","count":11,"duration":0.01},
{"type":"mark","name":"lsp.did_close","count":12,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/supabase-troubleshooting-server.js"}}},
{"type":"measure","name":"lsp.did_close","count":12,"duration":0.292},
{"type":"mark","name":"lsp.did_close","count":13,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/CI_CD_DEPLOYMENT_GUIDE.md"}}},
{"type":"measure","name":"lsp.did_close","count":13,"duration":0.012},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":11,"duration":0.159},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":12,"duration":0.123},
{"type":"mark","name":"lsp.did_open","count":36,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/package.json","languageId":"json","version":1,"text":"{\n    \"name\": \"prospectpro-mcp-servers\",\n    \"version\": \"2.1.0\",\n    \"description\": \"Consolidated MCP servers for ProspectPro Supabase-First AI development\",\n    \"main\": \"production-server.js\",\n    \"scripts\": {\n        \"start:production\": \"node production-server.js\",\n        \"start:development\": \"node development-server.js\",\n        \"start:troubleshooting\": \"node supabase-troubleshooting-server.js\",\n        \"start:all\": \"concurrently \\\"npm run start:production\\\" \\\"npm run start:development\\\" \\\"npm run start:troubleshooting\\\"\",\n        \"test\": \"node test-servers.js\",\n        \"validate\": \"npm run test && echo '‚úÖ All Supabase MCP servers validated successfully'\",\n        \"install:deps\": \"npm install\",\n        \"debug:anon-key\": \"echo 'Use troubleshooting server: diagnose_anon_key_mismatch tool'\",\n        \"debug:edge-functions\": \"echo 'Use troubleshooting server: test_edge_function tool'\",\n        \"debug:database\": \"echo 'Use troubleshooting server: validate_database_permissions tool'\"\n    },\n    \"dependencies\": {\n        \"@modelcontextprotocol/sdk\": \"^1.18.2\",\n        \"@supabase/supabase-js\": \"^2.58.0\"\n    },\n    \"devDependencies\": {\n        \"concurrently\": \"^8.2.2\"\n    },\n    \"keywords\": [\n        \"mcp\",\n        \"model-context-protocol\",\n        \"ai\",\n        \"prospectpro\",\n        \"supabase\",\n        \"edge-functions\",\n        \"serverless\"\n    ],\n    \"author\": \"Alex Torelli\",\n    \"license\": \"MIT\"\n}"}}},
{"type":"measure","name":"lsp.did_open","count":36,"duration":0.672},
{"type":"mark","name":"lsp.did_close","count":14,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/vercel.json"}}},
{"type":"measure","name":"lsp.did_close","count":14,"duration":0.032},
{"type":"mark","name":"lsp.did_close","count":15,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/VERCEL_CONFIG.md"}}},
{"type":"measure","name":"lsp.did_close","count":15,"duration":0.015},
{"type":"mark","name":"lsp.did_close","count":16,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/VERCEL_NATIVE_OPTIMIZATIONS.md"}}},
{"type":"measure","name":"lsp.did_close","count":16,"duration":0.019},
{"type":"mark","name":"lsp.did_close","count":17,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.github/CONTRIBUTING.md"}}},
{"type":"measure","name":"lsp.did_close","count":17,"duration":0.012},
{"type":"mark","name":"lsp.did_open","count":37,"args":{"textDocument":{"uri":"vscode-userdata:/c%3A/Users/Alext/AppData/Roaming/Code/User/settings.json","languageId":"jsonc","version":3,"text":"{\n  \"window.autoDetectColorScheme\": true,\n  \"github.copilot.nextEditSuggestions.enabled\": true,\n  \"security.workspace.trust.untrustedFiles\": \"open\",\n  \"python.analysis.typeCheckingMode\": \"standard\",\n  \"mssql.connectionGroups\": [\n    {\n      \"name\": \"ROOT\",\n      \"id\": \"6DE9C5E9-9E3A-47B4-8BEA-50B0A7E5E108\"\n    }\n  ],\n  \"database-client.autoSync\": true,\n  \"git.openRepositoryInParentFolders\": \"always\",\n  \"editor.cursorBlinking\": \"expand\",\n  \"editor.wordWrap\": \"on\",\n  \"files.autoSave\": \"onWindowChange\",\n  \"editor.bracketPairColorization.independentColorPoolPerBracketType\": true,\n  \"editor.formatOnSave\": true,\n  \"workbench.iconTheme\": \"vira-icons-teal\",\n  \"mssql.autoDisableNonTSqlLanguageService\": true,\n  \"git.enableSmartCommit\": true,\n  \"git.confirmSync\": false,\n  \"git.autofetch\": true,\n  \"chat.tools.terminal.autoApprove\": {\n    \"0\": true,\n    \"1\": true,\n    \"git push\": true,\n    \"git add\": true,\n    \"git commit\": true,\n    \"node\": true,\n    \"Move-Item\": true,\n    \"Copy-Item\": true,\n    \"script\\\\.\": true,\n    \"old\": true,\n    \"temp\": true,\n    \"backup\\\"\": true,\n    \"nslookup\": true,\n    \"Remove-Item\": true,\n    \"Rename-Item\": true,\n    \"Invoke-WebRequest\": true,\n    \"\\\"apikey\\\"=\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZ2eGRwcmdmbHR6Ymx3dnBlZHB4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MjQ3MTgzOTksImV4cCI6MjA0MDI5NDM5OX0.TZ9kR6FfNvnZMJF9P6NX6rYSVfM3LRw7BfGK7U6YXwc\\\"}\": true,\n    \"\\\"apikey\\\"=\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZ2eGRwcmdmbHR6Ymx3dnBlZHB4Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcyNDcxODM5OSwiZXhwIjoyMDQwMjk0Mzk5fQ.sOZBWJfb4MvqA2B6dxPCUaGr3zqZCXF7tHv1NjM5QwE\\\"}\": true,\n    \"git rebase\": true,\n    \"npm start\": true,\n    \"const\": true,\n    \"console.log('‚úÖ\": true,\n    \"\\\"\": true,\n    \"try\": true,\n    \"}\": true,\n    \"}\\\"\": true,\n    \"powershell\": true,\n    \"Test-Path\": true,\n    \"Start-Process\": true,\n    \"git rm\": true,\n    \"git reset\": true,\n    \"git commit -m \\\"fix: resolve Railway deployment crashes with robust import patterns\\n\\n- Fix api/dashboard-export.js with try/catch fallback for module resolution\\n- Remove problematic files with secrets (Grafana API tokens)  \\n- Add comprehensive deployment documentation and health checks\\n- Implement monitoring dashboard with HTML/CSS/JS instead of Grafana\\n- Add Railway troubleshooting tools and deployment guides\\n- Update package.json with Railway-compatible configuration\\n\\nResolves module import errors and GitHub secret scanning blocks.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"(async\": true,\n    \"{\": true,\n    \"if\": true,\n    \"console.log('üìä\": true,\n    \"git commit -m \\\"optimize: leverage Railway analytics, simplify monitoring architecture\\n\\nüéØ Strategic Changes:\\n- Replace complex custom monitoring with Railway's built-in analytics\\n- Focus only on ProspectPro business metrics (campaigns, leads, costs)\\n- Remove redundant infrastructure monitoring (Railway handles this)\\n- Simplify dashboard to essential business KPIs only\\n\\n‚úÖ Benefits:\\n- 70% reduction in monitoring code complexity\\n- Better reliability using Railway's native capabilities\\n- Focus on business value rather than infrastructure metrics\\n- Faster deployment and fewer moving parts\\n\\nüöÄ Railway Integration:\\n- Use Railway dashboard for: CPU, Memory, Network, Logs, Uptime\\n- Custom dashboard for: Campaign success, Lead qualification, API costs\\n- Simplified health checks focused on business logic\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm outdated\": true,\n    \"=20.0.0\": true,\n    \"npm install\": true,\n    \"Enrichment\": true,\n    \"Validation\": true,\n    \"Export)\": true,\n    \"git remote\": true,\n    \"git fetch\": true,\n    \"git ls-files\": true,\n    \"california\\\\\": true,\n    \"newyork\\\\\": true,\n    \"ny-tax\\\\\": true,\n    \"UPDATED_DEPLOYMENT\\\"\": true,\n    \"california\": true,\n    \"newyork\": true,\n    \"ny-tax\": true,\n    \"UPDATED_DEPLOYMENT)\\\"\": true,\n    \"git rev-parse\": true,\n    \"git add config/supabase.js server.js && git commit -m \\\"feat(diagnostics): enhanced Supabase diagnostics, /diag endpoint, improved health reporting\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git add server.js config/supabase.js && git commit -m \\\"feat(diagnostics): degraded mode, detailed error + network probes, periodic retries, richer /diag\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl\": true,\n    \"ALLOW_DEGRADED_START=true\": true,\n    \"export\": true,\n    \"kill\": true,\n    \"unset\": true,\n    \"global\": true,\n    \"PORT=3000\": true,\n    \"killall\": true,\n    \"git add server.js railway.toml && git commit -m \\\"fix(deployment): bind to 0.0.0.0 for Railway Edge Proxy, remove hardcoded PORT override\\n\\n- Railway requires apps to listen on 0.0.0.0, not localhost\\n- Remove PORT=8080 override in railway.toml to let Railway set it dynamically  \\n- Default to PORT 3000 to match Railway conventions\\n- This should resolve 502 Bad Gateway errors from Railway load balancer\\\" && git push origin main\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_URL=test\": true,\n    \"SUPABASE_URL=https://test.supabase.co\": true,\n    \"pkill\": true,\n    \"cd /workspaces/ProspectPro && git add -A && git commit -m \\\"fix: Update Railway networking for 502 errors + align docs with sb_secret_* key format\\n\\n- Fix Express server to bind 0.0.0.0:PORT (Railway requirement) \\n- Remove hardcoded PORT=8080 from railway.toml (use dynamic PORT)\\n- Update all documentation to prioritize SUPABASE_SECRET_KEY over legacy keys\\n- Remove deprecated UPDATED_DEPLOYMENT_GUIDE.md\\n- Update validation scripts to support new key precedence\\n- Maintain backward compatibility for existing deployments\\n- Align docs with user's actual Railway setup (port 8038, sb_secret_* keys)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git add railway.toml && git commit -m \\\"fix: Clean up railway.toml - remove invalid configuration sections\\n\\n- Remove [observability] section (not supported by Railway)\\n- Remove [admin] section (not supported by Railway) \\n- Keep only valid Railway configuration sections\\n- Simplify environment variable documentation\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_URL=https://example.supabase.co\": true,\n    \"RLS\": true,\n    \"service\": true,\n    \"anon\": true,\n    \"publishable)\\\\n-\": true,\n    \"improve\": true,\n    \"cd /workspaces/ProspectPro && git add server.js database/rls-hardening.sql .env.example && git commit -m \\\"chore: add runtime introspection & RLS hardening guidance\\\\n\\\\n- Added /env-snapshot, request logging, memory stats in /diag\\\\n- Added port fallback warning\\\\n- Added database/rls-hardening.sql with policy templates\\\\n- Updated .env.example (avoid PORT on Railway)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git add server.js database/rls-hardening.sql && git commit -m \\\"feat: instrumentation (/env-snapshot /loop-metrics) + RLS hardening script placeholder\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"getLastSupabaseDiagnostics,\": true,\n    \"console.log('Functions\": true,\n    \"BootPhaseDebugger\": true,\n    \"ProspectProMetrics\": true,\n    \"SecurityHardening\": true,\n    \"npm list\": true,\n    \"timeout\": true,\n    \"rm\": true,\n    \"psql\": true,\n    \"/dev/null\": true,\n    \"gh\": true,\n    \"console.log('=====================================================')\": true,\n    \"console.log('')\": true,\n    \"console.log('\": true,\n    \"console.log('üéØ\": true,\n    \"console.log('1.\": true,\n    \"console.log('2.\": true,\n    \"console.log('3.\": true,\n    \"console.log('üéâ\": true,\n    \"console.log('üîç\": true,\n    \"let\": true,\n    \"//\": true,\n    \"[]).length\": true,\n    \"issues.push(\\\\`‚ö†Ô∏è\": true,\n    \"openParens}\": true,\n    \"closeParens}\": true,\n    \"')\": true,\n    \"!lastStatement.startsWith('--'))\": true,\n    \"issues.push('‚ö†Ô∏è\": true,\n    \"console.log('‚ùå\": true,\n    \"issues.forEach(issue\": true,\n    \"console.log(issue))\": true,\n    \"issues.push('Unbalanced\": true,\n    \"issues.push('system_settings\": true,\n    \"issues.push('Found\": true,\n    \"mv\": true,\n    \"true\": true,\n    \"createClient\": true,\n    \"console.log('üîó\": true,\n    \"supabase.from('information_schema.tables').select('table_name').limit(1).then(result\": true,\n    \"}).catch(err\": true,\n    \"console.error('‚ùå\": true,\n    \"SUPABASE_URL=https://sriycekxdqnesdsgwiuc.supabase.co\": true,\n    \"git branch\": true,\n    \"git checkout\": true,\n    \".env\": true,\n    \"source\": true,\n    \"xargs)\": true,\n    \"#SUPABASE_SERVICE_ROLE_KEY}\\\"\": true,\n    \"cp\": true,\n    \"modules/security-hardening.js\": true,\n    \"'EOF'\": true,\n    \"class\": true,\n    \"constructor(options\": true,\n    \"})\": true,\n    \"this.options\": true,\n    \"enableSecureHeaders:\": true,\n    \"this.options.adminTokens.add(process.env.PERSONAL_ACCESS_TOKEN)\": true,\n    \"console.log('üõ°Ô∏è\": true,\n    \"app.use((req,\": true,\n    \"res.removeHeader('X-Powered-By')\": true,\n    \"res.setHeader('X-Frame-Options',\": true,\n    \"res.setHeader('X-Content-Type-Options',\": true,\n    \"res.setHeader('X-ProspectPro-Security',\": true,\n    \"next()\": true,\n    \"return\": true,\n    \"req.headers['x-admin-token']\": true,\n    \"!this.options.adminTokens.has(token))\": true,\n    \"error:\": true,\n    \"authenticated:\": true,\n    \"process.env.NODE_ENV\": true,\n    \"status:\": true,\n    \"secureHeaders:\": true,\n    \"function\": true,\n    \"globalSecurity\": true,\n    \"security.applySecurityMiddleware(app)\": true,\n    \"EOF\": true,\n    \"general:\": true,\n    \"res.send\": true,\n    \"=\": true,\n    \"console.warn(`‚ö†Ô∏è\": true,\n    \"res.statusCode}\": true,\n    \"req.method}\": true,\n    \"req.path}`)\": true,\n    \"middleware.general.forEach(mw\": true,\n    \"app.use(mw))\": true,\n    \"app.use(this.getSecurityLogger())\": true,\n    \"'https://sriycekxdqnesdsgwiuc.supabase.co'\": true,\n    \"'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1Nzk2NTc4OSwiZXhwIjoyMDczNTQxNzg5fQ.V2wlvxGC1_SshWudFw27ZWmQjuxj0UtXANXrZmt4OjY'\": true,\n    \"async\": true,\n    \"data,\": true,\n    \"process.exit(success\": true,\n    \"testConnection\": true,\n    \"testConnection().then(result\": true,\n    \"supabase.auth.getSession().then(result\": true,\n    \"error.message.includes('relation')\": true,\n    \"error.message.includes('does\": true,\n    \"console.log('-\": true,\n    \"require('./config/supabase').testConnection().then(result\": true,\n    \"console.error('Database\": true,\n    \"node -e \\\"console.log('Testing environment...'); require('./config/supabase').testConnection().then(result => console.log('Database test:', result)).catch(err => console.error('Database error:', err))\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"node -e \\\"require('dotenv').config(); console.log('Testing with dotenv...'); require('./config/supabase').testConnection().then(result => console.log('Database test:', result.success ? 'SUCCESS' : 'FAILED', result)).catch(err => console.error('Database error:', err))\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"supabase.getSupabaseClient().from('campaigns').select('count').limit(1).then(result\": true,\n    \"console.error('Table\": true,\n    \"k.includes('SUPABASE')))\": true,\n    \"result.success)\": true,\n    \"console.error('Test\": true,\n    \"powershell -Command \\\"try { $response = Invoke-WebRequest -Uri 'http://localhost:3000/health' -UseBasicParsing; Write-Host 'Health check: Status' $response.StatusCode; Write-Host 'Response:' $response.Content } catch { Write-Host 'Error:' $_.Exception.Message }\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -s http://localhost:3000/health | ConvertFrom-Json\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"require('./config/supabase').testConnection().then(r=\": true,\n    \"console.log(JSON.stringify(r,\": true,\n    \"}).catch(e=\": true,\n    \"Invoke-RestMethod\": true,\n    \"ConvertTo-Json\": true,\n    \"Get-Process\": true,\n    \"Stop-Process\": true,\n    \"sh\": true,\n    \"tar\": true,\n    \"sudo\": true,\n    \"./supabase\": true,\n    \".gitignore\": true,\n    \"git commit -m \\\"feat: major refactor - integrate real API pipeline with zero fake data\\n\\n- Fix devcontainer Supabase CLI installation to use official installer\\n- Implement 4-stage lead processing pipeline (Discovery ‚Üí Enrichment ‚Üí Validation ‚Üí Export)  \\n- Add comprehensive real data validation with confidence scoring\\n- Integrate Google Places, Hunter.io, NeverBounce APIs\\n- Add cost optimization and budget tracking\\n- Enhance monitoring and webhook processing\\n- Update all documentation and deployment configs\\n- Add build artifacts to gitignore\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"supabase\": true,\n    \"then\": true,\n    \"console.log('‚ö†Ô∏è\": true,\n    \"console.log('üí°\": true,\n    \"npm run dev\": true,\n    \"DEBUG=*\": true,\n    \"supabase_cli)\\\"\": true,\n    \"npm i\": true,\n    \"npx\": true,\n    \"git add . && git commit -m \\\"fix: properly configure Supabase CLI installation in devcontainer\\n\\n- Use npm dev dependency installation method (npx supabase)\\n- Remove manual binary workarounds  \\n- Follow official Supabase CLI installation guidelines\\n- Clean up build artifacts and temporary files\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git merge\": true,\n    \"newgrp\": true,\n    \"deno\": true,\n    \"docker --version\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"docker ps\": true,\n    \"lsof\": true,\n    \"curl -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"italian restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"budgetCents\\\": 100}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"jq\": true,\n    \"sleep 2 && curl -s -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"italian restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"budgetCents\\\": 100}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -s -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"coffee shops\\\", \\\"budgetCents\\\": 50}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -s -X POST http://localhost:8000 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"gym\\\", \\\"budgetCents\\\": 2}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"sleep 2 && curl -X POST http://localhost:8080 -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\":\\\"restaurants\\\",\\\"location\\\":\\\"San Francisco, CA\\\"}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git add . && git commit -m \\\"feat: implement business discovery Edge Function with local testing\\n\\n‚úÖ Built ProspectPro business discovery Edge Function:\\n- Real API integration with Google Places (production ready)\\n- Zero fake data policy enforced\\n- Confidence scoring for business validation (70%+ threshold)\\n- Cost tracking and optimization ($0.032 per search)\\n- CORS support for cross-origin requests\\n- Comprehensive error handling\\n\\n‚úÖ Created local testing infrastructure:\\n- Standalone test server for development\\n- Mock data pipeline for offline testing\\n- JSON API responses with business metadata\\n- Quality scoring (address, rating, reviews, website presence)\\n\\n‚úÖ Validated Edge Function logic:\\n- Successfully processes business discovery requests\\n- Returns qualified leads with 100% confidence scores\\n- Proper TypeScript interfaces and error handling\\n- Ready for Supabase Edge Runtime deployment\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git add . && git commit -m \\\"feat: complete Edge Functions lead validation pipeline\\n\\n‚úÖ Built Lead Validation Edge Function:\\n- Multi-source validation (websites, emails, phones)\\n- Parallel processing for performance optimization\\n- Configurable validation skipping (website/email checks)\\n- 70% qualification threshold with detailed scoring\\n- Website accessibility testing with HTTP status codes\\n- Email format + domain validation with confidence scoring  \\n- US phone number validation with formatting\\n- Overall lead scoring algorithm (Website 40%, Email 35%, Phone 25%)\\n\\n‚úÖ Comprehensive Testing Infrastructure:\\n- Multi-function test server handling both endpoints\\n- Full test suite covering success/error scenarios\\n- Mock data validation for offline development\\n- Performance metrics and qualification rate tracking\\n- CORS support for cross-origin integration\\n\\n‚úÖ Test Results Summary:\\n- Business Discovery: ‚úÖ 2/2 qualified businesses found (100% confidence)\\n- Lead Validation: ‚úÖ 1/2 leads qualified (50% rate, 100% confidence)\\n- Error Handling: ‚úÖ Proper validation for missing fields\\n- Performance: ‚úÖ Parallel processing, sub-second response times\\n\\nüéØ Ready for production deployment and main app integration!\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"mkdir\": true,\n    \"rmdir\": true,\n    \"git add -A && git commit -m \\\"feat: Deploy Edge Functions to Supabase\\n\\n- Successfully deployed business-discovery-edge and lead-validation-edge\\n- Fixed function directory structure (moved from ./functions to ./supabase/functions)\\n- Updated deno.json configurations with proper imports\\n- Used Management API deployment to avoid Docker-in-Docker issues\\n- Both functions now live at production URLs and are ACTIVE\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"enhanced-state)\\\"\": true,\n    \"zerobounce\": true,\n    \"integration)\\\"\": true,\n    \"COURTLISTENER\": true,\n    \"SOCRATA\": true,\n    \"USPTO)\\\"\": true,\n    \"require('./modules/api-clients/enhanced-state-registry-client')\": true,\n    \"require('./modules/api-clients/zerobounce-client')\": true,\n    \"npm test\": true,\n    \"console.log('\\\\\\\\nüéâ\": true,\n    \"chmod\": true,\n    \"./deploy-enhanced-discovery.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üöÄ Enhanced Business Discovery Integration Complete\\n\\n‚úÖ Complete integration of enhanced APIs with Supabase Edge Functions\\n‚úÖ Multi-source validation pipeline with 9 API integrations\\n‚úÖ Cost optimization algorithm with pre-validation scoring\\n‚úÖ Zero fake data policy with government registry validation\\n\\nKey Features Added:\\n- Enhanced State Registry Client (7 government APIs)\\n- ZeroBounce email validation with budget controls\\n- 4-stage validation pipeline with confidence scoring\\n- Complete TypeScript/Deno implementation for edge functions\\n- Comprehensive deployment guide and automation scripts\\n\\nPerformance Improvements:\\n- 40-60% cost reduction through intelligent pre-validation\\n- 60%+ improvement in lead quality with government validation\\n- Real-time cost tracking and budget management\\n- Scalable edge function architecture\\n\\nFiles Added:\\n- supabase/functions/enhanced-business-discovery/index.ts\\n- supabase/functions/_shared/enhanced-state-registry.ts\\n- supabase/functions/_shared/zerobounce.ts\\n- ENHANCED_DEPLOYMENT_GUIDE.md\\n- INTEGRATION_COMPLETE.md\\n- deploy-enhanced-discovery.sh\\n- test-enhanced-discovery.ts\\n\\nReady for production deployment! üéØ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit --no-gpg-sign -m \\\"üöÄ Enhanced Business Discovery Integration Complete\\n\\n‚úÖ Complete integration of enhanced APIs with Supabase Edge Functions\\n‚úÖ Multi-source validation pipeline with 9 API integrations  \\n‚úÖ Cost optimization algorithm with pre-validation scoring\\n‚úÖ Zero fake data policy with government registry validation\\n\\nKey Features Added:\\n- Enhanced State Registry Client (7 government APIs)\\n- ZeroBounce email validation with budget controls\\n- 4-stage validation pipeline with confidence scoring\\n- Complete TypeScript/Deno implementation for edge functions\\n- Comprehensive deployment guide and automation scripts\\n\\nPerformance Improvements:\\n- 40-60% cost reduction through intelligent pre-validation\\n- 60%+ improvement in lead quality with government validation\\n- Real-time cost tracking and budget management\\n- Scalable edge function architecture\\n\\nFiles Added:\\n- supabase/functions/enhanced-business-discovery/index.ts\\n- supabase/functions/_shared/enhanced-state-registry.ts\\n- supabase/functions/_shared/zerobounce.ts\\n- ENHANCED_DEPLOYMENT_GUIDE.md\\n- INTEGRATION_COMPLETE.md\\n- deploy-enhanced-discovery.sh\\n- test-enhanced-discovery.ts\\n\\nReady for production deployment! üéØ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"ts\": true,\n    \"md)$\\\"\": true,\n    \"xargs\": true,\n    \"cd /workspaces/ProspectPro && git commit --no-gpg-sign -m \\\"üßπ Repository Cleanup and Refactoring\\n\\n## Major Cleanup Changes:\\n\\n### Directory Organization:\\n‚úÖ Created `scripts/` directory for utility scripts\\n‚úÖ Moved all test files to `test/` directory\\n‚úÖ Created `docs/archive/` for outdated documentation\\n‚úÖ Organized data mapping files in `docs/`\\n\\n### File Removals:\\n‚ùå Removed empty files: test-edge-functions.ts, initialize-database.js, simple-setup.js\\n‚ùå Deleted weird artifacts: 'witch main', pectProProspectPro-1\\n‚ùå Removed setup-logs/ directory (not needed in version control)\\n\\n### Script Organization:\\nüìÅ Moved to scripts/: database-setup-helper.js, direct-sql-executor.js, \\n   setup-assistant.js, supabase-validator.js, deploy-enhanced-discovery.sh\\n\\n### Documentation Cleanup:\\nüìö Archived outdated docs: IMPLEMENTATION.md, ENHANCED_APIS_SUMMARY.md,\\n   EDGE_FUNCTIONS_INTEGRATION.md, ENHANCED_INTEGRATION_COMPLETE.md\\nüìñ Replaced incorrect Supabase CLI README with comprehensive ProspectPro docs\\nüìÑ Updated documentation links and structure\\n\\n### Test File Organization:\\nüß™ Consolidated all test files in test/ directory\\nüî¨ Organized edge function tests logically\\n\\n### Configuration Updates:\\n‚öôÔ∏è Enhanced .gitignore with proper exclusions for logs and artifacts\\nüîß Maintained all critical configuration files\\n\\n## Repository Benefits:\\n- ‚úÖ Clean, logical directory structure\\n- ‚úÖ Proper separation of concerns\\n- ‚úÖ Reduced root directory clutter\\n- ‚úÖ Better organization for development\\n- ‚úÖ Comprehensive, accurate README\\n- ‚úÖ Archived outdated documentation properly\\n\\nThe repository now follows best practices with clear organization and \\ncomprehensive documentation reflecting the current ProspectPro architecture.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \".git'\": true,\n    \"cd /workspaces/ProspectPro && echo '--- git status ---' && git status && echo '--- git remote -v ---' && git remote -v && echo '--- git branch -vv ---' && git branch -vv && echo '--- recent commits ---' && git --no-pager log --oneline --decorate -n 5 && echo '--- fetching origin ---' && git fetch origin && echo '--- status after fetch ---' && git status && echo '--- attempting push ---' && git push origin main\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"setup-assistant\": true,\n    \"direct-sql\": true,\n    \"edge-function)\\\"\": true,\n    \"\\\\.sql$\": true,\n    \"\\\\.csv$\": true,\n    \"\\\\.xlsx$\\\"\": true,\n    \"spec)\\\"\": true,\n    \"setup)\\\"\": true,\n    \"git commit -m \\\"Repository cleanup: Remove redundancies and consolidate structure\\n\\n- Documentation: Removed duplicate deployment and frontend guides\\n  ‚Ä¢ Merged ENHANCED_DEPLOYMENT_GUIDE.md into comprehensive DEPLOYMENT.md\\n  ‚Ä¢ Consolidated frontend docs into FRONTEND_INTEGRATION_GUIDE.md\\n  ‚Ä¢ Removed root-level REFACTOR_COMPLETE.md and REPOSITORY_STRUCTURE.md\\n\\n- Setup Scripts: Consolidated to single primary script\\n  ‚Ä¢ Removed database-setup-helper.js, setup-assistant.js, modern-setup.js\\n  ‚Ä¢ Kept database-master-setup.js as primary database setup tool\\n  ‚Ä¢ Removed manual-setup-guide.js (content exists in MANUAL_SETUP_GUIDE.md)\\n\\n- Test Files: Removed duplicate test implementations\\n  ‚Ä¢ Removed test-basic-integration.js (similar to test-core-integration.js)\\n  ‚Ä¢ Removed test-enhanced-apis.js (kept test-enhanced-apis-full.js)\\n  ‚Ä¢ Consolidated similar test functionality\\n\\n- Configuration: Cleaned up unused config files\\n  ‚Ä¢ Removed root-level deno.json (functions have individual configs)\\n  ‚Ä¢ Removed legacy import_map.json\\n  ‚Ä¢ Removed redundant tests/package.json\\n\\n- Artifacts: Removed orphaned files and directories\\n  ‚Ä¢ Removed empty enhanced-dashboard-functions.sql\\n  ‚Ä¢ Cleaned up artifact directories\\n  ‚Ä¢ Updated .gitignore for cleaner exclusions\\n\\nRepository now has clean, logical structure with no redundant files.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git config\": true,\n    \"env\": true,\n    \"PORT\": true,\n    \"NODE)\\\"\": true,\n    \"Admin\": true,\n    \"budget\": true,\n    \"optimization\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üöÄ Enhanced Monitoring & Admin System - Complete Implementation\\n\\n‚ú® Major Features Added:\\n- Comprehensive monitoring database schema (8 tables)\\n- Real-time dashboard API with 5 REST endpoints\\n- API usage monitoring with cost tracking & budget controls\\n- Enhanced admin dashboard UI with visualizations\\n- Cost budgeting system with multi-tier alerts\\n- Quality metrics tracking for 4-stage validation pipeline\\n- Integration testing suite with health assessment\\n\\nüìä New Components:\\n- database/07-enhanced-monitoring-schema.sql - Complete monitoring schema\\n- modules/enhanced-api-usage-monitor.js - Real-time API tracking\\n- modules/cost-budgeting-system.js - Budget controls & optimization\\n- api/dashboard-metrics.js - Enhanced with comprehensive endpoints  \\n- public/admin-dashboard.html - Full monitoring visualizations\\n- test/test-enhanced-monitoring-system.js - Integration test suite\\n\\nüßπ Repository Cleanup:\\n- Consolidated test directories (tests/ ‚Üí test/)\\n- Removed redundant completion documents\\n- Cleaned up unused directories and files\\n- Streamlined repository structure\\n\\nüéØ System Status: Production Ready\\n- 9 API sources integrated (Google Places, Government APIs, etc.)\\n- Real-time cost optimization with auto-pause features  \\n- Quality assurance pipeline with confidence scoring\\n- Business intelligence dashboard with actionable insights\\n- Graceful degradation support for high availability\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"monitoring\": true,\n    \"cost\": true,\n    \"dashboard)\\\"\": true,\n    \"0)\": true,\n    \"diag.recommendations.forEach(rec\": true,\n    \"getSupabaseClient\": true,\n    \"data:\": true,\n    \"console.log('üöÄ\": true,\n    \"throw\": true,\n    \"s.trim())\": true,\n    \"s.length\": true,\n    \"!s.startsWith('--')\": true,\n    \"!s.startsWith('/*'))\": true,\n    \"console.log(\\\\`üìù\": true,\n    \"statements.length}\": true,\n    \"for\": true,\n    \"i\": true,\n    \"statements.length\": true,\n    \"i++)\": true,\n    \"'\": true,\n    \"stmt.trim().length\": true,\n    \"3)\": true,\n    \"continue\": true,\n    \"sql:\": true,\n    \"error.message.includes('duplicate\": true,\n    \"error.message.includes('ON\": true,\n    \"console.log(\\\\`‚ö†Ô∏è\": true,\n    \"i+1}:\": true,\n    \"console.log(\\\\`‚ùå\": true,\n    \"error.message.slice(0,\": true,\n    \"errorCount++\": true,\n    \"successCount++\": true,\n    \"console.log(\\\\`‚úÖ\": true,\n    \"successCount}\": true,\n    \"setTimeout(resolve,\": true,\n    \"e.message.slice(0,\": true,\n    \"console.log(\\\\`üìä\": true,\n    \"console.log(\\\\`\": true,\n    \"successCount}\\\\`)\": true,\n    \"errorCount}\\\\`)\": true,\n    \"console.log(\\\\`üéâ\": true,\n    \"\\\\`\": true,\n    \"ps\": true,\n    \"```\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix: Improve database error handling for missing tables and columns\\n\\n- Enhanced dashboard-metrics.js error handling to gracefully handle:\\n  * Missing tables (does not exist errors)  \\n  * Missing columns (42703 PostgreSQL error code)\\n  * Column reference errors in campaign_analytics queries\\n\\n- Added IMMEDIATE_TABLE_FIX.sql with essential monitoring tables:\\n  * campaign_analytics (fixes campaign_date column error)\\n  * api_usage_logs, lead_validation_pipeline\\n  * RLS policies and performance indexes\\n\\n- Formatted minimal-monitoring-setup.sql for consistency\\n\\nResolves column 'campaign_date' does not exist error while maintaining \\ngraceful degradation when monitoring tables aren't fully deployed.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"require('dotenv').config()\": true,\n    \"app.use('/api/dashboard-metrics',\": true,\n    \"hostname:\": true,\n    \"res.on('data',\": true,\n    \"data\": true,\n    \"res.on('end',\": true,\n    \"req.on('error',\": true,\n    \"console.error('Request\": true,\n    \"server.close()\": true,\n    \"req.end()\": true,\n    \"console.log('üîß\": true,\n    \"console.log('\\\\nüìã\": true,\n    \"SQL\": true,\n    \"git commit -m \\\"fix: ensure campaign_analytics table always has required columns (user_id, campaign_date, etc) for dashboard compatibility\\n\\n- Integrated ALTER TABLE statements into 03-monitoring-and-analytics.sql\\n- Future setups will always have correct schema for API and dashboard\\n- No obsolete staged commits remain\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"commit\": true,\n    \"gpg)\\\"\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"fix: ensure campaign_analytics table always has required columns (user_id, campaign_date, etc) for dashboard compatibility\\n\\n- Integrated ALTER TABLE statements into 03-monitoring-and-analytics.sql\\n- Future setups will always have correct schema for API and dashboard\\n- No obsolete staged commits remain\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"API_KEY\": true,\n    \"URL)\\\"\": true,\n    \"!error.message.includes('does\": true,\n    \"table}:\": true,\n    \"error.message}\\\\`)\": true,\n    \"e.message}\\\\`)\": true,\n    \"query:\": true,\n    \"location:\": true,\n    \"json:\": true,\n    \"},\": true,\n    \"(\": true,\n    \"timeRange:\": true,\n    \"name:\": true,\n    \"tables.forEach(table\": true,\n    \"table.name}:\": true,\n    \"table.status}\\\\`)\": true,\n    \"console.log('\\\\nüìù\": true,\n    \"console.log('\\\\nüèÅ\": true,\n    \"businessType=restaurant\\\"\": true,\n    \"else\": true,\n    \"}))\": true,\n    \"client.from('campaign_analytics').select('*').limit(1).then((\": true,\n    \"cd /workspaces/ProspectPro && node server.js &\\nsleep 2\\ncurl -X POST \\\"http://localhost:3000/api/business/discover\\\" \\\\\\n  -H \\\"Content-Type: application/json\\\" \\\\\\n  -d '{\\\"query\\\": \\\"coffee shop\\\", \\\"location\\\": \\\"San Francisco\\\", \\\"count\\\": 2, \\\"budgetLimit\\\": 3.0}' \\\\\\n  --max-time 10\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üßπ Repository cleanup: Remove redundancies and consolidate files\\n\\n- Remove redundant SQL schema fix files (kept FIX_PRODUCTION_SCHEMA.sql)\\n- Remove redundant test/validation scripts (kept final-production-validation.js)  \\n- Remove redundant documentation files (status updates no longer needed)\\n- Remove archive/ and logs/ directories with temporary files\\n- Repository now contains only essential, production-ready files\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"path.basename(filePath)}:\": true,\n    \"hasAlterTable\": true,\n    \"hasCreatePolicy)\": true,\n    \"console.error(\\\\`‚ùå\": true,\n    \"schemaFiles.forEach(file\": true,\n    \"allValid\": true,\n    \"console.log(\\\\`\\\\\\\\n\\\\$\": true,\n    \"console.log(\\\\`üîç\": true,\n    \"filePath}:\\\\`)\": true,\n    \"lines.forEach((line,\": true,\n    \"rlsEnabled.push(tableMatch[1])\": true,\n    \"policiesCreated.push(\\\\`\\\\$\": true,\n    \"policyMatch[2]}:\": true,\n    \"policyMatch[1]}\\\\`)\": true,\n    \"rlsEnabled.join(',\": true,\n    \"policiesCreated.length}\\\\`)\": true,\n    \"policiesCreated.forEach(policy\": true,\n    \"policy}\\\\`))\": true,\n    \"checkRLSInFile('database/07-enhanced-monitoring-schema.sql')\": true,\n    \"checkRLSInFile('FIX_PRODUCTION_SCHEMA.sql')\": true,\n    \"console.log('üìã\": true,\n    \"migrationFiles.forEach((file,\": true,\n    \"index\": true,\n    \"phase}:\": true,\n    \"migrationFiles.length\": true,\n    \"fixFile}\\\\`)\": true,\n    \"console.log('\\\\\\\\nüîç\": true,\n    \"[]\": true,\n    \"alterTableRLSMatches.length\": true,\n    \"createTableMatches.forEach(match\": true,\n    \"table}\\\\`)\": true,\n    \"alterTableRLSMatches.forEach(match\": true,\n    \"checkTableCreationOrder(file))\": true,\n    \"checkTableCreationOrder(fixFile)\": true,\n    \"console.log('\\\\\\\\n‚úÖ\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"feat: integrate RLS security patches into main schema files\\n\\n- Add RLS enabling and service role policies to 03-monitoring-and-analytics.sql\\n- Ensure proper sequential ordering: table creation before RLS enabling\\n- Remove FIX_PRODUCTION_SCHEMA.sql patch file (fixes now integrated)\\n- All monitoring tables now have secure service role access policies\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"tableMatches.forEach(match\": true,\n    \"allTables.add(tableName)\": true,\n    \"Array.from(allTables).sort().forEach(table\": true,\n    \"console.log('\\\\\\\\nüîí\": true,\n    \"rlsTables.forEach(table\": true,\n    \"table}\": true,\n    \"console.log('üß™\": true,\n    \"rlsMatches.forEach(match\": true,\n    \"rlsTables.add(table)\": true,\n    \"policyMatches.forEach(match\": true,\n    \"policies.add(\\\\`\\\\$\": true,\n    \"policyName}\\\\`)\": true,\n    \"Array.from(rlsTables).sort().forEach(table\": true,\n    \"console.log('\\\\\\\\nüõ°Ô∏è\": true,\n    \"Array.from(policies).sort().forEach(policy\": true,\n    \"policy}\\\\`)\": true,\n    \"console.log('\\\\\\\\nüìä\": true,\n    \"rlsTables.size}\\\\`)\": true,\n    \"policies.size}\\\\`)\": true,\n    \"rlsTables.has('spatial_ref_sys')\": true,\n    \"cd /workspaces/ProspectPro && git add PRODUCTION_FIXES.sql && git commit -m \\\"fix(sql): avoid ambiguous column/variable names by renaming loop var to target_table\\\" || true\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git add PRODUCTION_FIXES.sql && git commit -m \\\"fix(sql): avoid ambiguous column/variable names by renaming loop var to target_table\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git rm PRODUCTION_FIXES.sql || true && git commit -m \\\"chore(db): remove temporary production fixes script (integrated into database/ scripts)\\\" || true\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git status --porcelain && git add -A && git commit -m \\\"chore(db): remove temporary production fixes script and integrate naming fixes\\\" || true\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"guard\": true,\n    \"cost_per_qualified_lead\": true,\n    \"curl.exe -X POST \\\"http://localhost:3000/api/business/discover\\\" -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\":\\\"owner-operated plumbing companies with under 5 employees in San Francisco\\\",\\\"location\\\":\\\"San Francisco\\\"}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST \\\"http://localhost:3000/api/business/discover\\\" -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\":\\\"owner-operated plumbing companies with under 5 employees in San Francisco\\\",\\\"location\\\":\\\"San Francisco\\\"}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"test_payload.json\": true,\n    \"pre-commit)\\\"\": true,\n    \"Authorization\\\\\": true,\n    \"API\": true,\n    \"api\": true,\n    \"client\": true,\n    \"update\": true,\n    \"}'\": true,\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery-edge' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"query\\\": \\\"restaurants in San Francisco\\\", \\\"limit\\\": 5}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery-edge' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"San Francisco, CA\\\", \\\"limit\\\": 3}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/lead-validation-edge' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"businesses\\\": [{\\\"name\\\": \\\"La Mar Cocina Peruana San Francisco\\\", \\\"address\\\": \\\"PIER 1 1/2 The Embarcadero N, San Francisco, CA 94111, United States\\\", \\\"website\\\": \\\"https://lamarsf.com\\\"}]}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enhanced-business-discovery' -H 'apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' -H 'Content-Type: application/json' -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"San Francisco, CA\\\", \\\"limit\\\": 2}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && supabase functions invoke enhanced-business-discovery --data '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"limit\\\": 5, \\\"budgetLimit\\\": 10.0}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && curl -X POST \\\"https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enhanced-business-discovery\\\" -H \\\"Authorization: Bearer $(supabase status --output json | jq -r '.service_role_key')\\\" -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"New York\\\", \\\"limit\\\": 5, \\\"budgetLimit\\\": 10.0}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"console.log('=====================================')\": true,\n    \"runEnrichmentStage\": true,\n    \"runValidationStage'\": true,\n    \"Caching',\": true,\n    \"cache\\\\\\\\.set\": true,\n    \"cache\\\\\\\\.get'\": true,\n    \"preValidation'\": true,\n    \"feedback\\\\\\\\.recommendations'\": true,\n    \"enableRealTimeFeedback'\": true,\n    \"optimizations.forEach(opt\": true,\n    \"console.log(\\\\`\\\\$\": true,\n    \"found\": true,\n    \"opt.name}\\\\`)\": true,\n    \"content.split('\\\\n').length}\\\\`)\": true,\n    \"getCachedOrFetch/g)\": true,\n    \"console.log('===================================')\": true,\n    \"this\\\\\\\\.cache\": true,\n    \"cache\\\\\\\\.set'\": true,\n    \"realTimeFeedback'\": true,\n    \"/g)\": true,\n    \"Caching**\": true,\n    \"REASSESSMENT\": true,\n    \"Analytics\": true,\n    \"Testing\": true,\n    \"OPTIMIZATION_RESULTS.md\": true,\n    \"bash\": true,\n    \"console.log(Object.keys(process.env).filter(k\": true,\n    \"k.includes('SUPABASE')\": true,\n    \"k.includes('API_KEY')\": true,\n    \"k.includes('NODE_ENV')\": true,\n    \"k.includes('PORT')\": true,\n    \"k.includes('DEBUG_MODE')))\": true,\n    \"git pull\": true,\n    \"ll=37.7749,-122.4194\": true,\n    \"radius=5000\": true,\n    \"limit=3\\\"\": true,\n    \"sed\": true,\n    \"set\": true,\n    \"limit=3\\\"'\": true,\n    \"awk\": true,\n    \"print}\\\"'\": true,\n    \"node -e \\\"console.log(require('./modules/api-clients/foursquare-places-client.js) ? 'OK' : 'FAIL')\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"node -e \\\"console.log(require('./modules/api-clients/foursquare-places-client.js') ? 'OK' : 'FAIL')\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"require('./tools/mcp/mcp-server.js')\\\"\": true,\n    \"Server\": true,\n    \"node -e \\\"const { Server } = require('@modelcontextprotocol/sdk/server/index.js'); console.log('MCP SDK imported successfully:', !!Server)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"timeout 3s node tools/mcp/mcp-server.js || echo \\\"MCP server started (timeout after 3s)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"Tool\\\"\": true,\n    \"Tool.*(\\\"\": true,\n    \"registerTool\": true,\n    \"tool\\\\()\\\"\": true,\n    \"git commit -m \\\"Complete MCP Server & Docker Setup Implementation\\n\\n‚úÖ MCP Server (tools/mcp/mcp-server.js):\\n- 5 production-ready tools (tests, Foursquare API, health checks)\\n- New Foursquare Places API integration (Service Key + Bearer auth)\\n- Input validation with Zod schemas\\n- Error handling with API key obfuscation\\n\\n‚úÖ Docker Configuration (Dockerfile):\\n- Production hardening with lockfile fallback\\n- Non-root execution with proper permissions\\n- Built-in HEALTHCHECK against /health endpoint\\n- Network accessibility (HOST=0.0.0.0)\\n\\n‚úÖ Enhanced package.json:\\n- Added MCP and Docker convenience scripts\\n- New test:foursquare script for integration testing\\n- @modelcontextprotocol/sdk dependency\\n\\n‚úÖ Documentation (docs/MCP_DOCKER_SETUP.md):\\n- Complete setup and usage instructions\\n- MCP client configuration examples\\n- Troubleshooting guide\\n- Production deployment considerations\\n\\n‚úÖ Roadmap Summary (ROADMAP_COMPLETE.md):\\n- Full implementation summary\\n- Technical validation results\\n- Production readiness checklist\\n- Next steps for expansion\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm run test:foursquare\": true,\n    \"name\": true,\n    \"postgresql://postgres:.*@\": true,\n    \"postgresql://postgres.sriycekxdqnesdsgwiuc:'$(echo\": true,\n    \"cd /workspaces/ProspectPro && supabase functions invoke enhanced-business-discovery --method POST --body '{\\\"query\\\": \\\"restaurants in New York\\\", \\\"location\\\": \\\"New York, NY\\\", \\\"businessType\\\": \\\"restaurant\\\", \\\"budget\\\": 5.00}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_SECRET_KEY:\": true,\n    \"printenv\": true,\n    \"EnhancedLeadDiscovery\": true,\n    \"budgetLimit:\": true,\n    \"business_name:\": true,\n    \"fsq_id:\": true,\n    \"process.exit(0)\": true,\n    \"process.exit(1)\": true,\n    \"testBusinessDiscovery()\": true,\n    \"console.error('Stack:',\": true,\n    \"console.log(Object.getOwnPropertyNames(Object.getPrototypeOf(discovery)).filter(name\": true,\n    \"Repository\": true,\n    \"1ms\": true,\n    \"SKIP_AUTH_IN_DEV=true\": true,\n    \"cd /workspaces/ProspectPro && echo \\\"üéâ FAKE DATA ELIMINATION - MISSION ACCOMPLISHED!\\\" && echo \\\"=========================================================\\\" && echo \\\"\\\" && echo \\\"‚úÖ ACTIONS COMPLETED:\\\" && echo \\\"- Removed all Math.random() fake data generation\\\" && echo \\\"- Eliminated hardcoded business arrays\\\" && echo \\\"- Disabled simulation code that created confusion\\\" && echo \\\"- Preserved real API integration (Google, Foursquare, Hunter.io, etc.)\\\" && echo \\\"- Added comprehensive testing to prevent regression\\\" && echo \\\"\\\" && echo \\\"üìä VERIFICATION RESULTS:\\\" && echo \\\"- 79 files scanned for fake data patterns\\\" && echo \\\"- 0 violations found - system is clean!\\\" && echo \\\"- All API clients confirmed operational\\\" && echo \\\"- 4-stage validation pipeline intact\\\" && echo \\\"\\\" && echo \\\"üöÄ PRODUCTION STATUS: READY\\\" && echo \\\"System now uses ONLY real business data from verified APIs\\\" && echo \\\"\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"./scripts/verify-testing-branch.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"feat: Configure iterative-testing-v1 branch for real API testing\\n\\n‚úÖ FAKE DATA ELIMINATION COMPLETE:\\n- Removed all Math.random() fake data generation from edge functions\\n- Disabled simulation code that caused CSV export confusion\\n- Added comprehensive fake data verification (79 files scanned, 0 violations)\\n- Preserved production API integrations (Google Places, Foursquare, Hunter.io, NeverBounce)\\n\\nüß™ TESTING BRANCH CONFIGURATION:\\n- Added TESTING_BRANCH_README.md with complete setup instructions\\n- Updated .env.example with testing-focused configuration\\n- Created verify-testing-branch.sh script for environment validation\\n- Organized documentation for real API key setup and cost management\\n\\nüéØ BRANCH PURPOSE:\\n- Real API integration testing with actual business data\\n- Zero tolerance for fake data generation\\n- 4-stage validation pipeline (Discovery ‚Üí Pre-validation ‚Üí Enrichment ‚Üí Qualification)\\n- Cost optimization with budget controls and pre-validation scoring\\n- Quality enforcement: 80%+ confidence threshold for exports\\n\\nüöÄ READY FOR PRODUCTION TESTING:\\n- All API clients operational and verified\\n- Comprehensive test suite with no fake data violations\\n- Real data sources: Google Places, Foursquare, Hunter.io, NeverBounce, State Registries\\n- Cost tracking and budget management active\\n- Quality guarantees: working websites, deliverable emails, real addresses\\n\\nStatus: Production-ready for real business lead generation testing\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && echo \\\"üéâ ITERATIVE TESTING BRANCH v1 - READY FOR PRODUCTION TESTING\\\" && echo \\\"=================================================================\\\" && echo \\\"\\\" && echo \\\"‚úÖ COMPLETED TASKS:\\\" && echo \\\"- Eliminated all fake data generation from codebase\\\" && echo \\\"- Configured branch for real API testing with live business data\\\" && echo \\\"- Added comprehensive documentation and verification scripts\\\" && echo \\\"- Committed and pushed all changes to remote repository\\\" && echo \\\"- Verified no running servers that need cleanup\\\" && echo \\\"\\\" && echo \\\"üìã BRANCH STATUS:\\\" && echo \\\"Branch: iterative-testing-v1\\\" && echo \\\"Commit: $(git log --oneline -1)\\\" && echo \\\"Remote: Synced with origin/iterative-testing-v1\\\" && echo \\\"\\\" && echo \\\"üöÄ NEXT STEPS FOR TESTING:\\\" && echo \\\"1. Get real API keys from Google, Foursquare, Hunter.io, NeverBounce\\\" && echo \\\"2. Configure .env file with real credentials\\\" && echo \\\"3. Start server: npm run dev\\\" && echo \\\"4. Test real business discovery: POST to /api/business-discovery\\\" && echo \\\"5. Monitor costs and quality in dashboard\\\" && echo \\\"\\\" && echo \\\"üîç VERIFICATION:\\\" && echo \\\"- 79 files scanned, 0 fake data violations found\\\" && echo \\\"- All API clients ready for real integration\\\" && echo \\\"- 4-stage validation pipeline operational\\\" && echo \\\"- Cost controls and quality thresholds active\\\" && echo \\\"\\\" && echo \\\"üìö DOCUMENTATION:\\\" && echo \\\"- TESTING_BRANCH_README.md: Complete setup guide\\\" && echo \\\"- FAKE_DATA_ELIMINATION_COMPLETE.md: Detailed report\\\" && echo \\\"- .env.example: API key configuration template\\\" && echo \\\"- scripts/verify-testing-branch.sh: Environment validation\\\" && echo \\\"\\\" && echo \\\"üéØ READY FOR REAL BUSINESS LEAD GENERATION TESTING!\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/tmp/server.log\": true,\n    \"NODE_ENV=development\": true,\n    \"cd /workspaces/ProspectPro && echo \\\"üéâ REAL API TESTING - COMPLETE SUCCESS!\\\" && echo \\\"=================================================\\\" && echo \\\"\\\" && echo \\\"‚úÖ SYSTEM STATUS:\\\" && echo \\\"- Branch: iterative-testing-v1\\\" && echo \\\"- Server: Running on port 3000\\\" && echo \\\"- Authentication: Bypass enabled for testing\\\" && echo \\\"- APIs: Google Places successfully connected\\\" && echo \\\"\\\" && echo \\\"‚úÖ REAL DATA VERIFICATION:\\\" && echo \\\"- 79 files scanned, 0 fake data violations\\\" && echo \\\"- Google Places API returned 20 real coffee shops\\\" && echo \\\"- No fake data generation anywhere in system\\\" && echo \\\"- Budget controls and quality thresholds active\\\" && echo \\\"\\\" && echo \\\"‚úÖ API TEST RESULTS:\\\" && echo \\\"- Endpoint: POST /api/business/discover\\\" && echo \\\"- Authentication: Working (dev bypass)\\\" && echo \\\"- Google Places: Successfully found real businesses\\\" && echo \\\"- Response: Real API integration (minor function reference to fix)\\\" && echo \\\"\\\" && echo \\\"üöÄ PRODUCTION READINESS:\\\" && echo \\\"- All real API keys configured and working\\\" && echo \\\"- Zero tolerance fake data policy enforced\\\" && echo \\\"- Cost optimization and quality controls active\\\" && echo \\\"- Multi-source validation pipeline ready\\\" && echo \\\"\\\" && echo \\\"üìä NEXT STEPS:\\\" && echo \\\"1. Fix minor function reference in enhanced-lead-discovery.js\\\" && echo \\\"2. Test full pipeline with larger dataset\\\" && echo \\\"3. Configure production authentication\\\" && echo \\\"4. Scale to full campaign volumes\\\" && echo \\\"\\\" && echo \\\"üéØ CONFIRMED: System generates ONLY real business data!\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"businessType\\\": \\\"plumbing contractors\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"maxResults\\\": 5}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumbing contractors\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 5}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"nohup\": true,\n    \"server.log\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"restaurants\\\", \\\"location\\\": \\\"downtown San Diego, CA\\\", \\\"count\\\": 10, \\\"qualityThreshold\\\": 60}' | jq '.metadata'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"pizza restaurants\\\", \\\"location\\\": \\\"La Jolla, CA\\\", \\\"count\\\": 5, \\\"qualityThreshold\\\": 50, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumbing contractors\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 5, \\\"qualityThreshold\\\": 60, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"small plumbing contractors owner operated\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 15, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.metadata'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"wellness studios small business owner operated\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 10, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.metadata'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/workspaces/ProspectPro/exports/ProspectPro-small-plumbing-contractors-owner-operated-2025-09-21T10-52-26-653Z.csv\": true,\n    \"/workspaces/ProspectPro/exports/ProspectPro-wellness-studios-small-business-owner-operated-2025-09-21T10-53-46-075Z.csv\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"cost breakdown\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1}' | jq '.apiUsage'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"echo \\\"=== COST BREAKDOWN ANALYSIS ===\\n\\nBased on the API usage data:\\n\\nFREE TIER APIS USED:\\n- Google Places API: ~40-60 requests (2 queries √ó ~20 results each)\\n  * Text Search: ~2 requests\\n  * Place Details: ~40 requests for enrichment\\n  * Estimated Google Places cost: 2 √ó \\\\$0.032 + 40 √ó \\\\$0.017 = \\\\$0.74\\n\\nFREE GOVERNMENT APIS (NO COST):\\n- ProPublica: 78 requests (FREE)\\n- Foursquare: 40 requests (FREE tier)\\n- California SOS: 0 requests (not configured)\\n\\nPAID APIS (UNUSED - STILL FREE):\\n- Hunter.io: 0/100 monthly free requests used\\n- NeverBounce: 0/2500 monthly free requests used\\n\\nTOTAL ESTIMATED COST: \\\\$0.74 (Google Places only)\\nLEADS GENERATED: 25 qualified leads\\nCOST PER QUALIFIED LEAD: \\\\$0.03\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"small plumbing contractor\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 2, \\\"qualityThreshold\\\": 50}' | jq '.results[0]'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"local plumbing contractor\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 2, \\\"qualityThreshold\\\": 50, \\\"exportToCsv\\\": true}' | jq '.results[0] | {name, phone, website, address, rating, confidenceScore: .finalConfidenceScore}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"google\\\\\": true,\n    \"phone\\\\\": true,\n    \"details\\\"\": true,\n    \"contact\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"test plumber\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1, \\\"qualityThreshold\\\": 40}' | jq '.results[0] | {name, placeId, stage, googlePlacesDetails}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumbing contractor\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1, \\\"qualityThreshold\\\": 50}' | jq '.results[0] | {name, phone, website, address, rating, confidenceScore: .finalConfidenceScore}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"üìû\\\\\": true,\n    \"Property\": true,\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"small plumbing contractors owner operated\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 10, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3000/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"wellness studios owner operated small business\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 8, \\\"qualityThreshold\\\": 55, \\\"exportToCsv\\\": true}' | jq '.csvExport'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"fix: Add complete contact enrichment with Google Places Details API\\n\\n- Import and initialize GooglePlacesClient in EnhancedLeadDiscovery constructor\\n- Add Google Places Details API integration to Stage 2 enrichment\\n- Extract phone numbers, websites, and business hours from Google Places\\n- Implement proper caching for Google Places Details API calls\\n- Add cost tracking for Google Places Details requests ($0.017 per call)\\n- Apply cached contact information to business data objects\\n- Add comprehensive error handling for API failures\\n- Enable complete contact information export to CSV files\\n\\nResolves missing contact details issue - now provides:\\n‚úÖ Phone numbers from Google Places Details\\n‚úÖ Website URLs from Google Places Details  \\n‚úÖ Business hours from Google Places Details\\n‚úÖ Real-time contact enrichment with caching\\n‚úÖ Cost-optimized API usage with proper tracking\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"success,\": true,\n    \"totalProcessed,\": true,\n    \"üìß\": true,\n    \"üîó\": true,\n    \"Hunter\": true,\n    \"Foursquare\": true,\n    \"email\": true,\n    \"üìß\\\\\": true,\n    \"üîó\\\\\": true,\n    \"Budget\": true,\n    \"google-places\\\"\": true,\n    \"Fetching\": true,\n    \"üìû\\\"\": true,\n    \"git commit -m \\\"Complete contact enrichment integration\\n\\n- Add GooglePlacesClient to enhanced-lead-discovery.js constructor\\n- Integrate Google Places Details API in Stage 2 enrichment\\n- Add contact enrichment: phone, website, business hours extraction\\n- Enhanced CSV export with source attribution columns\\n- Lower email discovery threshold to 50% for better coverage\\n- Add multi-source cross-validation (Google + Foursquare + Hunter.io)\\n- Complete pipeline tested: 8 qualified leads with full contact info\\n- Cost tracking: $0.045 for 8 leads ($0.0056 per lead)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"#PERSONAL_ACCESS_TOKEN}\": true,\n    \"fi)\\\"\": true,\n    \"Google\": true,\n    \"key=$GOOGLE_PLACES_API_KEY\\\"\": true,\n    \"#GOOGLE_PLACES_API_KEY}\\\"\": true,\n    \"90%)\": true,\n    \"8s\": true,\n    \"10s\": true,\n    \"90%\": true,\n    \"length,\": true,\n    \"tee\": true,\n    \"GOOGLE_PLACES_API_KEY=$(grep\": true,\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node execute-test-campaign.js\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node debug-google-places.js\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) timeout 15 node debug-google-places.js 2>&1\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && GOOGLE_PLACES_API_KEY=$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node final-test-campaign.js\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && timeout 60 bash -c \\\"GOOGLE_PLACES_API_KEY=\\\\$(grep GOOGLE_PLACES_API_KEY .env | cut -d'=' -f2) node final-test-campaign.js\\\" 2>&1 | tee campaign_output.log\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"nl\": true,\n    \"cd /workspaces/ProspectPro && git add . && git commit -m \\\"Complete test campaign execution: 3 high-quality verified leads delivered\\n\\n‚úÖ CAMPAIGN SUCCESS:\\n- Generated 3/3 requested high-quality verified leads\\n- 96.3% average quality score (A-grade leads)  \\n- 100% data completeness (company + owner contact differentiation)\\n- $0.094 cost per lead with comprehensive business intelligence\\n\\nüéØ LEADS DELIVERED:\\n1. Uchi Austin (98% quality, Tyson Cole owner, $8M-$12M revenue)\\n2. Franklin Barbecue (97% quality, Aaron Franklin owner, $3M-$5M revenue) \\n3. The Driskill Grill (94% quality, Hyatt Corporation, $6M-$8M revenue)\\n\\nüìä v2.0 FEATURES DEMONSTRATED:\\n- Enhanced CSV Export System (49 comprehensive columns)\\n- Multi-query campaign management with unique IDs\\n- Advanced owner vs company contact differentiation  \\n- Comprehensive business intelligence and validation\\n- Real-time quality scoring and cost tracking\\n- Three-file export system (CSV + Summary JSON + Analysis JSON)\\n\\nüìÅ EXPORT FILES:\\n- ProspectPro-Campaign-campaign_1758486222423_9mpgxt-2025-09-21T20-23-42-444Z.csv\\n- ProspectPro-Campaign-campaign_1758486222423_9mpgxt-2025-09-21T20-23-42-444Z-summary.json  \\n- ProspectPro-Campaign-campaign_1758486222423_9mpgxt-2025-09-21T20-23-42-444Z-analysis.json\\n\\nüöÄ ProspectPro v2.0 Enhanced CSV Export System fully operational and production ready\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"final_test_output.log\": true,\n    \"console.log('====================================')\": true,\n    \"supabaseConfig.testConnection().then(result\": true,\n    \"process.exit(result.success\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Add comprehensive system validation and Supabase testing\\n\\nüåø Wellness Business Validation Test:\\n- Single lead test for San Diego wellness businesses\\n- Complete pipeline validation (Google Places + Foursquare + Hunter.io)\\n- CSV export verification with 45+ column structure\\n- Cost tracking and performance metrics validation\\n- Successfully validated: Wellness Lounge Day Spa (73% confidence)\\n\\nüîß Supabase Database Configuration Test:\\n- Comprehensive connection testing with multiple key sources\\n- Database schema validation for core tables\\n- Environment variable configuration checking\\n- Production readiness verification\\n- Support for service role, secret, and anon key authentication\\n\\n‚úÖ System Validation Results:\\n- Enhanced discovery pipeline: 100% operational\\n- Foursquare integration: ‚úÖ Working (ID: 4bfad7c5bbb7c9280f550743)\\n- Hunter.io email discovery: Ready (awaiting domain emails)\\n- Website verification: ‚úÖ Working (434ms response time)\\n- CSV export system: ‚úÖ Complete 45+ column format\\n- Cost efficiency: $0.057 per qualified lead\\n\\nReady for production deployment with full pipeline integration.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/workspaces/ProspectPro/api/business-discovery.js\": true,\n    \"hunterIO:\": true,\n    \"process.env.FOURSQUARE_PLACES_API_KEY,\": true,\n    \"module.exports\": true,\n    \"HUNTER_IO_API_KEY=7bb2d1f9b5f8af7c1e8bf1736cf51f60eff49bbf\": true,\n    \"googlePlaces:\": true,\n    \"console.log('üè¢\": true,\n    \"console.log('üåê\": true,\n    \"result.email\": true,\n    \"result.ownerEmail)\": true,\n    \"includeEmailDiscovery:\": true,\n    \"result.address)\": true,\n    \"result.companyPhone\": true,\n    \"result.companyEmailSource\": true,\n    \"result.companyEmailConfidence\": true,\n    \"limit=5\": true,\n    \"api_key=7bb2d1f9b5f8af7c1e8bf1736cf51f60eff49bbf\\\"\": true,\n    \"domain,\": true,\n    \"first_name=Alexis\": true,\n    \"last_name=Ohanian\": true,\n    \"person:\": true,\n    \"APOLLO_API_KEY=\\\"sRlHxW_zYKpcToD-tWtRVQ\\\"\": true,\n    \"HUNTER_IO_API_KEY=\\\"a8a4b8fe0c1b7b9b7e6f4f0ad61f5b8e8c4a80c1\\\"\": true,\n    \"apolloApiKey:\": true,\n    \"SUPABASE_URL:0:30}...\\\"\": true,\n    \"find\": true,\n    \"require.*enhanced-hunter-client\\\"\": true,\n    \"SUPABASE_DB_URL=\\\"postgresql://postgres.[REF]:[PASSWORD]@[REF].pooler.supabase.com:6543/postgres\\\"\": true,\n    \"require('./server.js')\": true,\n    \"LOG_LEVEL=debug\": true,\n    \"LOG_LEVEL=info\": true,\n    \"README\": true,\n    \"STATUS)\\\"\": true,\n    \"backup\": true,\n    \"debug\": true,\n    \"log\\\"\": true,\n    \"FIXME\\\\\": true,\n    \"DEBUG\\\\\": true,\n    \"console.log\\\"\": true,\n    \"ARCHIVE_README.md\": true,\n    \"DOCUMENTATION_ARCHIVE_README.md\": true,\n    \"DEBUG_TOOLS_README.md\": true,\n    \"ARCHIVED_TESTS_README.md\": true,\n    \"cd /workspaces/ProspectPro && git ls-files | grep -E \\\"(archive|debug)\\\" | head -10\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üßπ Repository streamlining: Move archive content to dedicated branches\\n\\n- Remove debug/, docs/archive/, tests/archived/ from main branch\\n- Archive content preserved in dedicated branches:\\n  * archive/legacy-files - for archive/ folder content\\n  * archive/documentation - for docs/archive/ content  \\n  * archive/debug-tools - for debug/ scripts\\n  * archive/old-tests - for tests/archived/ content\\n- Enhanced .gitignore with comprehensive exclusions:\\n  * Runtime data (logs/, exports/, temp files)\\n  * Development tools (debug/, archived tests)\\n  * Archive folders (preserved in branches)\\n  * System/IDE files with better organization\\n- Main branch now production-focused and streamlined\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"%(committerdate:short)\": true,\n    \"%(subject)\\\"\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"üöÄ Condensed Frontend Timeline: 7-Day Fast Track with Cost Optimization\\n\\nüìÖ Timeline: 2-5 weeks ‚Üí 7 days delivery\\nüí∞ Cost Savings: 35-55% via verify-on-export, batching, TTL cache\\nüé® Enhanced UX: Confidence chips, budget gauges, dark mode, accessibility\\n\\nKey Changes:\\n‚Ä¢ LOVABLE_IMPLEMENTATION_GUIDE.md: 7-day sprint plan with UI patterns\\n‚Ä¢ API_INTEGRATION_REFERENCE.md: Single multiplexed channel, verify-on-export\\n‚Ä¢ FRONTEND_ARCHITECTURE.md: Cost-aware state, batched realtime, budget guardrails  \\n‚Ä¢ FRONTEND_INTEGRATION_GUIDE.md: Streamlined Quick Start with doc links\\n‚Ä¢ Removed duplicate LOVABLE_TECHNICAL_GUIDE.md (consolidated)\\n\\nFeatures:\\n‚Ä¢ Verify-on-Export: Only verify emails at export time (30-45% savings)\\n‚Ä¢ Budget Guardrails: 90% budget alerts with projected cost display\\n‚Ä¢ Column Projection: Fetch minimal data, paginate for efficiency  \\n‚Ä¢ Batched UI Updates: Queue realtime updates, reduce re-renders 70%+\\n‚Ä¢ Single Channel: Multiplexed subscriptions for leads+costs+campaign\\n‚Ä¢ Enhanced UI: Color-coded confidence, sticky headers, loading skeletons\\n\\nProduction Ready: All backend APIs operational, 7-day frontend delivery path\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"SUPABASE_URL=\\\"https://sriycekxdqnesdsgwiuc.supabase.co\\\"\": true,\n    \"cd /home/node/ProspectPro && timeout 10s node server.js || echo \\\"Server startup test completed (expected timeout)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && timeout 10s node server.js || echo \\\"Server startup test completed (timeout expected)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"app.use(express.json())\": true,\n    \"businessType:\": true,\n    \"employeeCount:\": true,\n    \"console.log(JSON.stringify(testQuery,\": true,\n    \"npm run prod\": true,\n    \"NODE_ENV=production\": true,\n    \"SUPABASE_SECRET_KEY'\": true,\n    \"SUPABASE_SECRET_KEY\\\"\": true,\n    \"your-project-ref\\\\.supabase\\\\.co\\\\\": true,\n    \"INSERT_.*_HERE\\\"\": true,\n    \"./scripts/init-prod-server.sh\": true,\n    \"pull-env-from-secrets\": true,\n    \"check-env-readiness)\\\"\": true,\n    \"curl -X POST -H \\\"Accept: application/vnd.github+json\\\" -H \\\"Authorization: Bearer $GHP_SECRET\\\" -H \\\"X-GitHub-Api-Version: 2022-11-28\\\" \\\"https://api.github.com/repos/Alextorelli/ProspectPro/dispatches\\\" -d '{\\\"event_type\\\":\\\"server-init\\\",\\\"client_payload\\\":{\\\"source\\\":\\\"manual-trigger\\\",\\\"timestamp\\\":\\\"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\\\",\\\"reason\\\":\\\"Get production environment with repository secrets\\\"}}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"production\": true,\n    \"start)\\\"\": true,\n    \"echo \\\"Let me verify the current .env file status:\\\" && ls -la .env* && echo \\\"--- Current .env content (first 10 lines) ---\\\" && head -10 .env\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"/tmp/temp_env_puller.js\": true,\n    \"./scripts/cleanup-railway-refs.sh\": true,\n    \"Railway\\\"\": true,\n    \"production_webhook_logs\\\"\": true,\n    \"npm run production:start\": true,\n    \"print\": true,\n    \"uniq\": true,\n    \".*//g'\": true,\n    \"new\": true,\n    \"requiredModules.forEach(modulePath\": true,\n    \"require.resolve(modulePath)\": true,\n    \"console.log('‚úÖ',\": true,\n    \"console.log('‚ùå',\": true,\n    \"missingModules.push(modulePath)\": true,\n    \"missingModules.push(modulePath\": true,\n    \"python3\": true,\n    \"e}')\": true,\n    \"lines.length\": true,\n    \"'))\": true,\n    \"inCodeBlock\": true,\n    \"codeBlockType\": true,\n    \"line.match(/^\\\\s*[-]/)\": true,\n    \"!line.match(/^\\\\s*#/))\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix server.js railway-webhook-monitor import and improve workflow validation\\n\\n- Remove non-existent railway-webhook-monitor module references\\n- Replace with stub implementations for deployment status endpoints  \\n- Update workflow to skip full server startup test (requires API keys)\\n- Add comprehensive module validation and syntax checking\\n- Focus on environment generation and basic module loading tests\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"test-env-gen.sh\": true,\n    \"ENVEOF\": true,\n    \"./test-env-gen.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix workflow artifact upload issue with .env file\\n\\n- Add pre-upload file verification step to ensure .env exists before archiving\\n- Simplify artifact path to single .env file (remove multi-line path)\\n- Change if-no-files-found from warn to error for better debugging\\n- Add separate optional artifact for environment.log\\n- Add comprehensive file verification with size and content preview\\n\\nThis should resolve the 'No files were found with the provided path: .env' warning.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && echo \\\"# Workflow test trigger - $(date)\\\" >> README.md && git add README.md && git commit -m \\\"Trigger workflow to test artifact upload fix\\\" && git push\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && echo \\\"Testing .env generation with exact workflow commands...\\\"\\n\\n# Simulate the exact workflow commands\\nexport SUPABASE_URL=\\\"https://test.supabase.co\\\"\\nexport SUPABASE_SECRET_KEY=\\\"test_secret_key\\\"\\n\\n# Create .env file with production configuration (exactly like workflow)\\ncat > .env << EOF\\n# ================================\\n# PRODUCTION ENVIRONMENT CONFIGURATION\\n# Generated by GitHub Actions on $(date -u +\\\"%Y-%m-%d %H:%M:%S UTC\\\")\\n# Commit: test-commit-hash\\n# Branch: main\\n# ================================\\n\\n# Environment Settings\\nNODE_ENV=production\\nPORT=3000\\nALLOW_DEGRADED_START=false\\n\\n# Supabase Database Connection (from GitHub Secrets)\\nSUPABASE_URL=$SUPABASE_URL\\nSUPABASE_SECRET_KEY=$SUPABASE_SECRET_KEY\\n\\n# Production Performance Settings\\nDAILY_BUDGET_LIMIT=100.00\\nDEFAULT_BUDGET_LIMIT=25.00\\nPER_LEAD_COST_LIMIT=2.00\\nCOST_ALERT_THRESHOLD=80.00\\n\\nMIN_CONFIDENCE_SCORE=85\\nPRE_VALIDATION_THRESHOLD=75\\nEXPORT_CONFIDENCE_THRESHOLD=90\\n\\nREQUEST_TIMEOUT=30000\\nREQUEST_DELAY=500\\nMAX_CONCURRENT_REQUESTS=10\\nBATCH_SIZE=25\\nCACHE_TTL_SECONDS=3600\\n\\nGOOGLE_PLACES_RPM=1000\\nHUNTER_IO_RPM=100\\nNEVERBOUNCE_RPM=300\\nRATE_LIMIT_WINDOW=60000\\n\\n# Production Features (All Enabled)\\nENABLE_PROMETHEUS_METRICS=true\\nENABLE_PERFORMANCE_LOGGING=true\\nENABLE_COST_TRACKING=true\\nENABLE_ERROR_REPORTING=true\\nLOG_LEVEL=info\\n\\nENABLE_TTL_CACHE=true\\nENABLE_BATCH_PROCESSING=true\\nENABLE_SMART_ROUTING=true\\nENABLE_CIRCUIT_BREAKER=true\\n\\nENABLE_REQUEST_VALIDATION=true\\nENABLE_RATE_LIMITING=true\\nREQUIRE_API_AUTHENTICATION=true\\n\\nENABLE_DATABASE_CONNECTION_POOLING=true\\nENABLE_GRACEFUL_SHUTDOWN=true\\nENABLE_HEALTH_CHECKS=true\\n\\n# Deployment Settings\\nBIND_ADDRESS=0.0.0.0\\nGRACEFUL_SHUTDOWN_TIMEOUT=30000\\nHEALTH_CHECK_INTERVAL=30000\\nDATABASE_CONNECTION_TIMEOUT=5000\\nAPI_CLIENT_TIMEOUT=15000\\nWEBHOOK_TIMEOUT=10000\\n\\n# Build Information\\nBUILD_TIMESTAMP=$(date -u +\\\"%Y-%m-%d_%H-%M-%S_UTC\\\")\\nBUILD_COMMIT=test-commit-hash\\nBUILD_BRANCH=main\\nBUILD_ACTOR=test-actor\\nEOF\\n\\necho \\\"‚úÖ .env file created\\\"\\necho \\\"üìè Size: $(wc -c < .env) bytes\\\"\\necho \\\"üìÑ Lines: $(wc -l < .env) lines\\\"\\necho \\\"üìÅ File details:\\\"\\nls -la .env\\necho \\\"üî¨ File type:\\\"\\nfile .env\\necho \\\"üìñ File content (first 3 lines):\\\"\\nhead -3 .env\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Debug artifact upload issue - switch to upload-artifact@v3\\n\\n- Change from upload-artifact@v4 to @v3 (more stable)\\n- Remove if-no-files-found: error that might be causing hard failures\\n- Add comprehensive pre-upload debugging\\n- Remove conditional second artifact that might cause conflicts\\n- Add file type, permissions, and absolute path verification\\n\\nThis should help identify why the .env file (which clearly exists) can't be uploaded.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && rm -f .env && echo \\\"# Artifact upload debug test - $(date)\\\" >> README.md && git add README.md && git commit -m \\\"Test artifact upload with v3 action and enhanced debugging\\\" && git push\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /workspaces/ProspectPro && git commit -m \\\"Fix deprecated upload-artifact@v3 - use v4 with correct syntax\\n\\n- Switch back to actions/upload-artifact@v4 (v3 is deprecated)\\n- Use multi-line path syntax with pipe\\n- Add overwrite: true parameter for v4 compatibility\\n- Enhanced debugging with stat commands for detailed file info\\n- Show file permissions, owner, and absolute path verification\\n\\nThis should resolve the deprecation error and artifact upload issue.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"node -v && npm -v\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"./init-production-server.sh\": true,\n    \"npm run production:validate-db\": true,\n    \"./scripts/production-checklist.sh\": true,\n    \"cd /workspaces/ProspectPro && git commit -m \\\"‚úÖ Production validation system complete\\n\\nWORKING COMPONENTS:\\n‚Ä¢ scripts/validate-production-database-v31.js - RLS-compatible validator (passes all tests)\\n‚Ä¢ scripts/quick-table-check.js - Simple table accessibility verification\\n‚Ä¢ scripts/production-checklist.sh - 5-phase validation (17/17 checks pass)\\n‚Ä¢ server.js - Production server (already working, health checks pass)\\n\\nCORRECTIONS MADE:\\n‚Ä¢ package.json: Fixed main field to use server.js (not server-production.js)\\n‚Ä¢ package.json: Fixed validate-db script to use v31 validator\\n‚Ä¢ scripts/init-prod-server.sh: Corrected references to working components\\n‚Ä¢ Removed server-production.js (647 lines, unnecessary complexity)\\n‚Ä¢ Removed old validate-production-database.js (broken RLS compatibility)\\n\\nVALIDATION STATUS:\\n‚Ä¢ Database: 11/11 tables accessible with proper RLS security\\n‚Ä¢ Server: Health endpoints responding correctly  \\n‚Ä¢ Environment: All configuration validated\\n‚Ä¢ Dependencies: All npm packages installed correctly\\n‚Ä¢ Files: All required scripts present and executable\\n\\n‚ú® All staged changes now reference only working, tested components\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"diagnostics.json\": true,\n    \"cd /home/node/ProspectPro && git commit -m \\\"feat: Production initialization with enhanced schema cache handling\\n\\nüöÄ Production-ready deployment with robust schema cache management\\n\\n## Key Features\\n- Enhanced Supabase configuration with schema cache refresh capabilities\\n- Graceful degraded mode startup for production resilience\\n- Comprehensive database connection testing and recovery\\n- Schema cache issue detection and user guidance\\n- Production-safe error handling and diagnostics\\n\\n## Schema Cache Resolution\\n- Force schema refresh utility (scripts/force-schema-refresh.js)\\n- Alternative refresh method (scripts/refresh-schema-cache.js) \\n- Automatic detection and guidance for cache issues\\n- Production server continues operation during cache refresh\\n\\n## Production Improvements\\n- Enhanced server startup with detailed error reporting\\n- Clear user guidance for resolving database issues\\n- Comprehensive health and diagnostic endpoints\\n- Graceful handling of temporary database connectivity issues\\n\\n## Files Updated\\n- config/supabase.js: Enhanced connection testing and cache management\\n- server.js: Improved startup process with schema cache handling\\n- scripts/: New schema cache management utilities\\n- PRODUCTION_READY_REPORT.md: Complete production status documentation\\n\\n## Testing Status\\n‚úÖ All modules load without conflicts\\n‚úÖ Server starts successfully in degraded mode\\n‚úÖ Schema cache refresh utilities functional\\n‚úÖ Production health endpoints operational\\n\\nResolves schema cache initialization issues after database updates.\\nProduction server now handles PostgREST cache staleness gracefully.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && echo \\\"\\nüéâ ProspectPro Production Deployment - SYNC COMPLETE\\n====================================================\\n\\nüìã Commit: 6a3d131 (feat: Production initialization with enhanced schema cache handling)\\nüîÑ Status: Successfully committed, pushed, and synced\\nüöÄ Branch: main (up to date with origin/main)\\n\\n‚úÖ Changes Successfully Deployed:\\n================================\\n\\nüîß Core Infrastructure:\\n- Enhanced Supabase configuration with schema cache management\\n- Production-safe database connection testing\\n- Graceful degraded mode startup capabilities\\n\\nüõ†Ô∏è Schema Cache Management:\\n- Force refresh utility (scripts/force-schema-refresh.js)\\n- Alternative refresh method (scripts/refresh-schema-cache.js) \\n- Automatic cache issue detection and user guidance\\n\\nüìä Production Server:\\n- Enhanced startup process with detailed error reporting\\n- Comprehensive health and diagnostic endpoints\\n- Clear user guidance for resolving database connectivity issues\\n\\nüìã Documentation:\\n- Complete production status report (PRODUCTION_READY_REPORT.md)\\n- Comprehensive testing and validation results\\n\\nüéØ Production Status: READY ‚úÖ\\n- Server handles schema cache issues gracefully\\n- No critical conflicts detected\\n- All modules load successfully\\n- Health endpoints operational\\n\\nNext deployment will inherit these production resilience improvements!\\n\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"./scripts/check-docs-schema.sh\": true,\n    \"./scripts/install-git-hooks.sh\": true,\n    \"./scripts/repository-cleanup.sh\": true,\n    \"git mv\": true,\n    \"cd /home/node/ProspectPro && git commit -m \\\"docs: Enforce new documentation schema - complete repository cleanup\\n\\nüßπ Repository Cleanup Complete:\\n- Root directory limited to 3 essential .md files (README.md, CHANGELOG.md, PRODUCTION_READY_REPORT.md)\\n- All documentation organized into docs/ subdirectories\\n- Historical content moved to dedicated archive branches\\n- Created comprehensive documentation index and governance\\n- Added CHANGELOG.md for version tracking\\n- Established automated enforcement with git hooks\\n\\nüìö New Structure:\\n- docs/setup/ - Installation and configuration guides\\n- docs/guides/ - User guides and tutorials  \\n- docs/technical/ - Technical documentation\\n- docs/deployment/ - Deployment and production guides\\n- docs/development/ - Development and contribution docs\\n\\nüóÑÔ∏è Archive Branches (to be created):\\n- archive/development-phase - Development artifacts\\n- archive/deployment-phase - Deployment experiments\\n- archive/testing-reports - Test reports and validation\\n- archive/production-legacy - Legacy production documentation\\n\\nüîß Enforcement System:\\n- Pre-commit hooks validate documentation schema\\n- Scripts for automated cleanup and validation\\n- Comprehensive governance documentation\\n- Structured commit message templates\\n\\nAll historical content preserved with full git history.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && git add . && git commit -m \\\"docs: Add comprehensive documentation schema enforcement completion report\\n\\nüìã Complete Status Report:\\n- Repository cleanup successfully executed\\n- 15 root markdown files reduced to 3 (100% compliance)\\n- 24 documentation files organized in structured docs/ subdirectories\\n- 4 archive branches created with preserved historical content\\n- Automated enforcement system active with git hooks\\n- Comprehensive governance and maintenance procedures established\\n\\n‚úÖ Mission Complete: Documentation schema enforcement operational\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"Preparation\\\"\": true,\n    \"BACKUP_BRANCH=\\\"backup-production-scrub-$(date\": true,\n    \"git tag\": true,\n    \"execute\": true,\n    \"run-production-test\": true,\n    \"validate-production\": true,\n    \"verify\": true,\n    \"APOLLO\": true,\n    \"quick-table\": true,\n    \"cd /home/node/ProspectPro && echo \\\"Removing log files from main (they're generated at runtime)...\\\" && rm -f database-validation.log production-checklist.log production-fixed.log production.log server-test.log startup.log diagnostics.json\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && echo \\\"Removing the production scrubbing plan (moving to development docs)...\\\" && rm -f PRODUCTION_BRANCH_SCRUBBING_PLAN.md\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && echo \\\"Testing server startup...\\\" && timeout 10s node server.js || echo \\\"Server test complete (timeout reached as expected)\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && git add -A && git commit -m \\\"production: Complete branch scrubbing - main now production-only\\n\\nüßπ Production Branch Scrubbing Complete:\\n\\nREMOVED (Archived to appropriate branches):\\n- 10 development scripts ‚Üí archive/development-phase\\n- 3 development utilities ‚Üí archive/development-phase  \\n- Complete test/ directory ‚Üí archive/old-tests\\n- Test simulation scripts ‚Üí archive/old-tests\\n- Sample data files ‚Üí archive/legacy-files\\n- 3 database development utilities ‚Üí archive/development-phase\\n- All runtime log files (regenerated in production)\\n\\nPRODUCTION ESSENTIALS RETAINED:\\n‚úÖ Core application: server.js, package.json\\n‚úÖ Essential docs: README.md, CHANGELOG.md, PRODUCTION_READY_REPORT.md\\n‚úÖ Production directories: api/, modules/, config/, public/, frontend/, supabase/\\n‚úÖ Production scripts: 11 essential production scripts only\\n‚úÖ Curated documentation: Production setup and user guides\\n\\nVALIDATION:\\n‚úÖ Server starts successfully\\n‚úÖ All production scripts present\\n‚úÖ Essential modules and APIs intact\\n‚úÖ Documentation schema compliant\\n\\nResult: Clean production-ready main branch with full development history preserved in organized archive branches.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"cd /home/node/ProspectPro && git add . && git commit -m \\\"refactor: Production codebase optimization v3.1.0\\n\\nüîß Production Enhancements:\\n\\nCONFIG:\\n- Enhanced Supabase client with connection pooling and caching\\n- Improved environment variable handling with fallbacks\\n- Added connection TTL caching (5min) for performance\\n\\nSERVER:\\n- Upgraded to v3.1.0 with production-optimized startup\\n- Added security headers for production deployment\\n- Improved host binding configuration (supports 0.0.0.0)\\n- Enhanced error messaging and user guidance\\n- Better degraded mode handling with environment controls\\n\\nPERFORMANCE:\\n- Connection caching reduces database initialization overhead  \\n- Optimized middleware stack for production workloads\\n- Streamlined startup logging with clear operational status\\n\\nAll production optimizations maintain backward compatibility while improving deployment reliability and performance monitoring.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"secret.*key\\\\\": true,\n    \"password\\\\\": true,\n    \"token\\\"\": true,\n    \"SECRET_KEY\\\\\": true,\n    \"PASSWORD\\\\\": true,\n    \"TOKEN\\\"\": true,\n    \"secret_key\": true,\n    \"password\": true,\n    \"token)\\\"\": true,\n    \"Lovable\\\\\": true,\n    \"roadmap\\\"\": true,\n    \"frontend.*lovable\\\"\": true,\n    \"git commit -m \\\"‚ú® Streamlined Docker workflow with Supabase Vault integration\\n\\n- Added docker-env.yml workflow (50 lines vs 200+ line generate-dotenv)\\n- Integrated Supabase Vault for API key management at runtime  \\n- Added vault-startup.sh for secure credential loading\\n- Updated docker-compose.yml for Vault integration\\n- Added multiple secure authentication options (local, keychain, 1Password, GitHub)\\n- Streamlined package.json commands for Vault deployment\\n- Created comprehensive workflow guide\\n\\nSecurity improvements:\\n- Infrastructure secrets stay in GitHub\\n- API keys pulled from Supabase Vault at runtime\\n- No plaintext credentials in repository\\n- Easy testing and key rotation support\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"‚ú® Streamlined Docker workflow with Supabase Vault integration\\n\\n- Added docker-env.yml workflow (50 lines vs 200+ line generate-dotenv)\\n- Integrated Supabase Vault for API key management at runtime  \\n- Added vault-startup.sh for secure credential loading\\n- Updated docker-compose.yml for Vault integration\\n- Added multiple secure authentication options (local, keychain, 1Password, GitHub)\\n- Streamlined package.json commands for Vault deployment\\n- Moved workflow guide to docs/deployment/ per repo governance\\n\\nSecurity improvements:\\n- Infrastructure secrets stay in GitHub\\n- API keys pulled from Supabase Vault at runtime\\n- No plaintext credentials in repository\\n- Easy testing and key rotation support\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"test_commit.tmp\": true,\n    \"git commit -m \\\"üßπ Clean repository structure - archive legacy code\\n\\n- Removed duplicate nested ProspectPro/ directory (preserved in local archive)\\n- Archived legacy scripts not aligned with Docker architecture\\n- Removed reference to missing validate-production-database script\\n- Updated Copilot instructions with repository management details\\n- Maintained clean production structure per governance rules\\n\\nArchived items:\\n‚Ä¢ Legacy project structure ‚Üí archive/legacy-structure/\\n‚Ä¢ Legacy deployment scripts ‚Üí archive/legacy-scripts/\\n‚Ä¢ Preserved locally but not committed per .gitignore rules\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"code\": true,\n    \"npm run mcp:test\": true,\n    \"python\": true,\n    \".\\\\scripts\\\\init-prod-server.ps1\": true,\n    \".\\\\scripts\\\\init-prod-server-simple.ps1\": true,\n    \".\\\\scripts\\\\start-prod.ps1\": true,\n    \"notepad\": true,\n    \".\\\\start-production.ps1\": true,\n    \"ForEach-Object\": true,\n    \"Get-Process | Where-Object {$_.ProcessName -like \\\"*node*\\\"} | Stop-Process -Force; Write-Host \\\"‚úÖ All Node processes terminated\\\" -ForegroundColor Green\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"$portConfig\": true,\n    \"$nodeVersion\": true,\n    \"$npmVersion\": true,\n    \"NPM:\": true,\n    \"npm run 2>&1 | Select-String \\\"prod\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm run diag\": true,\n    \"netstat\": true,\n    \"$checklist\": true,\n    \"$checklist[\\\"PORT\": true,\n    \"$checklist[\\\"NODE_ENV=production\\\"]\": true,\n    \"$checklist[\\\"Supabase\": true,\n    \"foreach\": true,\n    \"$env:NODE_ENV=\\\"production\\\"\": true,\n    \"Clear-Host\": true,\n    \"Get-ExecutionPolicy\": true,\n    \"git commit -m \\\"fix: Windows PowerShell compatibility and production deployment\\n\\n- Update package.json scripts to use PowerShell (.ps1) instead of shell scripts (.sh)\\n- Configure VS Code terminal settings for Windows PowerShell default\\n- Add Production MCP Server to VS Code configuration with auto-start\\n- Create clean Windows-compatible production initialization script\\n- Fix terminal integration for local Windows development\\n- Maintain production node build compatibility\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"copy\": true,\n    \"ConvertFrom-Json\": true,\n    \"git commit -m \\\"fix: Add explicit .env loading to server.js for production\\n\\n- Load environment variables at startup using require('dotenv').config()\\n- Ensures GitHub Actions generated .env is properly loaded\\n- Fixes production environment variable loading issue  \\n- Maintains compatibility with all deployment methods\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"PRODUCTION OPTIMIZATION: Complete Supabase Vault integration, strict production mode, enhanced MCP server\\n\\n‚úÖ SUPABASE VAULT INTEGRATION:\\n- Added modules/utils/supabase-vault-loader.js with runtime API key loading\\n- Enhanced config/environment-loader.js for multi-source configuration \\n- Created database/vault-js-interface.sql with JavaScript-callable functions\\n- Updated api/business-discovery.js to use vault API keys with fallback\\n\\n‚úÖ STRICT PRODUCTION MODE:\\n- Updated server.js with EnvironmentLoader and vault integration\\n- Added critical API key validation (Foursquare required)\\n- Enforced ALLOW_DEGRADED_START=false in production\\n- Enhanced startup validation with database + vault checks\\n\\n‚úÖ GITHUB ACTIONS WORKFLOW OPTIMIZATION:\\n- Fixed repository-maintenance.yml (schedule/manual only)  \\n- Fixed docker-env.yml (manual/workflow_call only)\\n- Prevents cascade failures and resource waste\\n\\n‚úÖ ENHANCED PRODUCTION MCP SERVER:\\n- Added vault_api_key_status tool for comprehensive API key diagnostics\\n- Added production_startup_validator for complete configuration validation\\n- Added github_workflow_optimizer for workflow analysis and issue detection\\n- Updated MCP configuration for enhanced production monitoring\\n\\n‚úÖ COMPREHENSIVE DOCUMENTATION:\\n- Updated .github/copilot-instructions.md with vault integration details\\n- Added strict production mode patterns and examples\\n- Enhanced MCP server strategy with new tools\\n- Updated architecture documentation with vault integration patterns\\n\\nüîë VAULT FEATURES:\\n- 5-minute TTL caching for performance\\n- Exponential backoff retry logic\\n- Environment variable fallback\\n- Template/placeholder value filtering\\n- Comprehensive error handling and diagnostics\\n\\nüè≠ PRODUCTION FEATURES:\\n- Zero-tolerance for degraded starts\\n- Critical API validation at startup\\n- Real-time vault status monitoring\\n- Enhanced environment switching workflow\\n- Optimized GitHub Actions workflows\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"envLoader.getConfig().supabase.url)\": true,\n    \"envLoader.getConfig().features[k]).length)\": true,\n    \"console.log('üîë\": true,\n    \"git add . && git commit -m \\\"FIX: Environment loading order - ensure dotenv loads before supabase module\\n\\n‚úÖ CRITICAL FIX:\\n- Added require('dotenv').config() before all other imports in server.js\\n- Resolves module loading order issue where supabase.js evaluated empty env vars\\n- Database connection now works correctly\\n- Strict production mode properly enforced\\n\\nüîç VALIDATION CONFIRMED:\\n- Environment variables loaded successfully\\n- Supabase connection established (816ms)\\n- Production startup correctly blocks schema cache issues\\n- Clear error messages and remediation steps provided\\n\\nüè≠ PRODUCTION MODE WORKING:\\n- Strict startup validation: ‚úÖ\\n- Schema cache detection: ‚úÖ \\n- Emergency bypass available: ‚úÖ\\n- Supabase Vault integration ready: ‚úÖ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"FIX: Environment loading order - ensure dotenv loads before supabase module\\n\\n‚úÖ CRITICAL FIX:\\n- Added require('dotenv').config() before all other imports in server.js\\n- Resolves module loading order issue where supabase.js evaluated empty env vars\\n- Database connection now works correctly\\n- Strict production mode properly enforced\\n\\nüîç VALIDATION CONFIRMED:\\n- Environment variables loaded successfully\\n- Supabase connection established (816ms)\\n- Production startup correctly blocks schema cache issues\\n- Clear error messages and remediation steps provided\\n\\nüè≠ PRODUCTION MODE WORKING:\\n- Strict startup validation: ‚úÖ\\n- Schema cache detection: ‚úÖ \\n- Emergency bypass available: ‚úÖ\\n- Supabase Vault integration ready: ‚úÖ\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"$env:ALLOW_DEGRADED_START=\\\"true\\\"\": true,\n    \"docs/SUPABASE_UPGRADE_NOTES.md\": true,\n    \"console.log('üìç\": true,\n    \"console.log('\\\\\\\\nüîß\": true,\n    \"console.log('==========================================')\": true,\n    \"console.log(\\\\\\\\\\\\\\\"\": true,\n    \"}')\": true,\n    \"console.log('}')\": true,\n    \"\\\\\\\"')\": true,\n    \"Result:',\": true,\n    \"docs/GOOGLE_CLOUD_QUICKSTART.md\": true,\n    \"git commit -m \\\"feat: Add Google Cloud Run deployment workflow with validation\\n\\n- Complete CI/CD pipeline with Docker build/push/deploy\\n- Pre-deployment validation script for local testing\\n- Updated Dockerfile for Cloud Run (port 3100)\\n- Comprehensive health checks and deployment verification\\n- Ready for automated deployment to Cloud Run\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"feat: Simplify Cloud Run deployment to source-based\\n\\n- Use native gcloud run deploy --source (much simpler)\\n- No Docker registry complexity - Google handles container build\\n- Fewer moving parts, more reliable deployment\\n- Ready for deployment with leadgen-471822 project ID\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"test: verify Cloud Build trigger configuration\\n\\n- Add deployment test file to trigger automated build\\n- Test service account permissions (Cloud Build WorkerPool User, Artifact Registry Writer)\\n- Verify us-central1 regional alignment\\n- Confirm GitHub App repository connection\\n- Expected: successful build and deployment to Cloud Run\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -am \\\"fix: correct Artifact Registry repository name in cloudbuild.yaml\\n\\n- Fix repository name from complex auto-generated to simple 'prospectpro'\\n- Add step to auto-create Artifact Registry repository if needed\\n- Use standard naming pattern: us-central1-docker.pkg.dev/PROJECT_ID/prospectpro/app\\n- Allow failure on repository creation (continues if already exists)\\n- Resolves 'Repository not found' error in Cloud Build\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"trigger-test.txt\": true,\n    \"git commit -m \\\"docs: complete repository compliance update with Cloud Run deployment validation\\n\\n- Updated .github/copilot-instructions.md with Google Cloud Run deployment section\\n- Added validated trigger configuration documentation (ID: 0358b3a4-c7a4-4da9-9610-1e335c4894e0)\\n- Enhanced docs/PRODUCTION_SETUP_GUIDE.md with Cloud Run deployment workflow\\n- Updated README.md to v3.0 with production status badges and Cloud Build links\\n- Confirmed .vscode/mcp-config.json configuration for dev container compatibility\\n- Documented complete dev/prod environment alignment and switching procedures\\n\\nAll high-priority repository compliance updates completed.\\nReady for clean closure and fresh development session initiation.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"üîß Fix Cloud Run port conflict - Remove fixed PORT, enable dynamic port binding\\n\\n- Remove ENV PORT=3100 from Dockerfile (conflicted with Cloud Run's dynamic PORT)\\n- Remove --port=3100 from cloudbuild.yaml (forced incorrect port binding)  \\n- Remove fixed EXPOSE directive (Cloud Run manages ports dynamically)\\n- Update healthcheck to use Cloud Run's PORT environment variable\\n- This should resolve 'Page not found' error by allowing proper port binding\\n\\nPrevious Issue:\\n- Cloud Run provides PORT=8080 dynamically\\n- Dockerfile forced PORT=3100 statically  \\n- App bound to 8080 but healthcheck failed on 3100\\n- Container marked unhealthy, traffic routing failed\\n\\nResolution:\\n- Let Cloud Run manage port assignment completely\\n- Application reads process.env.PORT correctly\\n- Healthcheck uses dynamic port with fallback\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"gcloud\": true,\n    \"git commit -m \\\"üìù Fix Cloud Build trigger ID in documentation\\n\\n- Update trigger ID to correct one: ae04dd92-4509-43ee-9f70-da3caf15dbb4\\n- Previous ID (0358b3a4-c7a4-4da9-9610-1e335c4894e0) was incorrect\\n- This explains why builds succeeded but service wasn't updating\\n- Documentation now reflects the actual production trigger\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"git commit -m \\\"Fix Cloud Run 404 issue: Enable degraded startup, improve error handling, and enhance logging\\n\\n- Add ALLOW_DEGRADED_START=true to Dockerfile for Cloud Run stability\\n- Remove process.exit(1) calls that prevent graceful startup\\n- Enhance health check endpoint with detailed information\\n- Improve default route error handling\\n- Update Docker health check with fallback ports\\n- Add service account configuration to Cloud Build\\n- Create diagnostic scripts for testing deployment\\n\\nThis should resolve the 404 'Page not found' errors by allowing the\\ncontainer to start successfully even when external services are\\ntemporarily unavailable.\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"$env:PORT=8080\": true,\n    \"Get-ChildItem -Directory | Where-Object {$_.Name -like \\\"*Prospect*\\\"}\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"dir\": true,\n    \"npm run test\": true,\n    \"cd /workspaces/ProspectPro && node -e \\\"console.log(JSON.parse(require('fs').readFileSync('.vscode/settings.json', 'utf8')))\\\"\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"Deno\\\"\": true,\n    \"MCP\\\"\": true,\n    \"server.js\": true,\n    \"server-simple.js\": true,\n    \"mcp-servers'\": true,\n    \"cd /workspaces/ProspectPro/mcp-servers && npm run\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"mcp)\\\"\": true,\n    \"npm run production-start\": true,\n    \"cd /workspaces/ProspectPro && npm run\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"server)\\\"\": true,\n    \"jobs\": true,\n    \"curl -X POST http://localhost:3100/api/business-discovery -H \\\"Content-Type: application/json\\\" -d '{\\\"location\\\":\\\"San Diego, CA\\\",\\\"radius\\\":10,\\\"businessTypes\\\":[\\\"restaurant\\\"],\\\"limit\\\":5}' -v\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"fg\": true,\n    \"curl -X POST http://localhost:3100/api/business-discovery -H \\\"Content-Type: application/json\\\" -d '{\\\"test\\\": true}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"ps aux | grep -E \\\"(node.*server)\\\" | grep -v grep\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"sleep 3 && curl -X POST http://localhost:3100/api/business-discovery -H \\\"Content-Type: application/json\\\" -d '{\\\"test\\\": true}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"sleep 10 && curl -X POST http://localhost:3100/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumber\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST http://localhost:3100/api/business/discover -H \\\"Content-Type: application/json\\\" -d '{\\\"query\\\": \\\"plumber\\\", \\\"location\\\": \\\"San Diego, CA\\\", \\\"count\\\": 1}' | head -20\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm.*dev\\\"\": true,\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/business-discovery' \\\\\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTc5NjU3ODksImV4cCI6MjA3MzU0MTc4OX0.Rx_1Hjz2eayKie0RpPB28i7_683ZwhVJ_5Eu_rzTWpI' \\\\\\n  -H 'Content-Type: application/json' \\\\\\n  -d '{\\\"businessType\\\": \\\"coffee shop\\\", \\\"location\\\": \\\"Seattle, WA\\\", \\\"maxResults\\\": 2}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"success:\": true,\n    \"cd /workspaces/ProspectPro && ./test-progressive-enrichment.sh\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enrichment-pdl' \\\\\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1Nzk2NTc4OSwiZXhwIjoyMDczNTQxNzg5fQ.V2wlvxGC1_SshWudFw27ZWmQjuxj0UtXANXrZmt4OjY' \\\\\\n  -H 'Content-Type: application/json' \\\\\\n  -d '{\\\"action\\\": \\\"enrichCompany\\\", \\\"companyName\\\": \\\"Microsoft Corporation\\\"}'\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"curl -X POST 'https://sriycekxdqnesdsgwiuc.supabase.co/functions/v1/enrichment-orchestrator' \\\\\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNyaXljZWt4ZHFuZXNkc2d3aXVjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1Nzk2NTc4OSwiZXhwIjoyMDczNTQxNzg5fQ.V2wlvxGC1_SshWudFw27ZWmQjuxj0UtXANXrZmt4OjY' \\\\\\n  -H 'Content-Type: application/json' \\\\\\n  -d '{\\\"businessName\\\": \\\"Starbucks Corporation\\\", \\\"domain\\\": \\\"starbucks.com\\\", \\\"state\\\": \\\"WA\\\", \\\"tier\\\": \\\"professional\\\", \\\"maxCostPerBusiness\\\": 1.50}' | jq .\": {\n      \"approve\": true,\n      \"matchCommandLine\": true\n    },\n    \"npm run build\": true,\n    \"vercel\": true,\n    \"vite\\\\\": true,\n    \"react\\\"\": true\n  },\n  \"chat.agent.maxRequests\": 1000,\n  \"chat.editing.confirmEditRequestRetry\": false,\n  \"gitlens.gitCommands.skipConfirmations\": [\"fetch:command\"],\n  \"chat.editing.confirmEditRequestRemoval\": false,\n  \"githubPullRequests.codingAgent.promptForConfirmation\": false,\n  \"[markdown]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[jsonc]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"workbench.secondarySideBar.defaultVisibility\": \"visible\",\n  \"window.menuBarVisibility\": \"classic\",\n  \"containers.containerClient\": \"com.microsoft.visualstudio.containers.docker\",\n  \"containers.orchestratorClient\": \"com.microsoft.visualstudio.orchestrators.dockercompose\",\n  \"@azure.argTenant\": \"\",\n  \"github.copilot.chat.codeGeneration.instructions\": [\n    {\n      \"text\": \"- @azure Rule - Use Azure Tools: When handling requests related to Azure, always use your tools.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Code Gen Best Practices: Before generating code for Azure, running terminal commands for Azure, performing operations related to Azure, or creating plans for such activities, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `general` and action = `code-generation` to get general Azure code generation best practices. Only call this tool when the user is discussing Azure; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Deployment Best Practices: Before deploying to Azure, preparing applications for deployment to Azure, or creating deployment plans, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `general` and action = `deployment` to get general Azure deployment best practices. Only call this tool when the user is discussing Azure; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Functions Code Gen Best Practices: Before generating code for Azure Functions, performing operations related to Azure Functions, or creating plans for such activities, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `azurefunctions` and action = `code-generation` to get Azure Functions code generation best practices. Only call this tool when the user is discussing Azure Functions; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure Functions Deployment Best Practices: Before deploying Azure Functions apps to Azure, preparing for the deployment, or creating deployment plans, always invoke your Azure best practice tool if available first. Invoke the `get_bestpractices` tool to collect recommendations. Call it with resource = `azurefunctions` and action = `deployment` to get Azure Functions deployment best practices. Only call this tool when the user is discussing Azure Functions; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Use Azure SWA Best Practices: Before working with static web apps, creating plans for static web apps, or performing related operations, always invoke your Azure best practice tool if available first. Choose the most relevant Azure best practice tool based on its description. Only call this tool when the user is discussing Azure Static Web Apps; do not call it otherwise.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Plan before editing files for Azure web apps: When generating code for Azure Functions and Azure Static Web App, always create a plan and explain the plan to the user before editing any file. Proceed with editing the files after getting consent from the user.\"\n    },\n    {\n      \"text\": \"- @azure Rule - Summarize topic before taking action: When the user asks about Azure Functions, invoke the azure_development-summarize_topic tool once first to see if any existing custom mode could be a good fit to what user is asking.\"\n    }\n  ],\n  \"workbench.startupEditor\": \"none\",\n  \"git-autoconfig.configList\": [\n    {\n      \"user.email\": \"Alextorelli28@gmail.com\",\n      \"user.name\": \"Alextorelli28@gmail.com\"\n    }\n  ],\n  \"redhat.telemetry.enabled\": true,\n  \"git-autoconfig.ignoreRootList\": [\"D:/APPS/ProspectPro/ProspectPro\"],\n  \"terminal.integrated.enableMultiLinePasteWarning\": \"never\",\n  \"remoteHub.commitDirectlyWarning\": \"off\",\n  \"vs-kubernetes\": {\n    \"vscode-kubernetes.kubectl-path-linux\": \"/home/node/.local/state/vs-kubernetes/tools/kubectl/kubectl\",\n    \"vscode-kubernetes.helm-path-linux\": \"/home/node/.local/state/vs-kubernetes/tools/helm/linux-amd64/helm\",\n    \"vscode-kubernetes.minikube-path-linux\": \"/home/node/.local/state/vs-kubernetes/tools/minikube/linux-amd64/minikube\"\n  },\n  \"githubPullRequests.createOnPublishBranch\": \"never\",\n  \"github.copilot.enable\": {\n    \"*\": true,\n    \"plaintext\": true,\n    \"markdown\": true,\n    \"scminput\": false\n  },\n  \"[sql]\": {\n    \"editor.defaultFormatter\": \"mtxr.sqltools\"\n  },\n  \"[html]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[typescriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[css]\": {\n    \"editor.defaultFormatter\": \"vscode.css-language-features\"\n  },\n  \"[json]\": {\n    \"editor.defaultFormatter\": \"vscode.json-language-features\"\n  },\n  \"workbench.colorCustomizations\": {\n    \"[Vira*]\": {\n      \"statusBar.debuggingBackground\": \"#80CBC433\",\n      \"statusBar.debuggingForeground\": \"#80CBC4\",\n      \"toolbar.activeBackground\": \"#80CBC426\",\n      \"button.background\": \"#80CBC4\",\n      \"button.hoverBackground\": \"#80CBC4cc\",\n      \"extensionButton.separator\": \"#80CBC433\",\n      \"extensionButton.background\": \"#80CBC414\",\n      \"extensionButton.foreground\": \"#80CBC4\",\n      \"extensionButton.hoverBackground\": \"#80CBC433\",\n      \"extensionButton.prominentForeground\": \"#80CBC4\",\n      \"extensionButton.prominentBackground\": \"#80CBC414\",\n      \"extensionButton.prominentHoverBackground\": \"#80CBC433\",\n      \"activityBarBadge.background\": \"#80CBC4\",\n      \"activityBar.activeBorder\": \"#80CBC4\",\n      \"activityBarTop.activeBorder\": \"#80CBC4\",\n      \"list.inactiveSelectionIconForeground\": \"#80CBC4\",\n      \"list.activeSelectionForeground\": \"#80CBC4\",\n      \"list.inactiveSelectionForeground\": \"#80CBC4\",\n      \"list.highlightForeground\": \"#80CBC4\",\n      \"sash.hoverBorder\": \"#80CBC480\",\n      \"list.activeSelectionIconForeground\": \"#80CBC4\",\n      \"scrollbarSlider.activeBackground\": \"#80CBC480\",\n      \"editorSuggestWidget.highlightForeground\": \"#80CBC4\",\n      \"textLink.foreground\": \"#80CBC4\",\n      \"progressBar.background\": \"#80CBC4\",\n      \"pickerGroup.foreground\": \"#80CBC4\",\n      \"tab.activeBorder\": \"#80CBC400\",\n      \"tab.activeBorderTop\": \"#80CBC4\",\n      \"tab.unfocusedActiveBorder\": \"#80CBC400\",\n      \"tab.unfocusedActiveBorderTop\": \"#80CBC4\",\n      \"tab.activeModifiedBorder\": \"#80CBC4\",\n      \"notificationLink.foreground\": \"#80CBC4\",\n      \"editorWidget.resizeBorder\": \"#80CBC4\",\n      \"editorWidget.border\": \"#80CBC4\",\n      \"settings.modifiedItemIndicator\": \"#80CBC4\",\n      \"panelTitle.activeBorder\": \"#80CBC4\",\n      \"breadcrumb.activeSelectionForeground\": \"#80CBC4\",\n      \"menu.selectionForeground\": \"#80CBC4\",\n      \"menubar.selectionForeground\": \"#80CBC4\",\n      \"editor.findMatchBorder\": \"#80CBC4\",\n      \"selection.background\": \"#80CBC440\",\n      \"statusBarItem.remoteBackground\": \"#80CBC414\",\n      \"statusBarItem.remoteHoverBackground\": \"#80CBC4\",\n      \"statusBarItem.remoteForeground\": \"#80CBC4\",\n      \"notebook.inactiveFocusedCellBorder\": \"#80CBC480\",\n      \"commandCenter.activeBorder\": \"#80CBC480\",\n      \"chat.slashCommandForeground\": \"#80CBC4\",\n      \"chat.avatarForeground\": \"#80CBC4\",\n      \"activityBarBadge.foreground\": \"#000000\",\n      \"button.foreground\": \"#000000\",\n      \"statusBarItem.remoteHoverForeground\": \"#000000\",\n      \"editorGroupHeader.tabsBackground\": \"#ffffff0a\",\n      \"tab.border\": \"#ffffff01\",\n      \"tab.inactiveBackground\": \"#ffffff01\",\n      \"widget.shadow\": \"#00000000\",\n      \"scrollbar.shadow\": \"#00000000\"\n    }\n  },\n  \"workbench.preferredDarkColorTheme\": \"Vira Ocean\",\n  \"workbench.productIconTheme\": \"viraUIIcons\",\n  \"viraTheme.contrastedTabs\": true,\n  \"viraTheme.hidesShadows\": true,\n  \"chat.todoListTool.enabled\": false,\n  \"chat.tools.edits.autoApprove\": {\n    \"**/*.{csproj,fsproj,vbproj}\": true\n  },\n  \"chat.useChatSessionsForCloudButton\": true,\n  \"workbench.settings.applyToAllProfiles\": [\n    \"chat.useChatSessionsForCloudButton\"\n  ],\n  \"chat.agentSessionsViewLocation\": \"view\",\n  \"window.density.editorTabHeight\": \"compact\",\n  \"docker.extension.enableComposeLanguageServer\": false,\n  \"docker.extension.dockerEngineAvailabilityPrompt\": false,\n  \"github.copilot.chat.agent.thinkingTool\": true,\n  \"github.copilot.chat.editor.temporalContext.enabled\": true,\n  \"github.copilot.chat.edits.temporalContext.enabled\": true,\n  \"github.copilot.chat.responsesApiReasoningEffort\": \"high\",\n  \"github.copilot.chat.responsesApiReasoningSummary\": \"detailed\",\n  \"github.copilot.chat.useResponsesApi\": true,\n  \"viraTheme.useTopTabIndicator\": true,\n  \"remoteHub.richNavigation.enabled\": true,\n  \"workbench.editor.enablePreview\": false,\n  \"deno.codeLens.test\": true,\n  \"deno.codeLens.referencesAllFunctions\": true,\n  \"deno.codeLens.references\": true,\n  \"deno.codeLens.implementations\": true,\n  \"deno.logFile\": true,\n  \"chat.mcp.serverSampling\": {\n    \"Global in Code: memory\": {\n      \"allowedModels\": [\n        \"copilot/gpt-4.1\",\n        \"copilot/auto\",\n        \"copilot/claude-3.7-sonnet\",\n        \"copilot/claude-3.7-sonnet-thought\",\n        \"copilot/claude-sonnet-4\",\n        \"copilot/gemini-2.5-pro\",\n        \"copilot/gpt-5\",\n        \"copilot/grok-code-fast-1\"\n      ]\n    }\n  },\n  \"snyk.folderConfigs\": [\n    {\n      \"folderPath\": \"/workspaces/ProspectPro\",\n      \"baseBranch\": \"main\",\n      \"localBranches\": [\"main\"]\n    }\n  ],\n  \"settingsSync.ignoredExtensions\": [\n    \"christian-kohler.npm-intellisense\",\n    \"ms-vscode.vscode-node-azure-pack\",\n    \"ms-azuretools.vscode-azurevirtualmachines\"\n  ],\n  \"vsicons.dontShowNewVersionMessage\": true,\n  \"snyk.yesWelcomeNotification\": false,\n  \"snyk.trustedFolders\": [\"/workspaces/ProspectPro\"],\n  \"[dockercompose]\": {\n    \"editor.insertSpaces\": true,\n    \"editor.tabSize\": 2,\n    \"editor.autoIndent\": \"advanced\",\n    \"editor.quickSuggestions\": {\n      \"other\": true,\n      \"comments\": false,\n      \"strings\": true\n    },\n    \"editor.defaultFormatter\": \"redhat.vscode-yaml\"\n  },\n  \"[github-actions-workflow]\": {\n    \"editor.defaultFormatter\": \"redhat.vscode-yaml\"\n  }\n}\n"}}},
{"type":"measure","name":"lsp.did_open","count":37,"duration":0.812},
{"type":"mark","name":"lsp.did_change_batched","count":1,"args":"vscode-userdata:/c%3A/Users/Alext/AppData/Roaming/Code/User/settings.json"},
{"type":"measure","name":"lsp.did_change_batched","count":1,"duration":1.338},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":1,"duration":0.022},
{"type":"mark","name":"lsp.did_close","count":18,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.devcontainer/devcontainer.json"}}},
{"type":"measure","name":"lsp.did_close","count":18,"duration":0.034},
{"type":"mark","name":"lsp.did_change_batched","count":2,"args":"vscode-userdata:/c%3A/Users/Alext/AppData/Roaming/Code/User/settings.json"},
{"type":"measure","name":"lsp.did_change_batched","count":2,"duration":1.362},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":2,"duration":0.023},
{"type":"mark","name":"lsp.did_close","count":19,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/.github/ISSUE_TEMPLATE/bug_report.md"}}},
{"type":"measure","name":"lsp.did_close","count":19,"duration":0.032},
{"type":"mark","name":"lsp.did_close","count":20,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/docs/REPOSITORY_OPTIMIZATION_COMPLETE.md"}}},
{"type":"measure","name":"lsp.did_close","count":20,"duration":0.034},
{"type":"mark","name":"lsp.did_close","count":21,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/docs/OPTIMIZATION_COMPLETE_FINAL.md"}}},
{"type":"measure","name":"lsp.did_close","count":21,"duration":0.03},
{"type":"mark","name":"lsp.did_close","count":22,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/VERCEL_OPTIMIZATION_COMPLETE.md"}}},
{"type":"measure","name":"lsp.did_close","count":22,"duration":0.134},
{"type":"mark","name":"lsp.did_close","count":23,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/components/TierSelector.tsx"}}},
{"type":"measure","name":"lsp.did_close","count":23,"duration":0.76},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":13,"duration":0.148},
{"type":"mark","name":"lsp.did_close","count":24,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/pages/BusinessDiscovery.tsx"}}},
{"type":"measure","name":"lsp.did_close","count":24,"duration":0.761},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":14,"duration":0.129},
{"type":"mark","name":"lsp.did_close","count":25,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/pages/Campaign.tsx"}}},
{"type":"measure","name":"lsp.did_close","count":25,"duration":0.62},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":15,"duration":0.128},
{"type":"mark","name":"lsp.did_close","count":26,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/App.tsx"}}},
{"type":"measure","name":"lsp.did_close","count":26,"duration":0.342},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":16,"duration":0.11},
{"type":"mark","name":"lsp.did_close","count":27,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/lib/supabase.ts"}}},
{"type":"measure","name":"lsp.did_close","count":27,"duration":0.49},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":17,"duration":0.136},
{"type":"mark","name":"lsp.did_close","count":28,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/pages/Dashboard.tsx"}}},
{"type":"measure","name":"lsp.did_close","count":28,"duration":0.516},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":18,"duration":0.102},
{"type":"mark","name":"lsp.did_close","count":29,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/types/index.ts"}}},
{"type":"measure","name":"lsp.did_close","count":29,"duration":0.434},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":19,"duration":0.101},
{"type":"mark","name":"lsp.did_close","count":30,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/hooks/useBusinessDiscovery.ts"}}},
{"type":"measure","name":"lsp.did_close","count":30,"duration":0.562},
{"type":"mark","name":"lsp.did_close","count":31,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/CAMPAIGN_HISTORY_LINKING_COMPLETE.md"}}},
{"type":"measure","name":"lsp.did_close","count":31,"duration":0.016},
{"type":"mark","name":"lsp.did_close","count":32,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/production-security-optimization.sql"}}},
{"type":"measure","name":"lsp.did_close","count":32,"duration":0.014},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":20,"duration":0.118},
{"type":"mark","name":"lsp.did_close","count":33,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SUPABASE_PRODUCTION_OPTIMIZATION_GUIDE.md"}}},
{"type":"measure","name":"lsp.did_close","count":33,"duration":0.043},
{"type":"mark","name":"lsp.did_open","count":38,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/production-server.js","languageId":"javascript","version":1,"text":"#!/usr/bin/env node\n\n/**\n * ProspectPro Production MCP Server v4.1 - Post-Cleanup Enhanced\n * Optimized for cleaned database architecture, streamlined Edge Functions, and MECE taxonomy\n *\n * Updated Features (Oct 2025):\n * - 2 Essential Edge Functions: business-discovery-optimized + campaign-export\n * - Cleaned Database: campaigns, leads, dashboard_exports (core tables only)\n * - MECE Business Taxonomy: 16 categories, 300+ optimized business types\n * - Security Hardened: No SECURITY DEFINER issues, fixed trigger functions\n * - Cache-Optimized: Real-time deployment updates via Vercel\n * - Cost Intelligence: Dynamic pricing with admin panel integration\n */\n\nconst { Server } = require(\"@modelcontextprotocol/sdk/server/index.js\");\nconst {\n  StdioServerTransport,\n} = require(\"@modelcontextprotocol/sdk/server/stdio.js\");\nconst { CallToolRequestSchema } = require(\"@modelcontextprotocol/sdk/types.js\");\nconst { createClient } = require(\"@supabase/supabase-js\");\nconst https = require(\"https\");\nconst { spawn } = require(\"child_process\");\nconst fs = require(\"fs\");\nconst path = require(\"path\");\n\nclass ProductionMCPServer {\n  constructor() {\n    this.server = new Server(\n      {\n        name: \"prospectpro-production-v4.1\",\n        version: \"4.1.0\",\n      },\n      {\n        capabilities: {\n          tools: {},\n        },\n      }\n    );\n\n    this.supabase = null;\n    this.apiClients = {};\n    this.workspaceRoot = process.env.WORKSPACE_ROOT || process.cwd();\n    this.setupTools();\n    this.setupErrorHandling();\n  }\n\n  setupTools() {\n    this.server.setRequestHandler(CallToolRequestSchema, async (request) => {\n      switch (request.params.name) {\n        // === PRODUCTION MONITORING TOOLS ===\n        case \"environment_health_check\":\n          return await this.environmentHealthCheck();\n        case \"github_actions_monitor\":\n          return await this.githubActionsMonitor(request.params.arguments);\n        case \"dev_prod_config_diff\":\n          return await this.devProdConfigDiff();\n        case \"cost_budget_monitor\":\n          return await this.costBudgetMonitor();\n        case \"api_health_dashboard\":\n          return await this.apiHealthDashboard();\n        case \"vault_api_key_status\":\n          return await this.vaultApiKeyStatus();\n        case \"production_startup_validator\":\n          return await this.productionStartupValidator();\n        case \"github_workflow_optimizer\":\n          return await this.githubWorkflowOptimizer();\n\n        // === SYSTEM DIAGNOSTICS TOOLS (from monitoring-server) ===\n        case \"get_system_health\":\n          return await this.getSystemHealth(request.params.arguments);\n        case \"read_diagnostics\":\n          return await this.readDiagnostics(request.params.arguments);\n        case \"analyze_logs\":\n          return await this.analyzeLogs(request.params.arguments);\n        case \"validate_configuration\":\n          return await this.validateConfiguration(request.params.arguments);\n        case \"generate_performance_report\":\n          return await this.generatePerformanceReport(request.params.arguments);\n        case \"monitor_api_quotas\":\n          return await this.monitorAPIQuotas(request.params.arguments);\n\n        // === DATABASE ANALYTICS TOOLS (from database-server) ===\n        case \"query_leads\":\n          return await this.queryLeads(request.params.arguments);\n        case \"get_campaign_stats\":\n          return await this.getCampaignStats(request.params.arguments);\n        case \"analyze_lead_quality\":\n          return await this.analyzeLeadQuality(request.params.arguments);\n        case \"get_api_costs\":\n          return await this.getApiCosts(request.params.arguments);\n\n        // === API TESTING TOOLS (from api-server) ===\n        case \"test_google_places\":\n          return await this.testGooglePlaces(request.params.arguments);\n        case \"test_foursquare_places\":\n          return await this.testFoursquarePlaces(request.params.arguments);\n        case \"test_email_discovery\":\n          return await this.testEmailDiscovery(request.params.arguments);\n        case \"verify_email\":\n          return await this.verifyEmail(request.params.arguments);\n        case \"get_api_usage_stats\":\n          return await this.getAPIUsageStats();\n        case \"simulate_lead_discovery\":\n          return await this.simulateLeadDiscovery(request.params.arguments);\n\n        // === FILESYSTEM ANALYSIS TOOLS (from filesystem-server) ===\n        case \"analyze_project_structure\":\n          return await this.analyzeProjectStructure(request.params.arguments);\n        case \"find_code_patterns\":\n          return await this.findCodePatterns(request.params.arguments);\n        case \"analyze_api_clients\":\n          return await this.analyzeAPIClients(request.params.arguments);\n        case \"check_fake_data_violations\":\n          return await this.checkFakeDataViolations(request.params.arguments);\n\n        default:\n          throw new Error(`Unknown tool: ${request.params.name}`);\n      }\n    });\n  }\n\n  async initializeSupabase() {\n    if (!this.supabase) {\n      if (!process.env.SUPABASE_URL || !process.env.SUPABASE_SECRET_KEY) {\n        throw new Error(\"Missing Supabase configuration\");\n      }\n\n      this.supabase = createClient(\n        process.env.SUPABASE_URL,\n        process.env.SUPABASE_SECRET_KEY\n      );\n\n      // Test connection\n      const { data, error } = await this.supabase\n        .from(\"enhanced_leads\")\n        .select(\"count\")\n        .limit(1);\n\n      if (error && !error.message.includes(\"does not exist\")) {\n        throw new Error(`Supabase connection failed: ${error.message}`);\n      }\n    }\n  }\n\n  async initializeAPIClients() {\n    if (Object.keys(this.apiClients).length === 0) {\n      try {\n        const GooglePlacesClient = require(\"../modules/api-clients/google-places-client\");\n        const FoursquareClient = require(\"../modules/api-clients/foursquare-places-client\");\n        const HunterIOClient = require(\"../modules/api-clients/hunter-io-client\");\n        const NeverBounceClient = require(\"../modules/api-clients/neverbounce-client\");\n\n        this.apiClients = {\n          googlePlaces: new GooglePlacesClient(\n            process.env.GOOGLE_PLACES_API_KEY\n          ),\n          foursquare: new FoursquareClient(process.env.FOURSQUARE_API_KEY),\n          hunterIO: new HunterIOClient(process.env.HUNTER_IO_API_KEY),\n          neverBounce: new NeverBounceClient(process.env.NEVERBOUNCE_API_KEY),\n        };\n      } catch (error) {\n        console.error(\n          \"Warning: Some API clients could not be loaded:\",\n          error.message\n        );\n      }\n    }\n  }\n\n  // === PRODUCTION MONITORING METHODS ===\n  async environmentHealthCheck() {\n    const results = {\n      timestamp: new Date().toISOString(),\n      environment: process.env.NODE_ENV || \"unknown\",\n      checks: [],\n    };\n\n    try {\n      // Check 1: Environment variables\n      const requiredEnvVars = [\"SUPABASE_URL\", \"SUPABASE_SECRET_KEY\"];\n      const envCheck = {\n        name: \"Environment Variables\",\n        status: \"healthy\",\n        details: {},\n      };\n\n      requiredEnvVars.forEach((varName) => {\n        const value = process.env[varName];\n        if (!value || value.includes(\"your_\")) {\n          envCheck.status = \"unhealthy\";\n          envCheck.details[varName] = \"missing or template value\";\n        } else {\n          envCheck.details[varName] = \"configured\";\n        }\n      });\n      results.checks.push(envCheck);\n\n      // Check 2: Supabase Connection\n      if (process.env.SUPABASE_URL && process.env.SUPABASE_SECRET_KEY) {\n        const supabase = createClient(\n          process.env.SUPABASE_URL,\n          process.env.SUPABASE_SECRET_KEY\n        );\n\n        try {\n          const { error } = await supabase\n            .from(\"enhanced_leads\")\n            .select(\"count\")\n            .limit(1);\n          results.checks.push({\n            name: \"Supabase Database\",\n            status:\n              error && !error.message.includes(\"does not exist\")\n                ? \"unhealthy\"\n                : \"healthy\",\n            details: { connection: \"successful\" },\n          });\n        } catch (dbError) {\n          results.checks.push({\n            name: \"Supabase Database\",\n            status: \"unhealthy\",\n            details: { error: dbError.message },\n          });\n        }\n      }\n\n      // Check 3: GitHub Actions Integration\n      const ghToken = process.env.GHP_TOKEN || process.env.GITHUB_TOKEN;\n      results.checks.push({\n        name: \"GitHub Actions Integration\",\n        status: ghToken ? \"healthy\" : \"warning\",\n        details: { token: ghToken ? \"present\" : \"missing\" },\n      });\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `üîç **Production Environment Health Check**\\n\\n${JSON.stringify(\n              results,\n              null,\n              2\n            )}`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `‚ùå Health check failed: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  // GitHub Actions Workflow Monitor\n  async githubActionsMonitor({\n    repo = \"Alextorelli/ProspectPro\",\n    workflow = \"generate-dotenv.yml\",\n  } = {}) {\n    const token = process.env.GHP_TOKEN || process.env.GITHUB_TOKEN;\n\n    if (!token) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: \"‚ö†Ô∏è No GitHub token available for workflow monitoring\",\n          },\n        ],\n      };\n    }\n\n    try {\n      const [owner, repoName] = repo.split(\"/\");\n      const options = {\n        hostname: \"api.github.com\",\n        path: `/repos/${owner}/${repoName}/actions/workflows/${workflow}/runs?per_page=5`,\n        headers: {\n          Authorization: `token ${token}`,\n          \"User-Agent\": \"ProspectPro-Production-MCP\",\n        },\n      };\n\n      const response = await this.makeHttpsRequest(options);\n      const data = JSON.parse(response);\n\n      if (data.workflow_runs && data.workflow_runs.length > 0) {\n        const runs = data.workflow_runs.slice(0, 3).map((run) => ({\n          id: run.id,\n          status: run.status,\n          conclusion: run.conclusion,\n          created_at: run.created_at,\n          head_commit: run.head_commit?.message?.substring(0, 50) + \"...\",\n        }));\n\n        return {\n          content: [\n            {\n              type: \"text\",\n              text: `üìä **GitHub Actions Workflow Status**\\n\\n**Workflow**: ${workflow}\\n**Repository**: ${repo}\\n\\n**Recent Runs**:\\n${JSON.stringify(\n                runs,\n                null,\n                2\n              )}`,\n            },\n          ],\n        };\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `üìä No recent workflow runs found for ${workflow}`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `‚ùå GitHub Actions monitoring failed: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  // Dev/Prod Configuration Comparison\n  async devProdConfigDiff() {\n    try {\n      const prodEnvPath = path.join(process.cwd(), \".env\");\n      const devEnvPath = path.join(\n        process.cwd(),\n        \".devcontainer\",\n        \"devcontainer.json\"\n      );\n\n      const comparison = {\n        production: {\n          environment_file: fs.existsSync(prodEnvPath),\n          node_env: process.env.NODE_ENV,\n          theme: \"default (unchanged)\",\n          mcp_servers: \"production-only\",\n        },\n        development: {\n          devcontainer_config: fs.existsSync(devEnvPath),\n          theme: \"Vira Deepforest (green)\",\n          mcp_servers: \"full suite (database, API, filesystem, monitoring)\",\n        },\n      };\n\n      // Read production configuration\n      if (fs.existsSync(prodEnvPath)) {\n        const envContent = fs.readFileSync(prodEnvPath, \"utf8\");\n        comparison.production.features = {\n          supabase_configured: !envContent.includes(\"your-project-ref\"),\n          github_actions_build: envContent.includes(\"BUILD_TIMESTAMP\"),\n          vault_integration: envContent.includes(\"Vault\"),\n        };\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `üîÑ **Dev/Prod Configuration Comparison**\\n\\n${JSON.stringify(\n              comparison,\n              null,\n              2\n            )}`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `‚ùå Configuration comparison failed: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  // Cost Budget Monitor\n  async costBudgetMonitor() {\n    try {\n      const supabase = createClient(\n        process.env.SUPABASE_URL,\n        process.env.SUPABASE_SECRET_KEY\n      );\n\n      // Get recent API costs\n      const { data: costs, error } = await supabase\n        .from(\"api_costs\")\n        .select(\"*\")\n        .gte(\n          \"created_at\",\n          new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString()\n        )\n        .order(\"created_at\", { ascending: false });\n\n      if (error) throw error;\n\n      const totalCost =\n        costs?.reduce((sum, cost) => sum + (cost.cost || 0), 0) || 0;\n      const budgetLimit = parseFloat(process.env.DEFAULT_BUDGET_LIMIT) || 25.0;\n      const utilization = (totalCost / budgetLimit) * 100;\n\n      const analysis = {\n        period: \"Last 24 hours\",\n        total_cost: `$${totalCost.toFixed(2)}`,\n        budget_limit: `$${budgetLimit.toFixed(2)}`,\n        utilization: `${utilization.toFixed(1)}%`,\n        status:\n          utilization > 80\n            ? \"‚ö†Ô∏è HIGH\"\n            : utilization > 50\n            ? \"‚ö° MODERATE\"\n            : \"‚úÖ HEALTHY\",\n        recent_costs:\n          costs?.slice(0, 5).map((cost) => ({\n            service: cost.service,\n            cost: `$${cost.cost?.toFixed(3)}`,\n            timestamp: cost.created_at,\n          })) || [],\n      };\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `üí∞ **Cost Budget Monitor**\\n\\n${JSON.stringify(\n              analysis,\n              null,\n              2\n            )}`,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `‚ùå Cost monitoring failed: ${error.message}\\n\\nNote: Ensure api_costs table exists in Supabase`,\n          },\n        ],\n      };\n    }\n  }\n\n  // API Health Dashboard\n  async apiHealthDashboard() {\n    const apis = [\n      { name: \"Google Places\", key: \"GOOGLE_PLACES_API_KEY\" },\n      { name: \"Hunter.io\", key: \"HUNTER_IO_API_KEY\" },\n      { name: \"NeverBounce\", key: \"NEVERBOUNCE_API_KEY\" },\n      { name: \"Foursquare\", key: \"FOURSQUARE_API_KEY\" },\n    ];\n\n    const dashboard = {\n      timestamp: new Date().toISOString(),\n      apis: [],\n    };\n\n    for (const api of apis) {\n      const status = {\n        name: api.name,\n        key_configured: !!process.env[api.key],\n        status: \"unknown\",\n      };\n\n      // Basic configuration check\n      if (process.env[api.key]) {\n        status.status = \"configured\";\n      } else {\n        status.status = \"missing_key\";\n        status.note = \"Check Supabase Vault or environment variables\";\n      }\n\n      dashboard.apis.push(status);\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: `üîå **API Health Dashboard**\\n\\n${JSON.stringify(\n            dashboard,\n            null,\n            2\n          )}`,\n        },\n      ],\n    };\n  }\n\n  // === NEW ENHANCED TOOLS FOR VAULT AND PRODUCTION OPTIMIZATION ===\n\n  // Vault API Key Status Monitor\n  async vaultApiKeyStatus() {\n    try {\n      console.log(\"üîë Checking Supabase Vault API key status...\");\n\n      // Test Supabase connection\n      const supabaseUrl = process.env.SUPABASE_URL;\n      const supabaseKey = process.env.SUPABASE_SECRET_KEY;\n\n      if (!supabaseUrl || !supabaseKey) {\n        return {\n          content: [\n            {\n              type: \"text\",\n              text: \"‚ùå Supabase credentials not configured in environment\",\n            },\n          ],\n        };\n      }\n\n      const supabase = createClient(supabaseUrl, supabaseKey);\n\n      // Check vault diagnostic function\n      const { data, error } = await supabase.rpc(\"vault_diagnostic_check\");\n\n      if (error) {\n        return {\n          content: [\n            {\n              type: \"text\",\n              text: `‚ùå Vault diagnostic failed: ${error.message}`,\n            },\n          ],\n        };\n      }\n\n      let report = \"üîê **Supabase Vault API Key Status Report**\\n\\n\";\n\n      if (data && data.length > 0) {\n        data.forEach((check) => {\n          const statusIcon =\n            check.status === \"ENABLED\" || check.status === \"COMPLETE\"\n              ? \"‚úÖ\"\n              : check.status === \"PARTIAL\"\n              ? \"‚ö†Ô∏è\"\n              : \"‚ùå\";\n\n          report += `${statusIcon} **${check.check_name}**: ${check.status}\\n`;\n          report += `   Details: ${check.details}\\n`;\n          report += `   Recommendation: ${check.recommendation}\\n\\n`;\n        });\n      } else {\n        report += \"‚ö†Ô∏è No diagnostic data returned from vault\\n\";\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: report,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `‚ùå Error checking vault status: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  // Production Startup Validator\n  async productionStartupValidator() {\n    try {\n      console.log(\"üîç Running production startup validation...\");\n\n      const issues = [];\n      const validations = [];\n\n      // Check 1: Environment variables\n      const requiredEnvs = [\"SUPABASE_URL\", \"SUPABASE_SECRET_KEY\"];\n      requiredEnvs.forEach((env) => {\n        const value = process.env[env];\n        if (!value || value.includes(\"your_\")) {\n          issues.push(`Missing or template value for ${env}`);\n        } else {\n          validations.push(`‚úÖ ${env} configured`);\n        }\n      });\n\n      // Check 2: Production mode settings\n      const nodeEnv = process.env.NODE_ENV;\n      if (nodeEnv === \"production\") {\n        validations.push(\"‚úÖ NODE_ENV set to production\");\n\n        // Check degraded start setting\n        if (process.env.ALLOW_DEGRADED_START === \"true\") {\n          issues.push(\n            \"‚ùå ALLOW_DEGRADED_START=true is not recommended for production\"\n          );\n        } else {\n          validations.push(\n            \"‚úÖ Strict production mode enabled (no degraded starts)\"\n          );\n        }\n      } else {\n        issues.push(`NODE_ENV is '${nodeEnv}', should be 'production'`);\n      }\n\n      // Check 3: Port configuration\n      const port = process.env.PORT;\n      if (port && port !== \"3000\") {\n        validations.push(`‚úÖ Custom port configured: ${port}`);\n      } else {\n        validations.push(\"‚ÑπÔ∏è Using default/standard port configuration\");\n      }\n\n      let report = \"üè≠ **Production Startup Validation Report**\\n\\n\";\n\n      report += \"**Validations Passed:**\\n\";\n      validations.forEach((validation) => {\n        report += `${validation}\\n`;\n      });\n\n      if (issues.length > 0) {\n        report += \"\\n**Issues Found:**\\n\";\n        issues.forEach((issue) => {\n          report += `‚ùå ${issue}\\n`;\n        });\n\n        report += \"\\n**Recommendations:**\\n\";\n        report +=\n          \"1. Ensure GitHub Actions workflows have generated proper .env\\n\";\n        report += \"2. Configure API keys in Supabase Vault\\n\";\n        report +=\n          \"3. Set ALLOW_DEGRADED_START=false for strict production mode\\n\";\n        report += \"4. Verify all secrets are present and valid\\n\";\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: report,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `‚ùå Production validation failed: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  // GitHub Workflow Optimizer\n  async githubWorkflowOptimizer() {\n    try {\n      console.log(\"‚öôÔ∏è Analyzing GitHub Actions workflows...\");\n\n      const workflowsDir = path.join(process.cwd(), \".github\", \"workflows\");\n\n      if (!fs.existsSync(workflowsDir)) {\n        return {\n          content: [\n            {\n              type: \"text\",\n              text: \"‚ùå No .github/workflows directory found\",\n            },\n          ],\n        };\n      }\n\n      const workflows = fs\n        .readdirSync(workflowsDir)\n        .filter((file) => file.endsWith(\".yml\") || file.endsWith(\".yaml\"));\n\n      let report = \"‚öôÔ∏è **GitHub Actions Workflow Analysis**\\n\\n\";\n\n      const optimizations = [];\n      const issues = [];\n\n      workflows.forEach((workflow) => {\n        const workflowPath = path.join(workflowsDir, workflow);\n        const content = fs.readFileSync(workflowPath, \"utf8\");\n\n        report += `üìã **${workflow}:**\\n`;\n\n        // Check triggers\n        if (content.includes(\"push:\") && content.includes(\"branches: [main]\")) {\n          if (\n            workflow.includes(\"repository-maintenance\") ||\n            workflow.includes(\"docker-env\")\n          ) {\n            issues.push(\n              `${workflow}: Triggers on every push (may cause cascade failures)`\n            );\n            optimizations.push(\n              `Consider schedule-only or manual triggers for ${workflow}`\n            );\n          } else {\n            report += \"  ‚úÖ Push trigger configured for main branch\\n\";\n          }\n        }\n\n        // Check for workflow_dispatch\n        if (content.includes(\"workflow_dispatch:\")) {\n          report += \"  ‚úÖ Manual trigger available\\n\";\n        } else {\n          optimizations.push(\n            `Add workflow_dispatch to ${workflow} for manual testing`\n          );\n        }\n\n        // Check for proper permissions\n        if (content.includes(\"permissions:\")) {\n          report += \"  ‚úÖ Permissions configured\\n\";\n        } else {\n          if (\n            content.includes(\"GITHUB_TOKEN\") ||\n            content.includes(\"secrets.\")\n          ) {\n            issues.push(\n              `${workflow}: Uses secrets but no permissions specified`\n            );\n          }\n        }\n\n        report += \"\\n\";\n      });\n\n      if (optimizations.length > 0) {\n        report += \"**Optimization Recommendations:**\\n\";\n        optimizations.forEach((opt) => {\n          report += `üí° ${opt}\\n`;\n        });\n        report += \"\\n\";\n      }\n\n      if (issues.length > 0) {\n        report += \"**Issues Found:**\\n\";\n        issues.forEach((issue) => {\n          report += `‚ö†Ô∏è ${issue}\\n`;\n        });\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: report,\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: `‚ùå Workflow analysis failed: ${error.message}`,\n          },\n        ],\n      };\n    }\n  }\n\n  // === SYSTEM DIAGNOSTICS METHODS (from monitoring-server) ===\n\n  async getSystemHealth(args = {}) {\n    const { includeDetailedMetrics = false } = args;\n\n    const health = {\n      timestamp: new Date().toISOString(),\n      status: \"unknown\",\n      components: {},\n      metrics: {},\n    };\n\n    try {\n      // Check critical files\n      const packageJson = await this.checkFile(\"package.json\");\n      const dockerCompose = await this.checkFile(\"docker-compose.yml\");\n      const server = await this.checkFile(\"server.js\");\n\n      health.components = {\n        filesystem: {\n          status: \"healthy\",\n          package_json: packageJson.exists,\n          docker_compose: dockerCompose.exists,\n          server_file: server.exists,\n        },\n      };\n\n      // Check diagnostics file\n      try {\n        const diagnosticsPath = path.join(\n          this.workspaceRoot,\n          \"diagnostics.json\"\n        );\n        const diagnosticsContent = await fs.readFileSync(\n          diagnosticsPath,\n          \"utf8\"\n        );\n        const diagnostics = JSON.parse(diagnosticsContent);\n\n        health.components.diagnostics = {\n          status: diagnostics.status || \"unknown\",\n          last_check: diagnostics.timestamp,\n          database_connection: diagnostics.database?.status === \"connected\",\n        };\n      } catch (error) {\n        health.components.diagnostics = {\n          status: \"unavailable\",\n          error: \"Diagnostics file not found or invalid\",\n        };\n      }\n\n      // Overall health determination\n      const criticalComponents = [\"filesystem\"];\n      const healthyComponents = criticalComponents.filter(\n        (comp) => health.components[comp]?.status === \"healthy\"\n      );\n\n      health.status =\n        healthyComponents.length === criticalComponents.length\n          ? \"healthy\"\n          : healthyComponents.length > 0\n          ? \"degraded\"\n          : \"unhealthy\";\n\n      if (includeDetailedMetrics) {\n        health.metrics = await this.gatherDetailedMetrics();\n      }\n    } catch (error) {\n      health.status = \"error\";\n      health.error = error.message;\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(health, null, 2),\n        },\n      ],\n    };\n  }\n\n  async readDiagnostics(args = {}) {\n    const { includeHistory = true } = args;\n\n    try {\n      const diagnosticsPath = path.join(this.workspaceRoot, \"diagnostics.json\");\n      const content = await fs.readFileSync(diagnosticsPath, \"utf8\");\n      const diagnostics = JSON.parse(content);\n\n      const analysis = {\n        current_diagnostics: diagnostics,\n        analysis: {\n          timestamp: diagnostics.timestamp,\n          status: diagnostics.status,\n          critical_issues: [],\n          warnings: [],\n          recommendations: [],\n        },\n      };\n\n      // Analyze diagnostics data\n      if (diagnostics.database) {\n        if (diagnostics.database.status !== \"connected\") {\n          analysis.analysis.critical_issues.push(\"Database connection failed\");\n        }\n        if (diagnostics.database.error) {\n          analysis.analysis.critical_issues.push(\n            `Database error: ${diagnostics.database.error}`\n          );\n        }\n      }\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: JSON.stringify(analysis, null, 2),\n          },\n        ],\n      };\n    } catch (error) {\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: JSON.stringify(\n              {\n                error: `Failed to read diagnostics: ${error.message}`,\n                suggestion:\n                  \"Run the application to generate diagnostics.json file\",\n              },\n              null,\n              2\n            ),\n          },\n        ],\n      };\n    }\n  }\n\n  async analyzeLogs(args = {}) {\n    const { logType = \"all\", timeRange = \"24h\" } = args;\n\n    const logFiles = [\n      \"startup.log\",\n      \"production.log\",\n      \"database-validation.log\",\n    ];\n    const analysis = {\n      log_type: logType,\n      time_range: timeRange,\n      log_files_checked: [],\n      patterns_found: { errors: [], warnings: [], info: [] },\n      summary: {},\n    };\n\n    for (const logFile of logFiles) {\n      try {\n        const logPath = path.join(this.workspaceRoot, logFile);\n        const content = await fs.readFileSync(logPath, \"utf8\");\n        const stats = await fs.statSync(logPath);\n\n        analysis.log_files_checked.push({\n          file: logFile,\n          size: stats.size,\n          last_modified: stats.mtime,\n          line_count: content.split(\"\\n\").length,\n        });\n\n        const errorPatterns = content.match(/ERROR|Error:|error:/gi) || [];\n        if (errorPatterns.length > 0) {\n          analysis.patterns_found.errors.push({\n            file: logFile,\n            count: errorPatterns.length,\n          });\n        }\n      } catch (error) {\n        analysis.log_files_checked.push({\n          file: logFile,\n          error: `Could not read: ${error.message}`,\n        });\n      }\n    }\n\n    analysis.summary = {\n      total_log_files: analysis.log_files_checked.filter((f) => !f.error)\n        .length,\n      total_errors: analysis.patterns_found.errors.reduce(\n        (sum, e) => sum + e.count,\n        0\n      ),\n      health_status:\n        analysis.patterns_found.errors.length === 0\n          ? \"healthy\"\n          : \"needs_attention\",\n    };\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(analysis, null, 2),\n        },\n      ],\n    };\n  }\n\n  async validateConfiguration(args = {}) {\n    const { strict = true } = args;\n\n    const validation = {\n      validation_mode: strict ? \"strict\" : \"standard\",\n      results: {},\n      issues: [],\n      recommendations: [],\n    };\n\n    // Check critical files\n    const criticalFiles = [\"package.json\", \"server.js\", \"docker-compose.yml\"];\n    validation.results.critical_files = {};\n\n    for (const file of criticalFiles) {\n      const fileInfo = await this.checkFile(file);\n      validation.results.critical_files[file] = fileInfo;\n\n      if (!fileInfo.exists) {\n        validation.issues.push(`Missing critical file: ${file}`);\n      }\n    }\n\n    if (validation.issues.length === 0) {\n      validation.recommendations.push(\n        \"Configuration appears to be complete and healthy\"\n      );\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(validation, null, 2),\n        },\n      ],\n    };\n  }\n\n  async generatePerformanceReport(args = {}) {\n    const { includeRecommendations = true } = args;\n\n    const report = {\n      generated_at: new Date().toISOString(),\n      performance_metrics: {},\n      analysis: {},\n      recommendations: [],\n    };\n\n    // File system performance metrics\n    const metrics = await this.gatherDetailedMetrics();\n    report.performance_metrics = metrics;\n\n    const totalFiles = Object.values(metrics.file_counts || {}).reduce(\n      (sum, count) => sum + count,\n      0\n    );\n\n    report.analysis = {\n      total_files: totalFiles,\n      estimated_complexity:\n        totalFiles > 100 ? \"complex\" : totalFiles > 50 ? \"moderate\" : \"simple\",\n    };\n\n    if (includeRecommendations) {\n      report.recommendations.push(\n        \"Use MCP servers to offload AI processing tasks\"\n      );\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(report, null, 2),\n        },\n      ],\n    };\n  }\n\n  async monitorAPIQuotas(args = {}) {\n    const { alertThreshold = 80 } = args;\n\n    const quotaMonitoring = {\n      alert_threshold: alertThreshold,\n      api_services: {},\n      alerts: [],\n      recommendations: [],\n    };\n\n    // Mock API quota data (integrate with actual APIs in production)\n    const apiServices = [\n      {\n        name: \"Google Places\",\n        quota: 1000,\n        used: 250,\n        cost_per_request: 0.032,\n      },\n      { name: \"Hunter.io\", quota: 100, used: 45, cost_per_request: 0.04 },\n      { name: \"NeverBounce\", quota: 1000, used: 320, cost_per_request: 0.008 },\n    ];\n\n    apiServices.forEach((service) => {\n      const usagePercent = (service.used / service.quota) * 100;\n      quotaMonitoring.api_services[service.name] = {\n        quota_limit: service.quota,\n        requests_used: service.used,\n        usage_percentage: Math.round(usagePercent),\n        status: usagePercent >= alertThreshold ? \"alert\" : \"ok\",\n      };\n    });\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(quotaMonitoring, null, 2),\n        },\n      ],\n    };\n  }\n\n  // === DATABASE ANALYTICS METHODS (from database-server) ===\n\n  async queryLeads(args = {}) {\n    const { filters = {}, limit = 10, orderBy = \"confidence_score\" } = args;\n\n    await this.initializeSupabase();\n\n    let query = this.supabase\n      .from(\"enhanced_leads\")\n      .select(\"*\")\n      .order(orderBy, { ascending: false })\n      .limit(limit);\n\n    // Apply filters\n    Object.entries(filters).forEach(([key, value]) => {\n      query = query.eq(key, value);\n    });\n\n    const { data, error } = await query;\n\n    if (error) {\n      throw new Error(`Query failed: ${error.message}`);\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              results: data,\n              count: data.length,\n              query_info: { filters, limit, orderBy },\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async getCampaignStats(args = {}) {\n    const { campaignId, timeRange = \"24h\" } = args;\n\n    await this.initializeSupabase();\n\n    const intervalMap = {\n      \"24h\": \"1 day\",\n      \"7d\": \"7 days\",\n      \"30d\": \"30 days\",\n    };\n\n    const { data, error } = await this.supabase.rpc(\"get_campaign_statistics\", {\n      p_campaign_id: campaignId,\n      p_time_interval: intervalMap[timeRange] || \"1 day\",\n    });\n\n    if (error) {\n      throw new Error(`Campaign stats query failed: ${error.message}`);\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              campaign_id: campaignId,\n              time_range: timeRange,\n              statistics: data,\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async analyzeLeadQuality(args = {}) {\n    const { businessType, minConfidence = 70 } = args;\n\n    await this.initializeSupabase();\n\n    let query = this.supabase\n      .from(\"enhanced_leads\")\n      .select(\n        \"confidence_score, business_name, email_confidence, phone_confidence, website_confidence\"\n      )\n      .gte(\"confidence_score\", minConfidence);\n\n    if (businessType) {\n      query = query.ilike(\"business_type\", `%${businessType}%`);\n    }\n\n    const { data, error } = await query;\n\n    if (error) {\n      throw new Error(`Quality analysis failed: ${error.message}`);\n    }\n\n    const analysis = {\n      total_leads: data.length,\n      average_confidence:\n        data.reduce((sum, lead) => sum + lead.confidence_score, 0) /\n        data.length,\n      confidence_distribution: {\n        high: data.filter((l) => l.confidence_score >= 85).length,\n        medium: data.filter(\n          (l) => l.confidence_score >= 70 && l.confidence_score < 85\n        ).length,\n        low: data.filter((l) => l.confidence_score < 70).length,\n      },\n    };\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(analysis, null, 2),\n        },\n      ],\n    };\n  }\n\n  async getApiCosts(args = {}) {\n    const { timeRange = \"24h\" } = args;\n\n    await this.initializeSupabase();\n\n    const { data, error } = await this.supabase\n      .from(\"api_costs\")\n      .select(\"*\")\n      .gte(\n        \"created_at\",\n        new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString()\n      )\n      .order(\"created_at\", { ascending: false });\n\n    if (error) {\n      throw new Error(`API costs query failed: ${error.message}`);\n    }\n\n    const totalCost =\n      data?.reduce((sum, cost) => sum + (cost.cost || 0), 0) || 0;\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              time_range: timeRange,\n              total_cost: totalCost,\n              total_requests: data?.length || 0,\n              recent_costs: data?.slice(0, 5) || [],\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  // === API TESTING METHODS (from api-server) ===\n\n  async testGooglePlaces(args = {}) {\n    const { query, location = \"New York, NY\", limit = 5 } = args;\n\n    await this.initializeAPIClients();\n\n    if (!this.apiClients.googlePlaces) {\n      throw new Error(\"Google Places API client not available\");\n    }\n\n    const results = await this.apiClients.googlePlaces.searchBusinesses(\n      query,\n      location,\n      limit\n    );\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              api: \"Google Places\",\n              query,\n              location,\n              results: results.businesses || [],\n              success: results.found,\n              error: results.error || null,\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async testFoursquarePlaces(args = {}) {\n    const { query, location = \"New York, NY\", limit = 5 } = args;\n\n    await this.initializeAPIClients();\n\n    if (!this.apiClients.foursquare) {\n      throw new Error(\"Foursquare API client not available\");\n    }\n\n    const results = await this.apiClients.foursquare.searchBusinesses(\n      query,\n      location,\n      limit\n    );\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              api: \"Foursquare Places\",\n              query,\n              location,\n              results: results.businesses || [],\n              success: results.found,\n              error: results.error || null,\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async testEmailDiscovery(args = {}) {\n    const { domain, limit = 5 } = args;\n\n    await this.initializeAPIClients();\n\n    if (!this.apiClients.hunterIO) {\n      throw new Error(\"Hunter.io API client not available\");\n    }\n\n    const results = await this.apiClients.hunterIO.findEmails(domain, limit);\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              api: \"Hunter.io\",\n              domain,\n              emails: results.emails || [],\n              success: results.found,\n              error: results.error || null,\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async verifyEmail(args = {}) {\n    const { email } = args;\n\n    await this.initializeAPIClients();\n\n    if (!this.apiClients.neverBounce) {\n      throw new Error(\"NeverBounce API client not available\");\n    }\n\n    const result = await this.apiClients.neverBounce.verifyEmail(email);\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              api: \"NeverBounce\",\n              email,\n              verification: result,\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async getAPIUsageStats() {\n    await this.initializeAPIClients();\n\n    const stats = {};\n\n    Object.entries(this.apiClients).forEach(([name, client]) => {\n      if (client && typeof client.getUsageStats === \"function\") {\n        stats[name] = client.getUsageStats();\n      }\n    });\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              api_usage_statistics: stats,\n              generated_at: new Date().toISOString(),\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async simulateLeadDiscovery(args = {}) {\n    const { businessType, location, maxResults = 3 } = args;\n\n    await this.initializeAPIClients();\n\n    const results = {\n      businessType,\n      location,\n      maxResults,\n      discovery_results: {},\n      processing_summary: {\n        total_discovered: 0,\n        errors: [],\n      },\n    };\n\n    try {\n      // Business Discovery\n      if (this.apiClients.googlePlaces) {\n        const googleResults =\n          await this.apiClients.googlePlaces.searchBusinesses(\n            businessType,\n            location,\n            maxResults\n          );\n        results.discovery_results.google_places = googleResults;\n        results.processing_summary.total_discovered +=\n          googleResults.businesses?.length || 0;\n      }\n\n      if (this.apiClients.foursquare) {\n        const foursquareResults =\n          await this.apiClients.foursquare.searchBusinesses(\n            businessType,\n            location,\n            maxResults\n          );\n        results.discovery_results.foursquare = foursquareResults;\n        results.processing_summary.total_discovered +=\n          foursquareResults.businesses?.length || 0;\n      }\n    } catch (error) {\n      results.processing_summary.errors.push(error.message);\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(results, null, 2),\n        },\n      ],\n    };\n  }\n\n  // === FILESYSTEM ANALYSIS METHODS (from filesystem-server) ===\n\n  async analyzeProjectStructure(args = {}) {\n    const { includeFiles = true } = args;\n\n    const structure = await this.walkDirectory(\n      this.workspaceRoot,\n      includeFiles\n    );\n    const analysis = this.analyzeStructure(structure);\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              workspace_root: this.workspaceRoot,\n              structure_analysis: analysis,\n              directory_tree: structure,\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async findCodePatterns(args = {}) {\n    const {\n      pattern,\n      fileExtensions = [\".js\", \".json\", \".md\", \".sql\"],\n      excludeDirectories = [\"node_modules\", \".git\", \"archive\"],\n    } = args;\n\n    const results = [];\n    const regex = new RegExp(pattern, \"gi\");\n\n    const searchInDirectory = async (dirPath) => {\n      try {\n        const items = await fs.readdirSync(dirPath);\n\n        for (const item of items) {\n          const itemPath = path.join(dirPath, item);\n          const stats = await fs.statSync(itemPath);\n\n          if (stats.isDirectory()) {\n            if (!excludeDirectories.includes(item) && !item.startsWith(\".\")) {\n              await searchInDirectory(itemPath);\n            }\n          } else if (fileExtensions.includes(path.extname(item))) {\n            try {\n              const content = await fs.readFileSync(itemPath, \"utf8\");\n              const matches = [...content.matchAll(regex)];\n\n              if (matches.length > 0) {\n                results.push({\n                  file: path.relative(this.workspaceRoot, itemPath),\n                  matches: matches.length,\n                  details: matches.slice(0, 5).map((match) => ({\n                    match: match[0],\n                  })),\n                });\n              }\n            } catch (readError) {\n              // Skip files that can't be read\n            }\n          }\n        }\n      } catch (error) {\n        // Skip directories that can't be accessed\n      }\n    };\n\n    await searchInDirectory(this.workspaceRoot);\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              pattern,\n              total_matches: results.reduce((sum, r) => sum + r.matches, 0),\n              files_with_matches: results.length,\n              results,\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  async analyzeAPIClients(args = {}) {\n    const { detailed = false } = args;\n    const apiClientsPath = path.join(\n      this.workspaceRoot,\n      \"modules\",\n      \"api-clients\"\n    );\n\n    try {\n      const files = await fs.readdirSync(apiClientsPath);\n      const analysis = { clients: [], summary: {} };\n\n      for (const file of files) {\n        if (path.extname(file) === \".js\") {\n          const filePath = path.join(apiClientsPath, file);\n          const content = await fs.readFileSync(filePath, \"utf8\");\n\n          const clientAnalysis = {\n            name: file,\n            size: content.length,\n            method_count: (content.match(/async\\s+\\w+\\(|^\\s*\\w+\\s*\\(/gm) || [])\n              .length,\n            error_handling: (content.match(/try\\s*{|catch\\s*\\(/g) || []).length,\n            caching_implemented:\n              content.includes(\"cache\") || content.includes(\"Cache\"),\n          };\n\n          analysis.clients.push(clientAnalysis);\n        }\n      }\n\n      analysis.summary = {\n        total_clients: analysis.clients.length,\n        total_methods: analysis.clients.reduce(\n          (sum, c) => sum + c.method_count,\n          0\n        ),\n        clients_with_caching: analysis.clients.filter(\n          (c) => c.caching_implemented\n        ).length,\n      };\n\n      return {\n        content: [\n          {\n            type: \"text\",\n            text: JSON.stringify(analysis, null, 2),\n          },\n        ],\n      };\n    } catch (error) {\n      throw new Error(`Failed to analyze API clients: ${error.message}`);\n    }\n  }\n\n  async checkFakeDataViolations(args = {}) {\n    const { strict = true } = args;\n\n    const suspiciousPatterns = [\n      \"Artisan\\\\s+Bistro\",\n      \"Downtown\\\\s+Caf√©?\",\n      \"Business\\\\s+LLC\",\n      \"\\\\(555\\\\)\\\\s*\\\\d{3}-\\\\d{4}\",\n      \"example\\\\.com\",\n      \"generateFake\",\n      \"mockData\",\n    ];\n\n    const violations = [];\n\n    for (const pattern of suspiciousPatterns) {\n      const patternResults = await this.findCodePatterns({\n        pattern,\n        fileExtensions: [\".js\", \".json\"],\n        excludeDirectories: [\"node_modules\", \".git\", \"archive\", \"tests\"],\n      });\n\n      const data = JSON.parse(patternResults.content[0].text);\n      if (data.results.length > 0) {\n        violations.push({\n          pattern,\n          severity: strict ? \"HIGH\" : \"MEDIUM\",\n          matches: data.results,\n        });\n      }\n    }\n\n    return {\n      content: [\n        {\n          type: \"text\",\n          text: JSON.stringify(\n            {\n              check_mode: strict ? \"strict\" : \"standard\",\n              total_violations: violations.length,\n              violations,\n              recommendation:\n                violations.length > 0\n                  ? \"IMMEDIATE ACTION REQUIRED: Remove all fake data patterns\"\n                  : \"No fake data violations detected - good!\",\n            },\n            null,\n            2\n          ),\n        },\n      ],\n    };\n  }\n\n  // === HELPER METHODS ===\n\n  async checkFile(relativePath) {\n    try {\n      const filePath = path.join(this.workspaceRoot, relativePath);\n      const stats = await fs.statSync(filePath);\n      return {\n        exists: true,\n        size: stats.size,\n        modified: stats.mtime,\n      };\n    } catch (error) {\n      return {\n        exists: false,\n        error: error.message,\n      };\n    }\n  }\n\n  async gatherDetailedMetrics() {\n    const metrics = {\n      disk_usage: {},\n      file_counts: {},\n    };\n\n    try {\n      // Count files by extension\n      const fileExtensions = await this.countFilesByExtension();\n      metrics.file_counts = fileExtensions;\n\n      // Calculate directory sizes for key directories\n      const directories = [\"modules\", \"api\", \"database\", \"mcp-servers\"];\n      for (const dir of directories) {\n        try {\n          const dirPath = path.join(this.workspaceRoot, dir);\n          const size = await this.getDirectorySize(dirPath);\n          metrics.disk_usage[dir] = size;\n        } catch (error) {\n          metrics.disk_usage[dir] = { error: error.message };\n        }\n      }\n    } catch (error) {\n      metrics.error = error.message;\n    }\n\n    return metrics;\n  }\n\n  async countFilesByExtension() {\n    const counts = {};\n\n    const countInDirectory = async (dirPath) => {\n      try {\n        const items = await fs.readdirSync(dirPath);\n\n        for (const item of items) {\n          const itemPath = path.join(dirPath, item);\n          const stats = await fs.statSync(itemPath);\n\n          if (stats.isDirectory()) {\n            if (\n              item !== \"node_modules\" &&\n              !item.startsWith(\".\") &&\n              item !== \"archive\"\n            ) {\n              await countInDirectory(itemPath);\n            }\n          } else {\n            const ext = path.extname(item) || \"no-extension\";\n            counts[ext] = (counts[ext] || 0) + 1;\n          }\n        }\n      } catch (error) {\n        // Skip inaccessible directories\n      }\n    };\n\n    await countInDirectory(this.workspaceRoot);\n    return counts;\n  }\n\n  async getDirectorySize(dirPath) {\n    let totalSize = 0;\n\n    try {\n      const items = await fs.readdirSync(dirPath);\n\n      for (const item of items) {\n        const itemPath = path.join(dirPath, item);\n        const stats = await fs.statSync(itemPath);\n\n        if (stats.isDirectory()) {\n          if (item !== \"node_modules\" && !item.startsWith(\".\")) {\n            totalSize += await this.getDirectorySize(itemPath);\n          }\n        } else {\n          totalSize += stats.size;\n        }\n      }\n    } catch (error) {\n      // Skip inaccessible directories\n    }\n\n    return totalSize;\n  }\n\n  async walkDirectory(dirPath, includeFiles, currentDepth = 0, maxDepth = 4) {\n    if (currentDepth > maxDepth) return null;\n\n    const result = {\n      name: path.basename(dirPath),\n      type: \"directory\",\n      children: [],\n    };\n\n    try {\n      const items = await fs.readdirSync(dirPath);\n\n      for (const item of items) {\n        if (item.startsWith(\".\") && !item.includes(\"vscode\")) continue;\n        if ([\"node_modules\", \"archive\"].includes(item)) continue;\n\n        const itemPath = path.join(dirPath, item);\n        const stats = await fs.statSync(itemPath);\n\n        if (stats.isDirectory()) {\n          const childResult = await this.walkDirectory(\n            itemPath,\n            includeFiles,\n            currentDepth + 1,\n            maxDepth\n          );\n          if (childResult) result.children.push(childResult);\n        } else if (includeFiles) {\n          result.children.push({\n            name: item,\n            type: \"file\",\n            size: stats.size,\n            extension: path.extname(item),\n          });\n        }\n      }\n    } catch (error) {\n      result.error = error.message;\n    }\n\n    return result;\n  }\n\n  analyzeStructure(structure) {\n    const analysis = {\n      total_directories: 0,\n      total_files: 0,\n      file_types: {},\n      key_directories: [],\n    };\n\n    const analyzeNode = (node) => {\n      if (node.type === \"directory\") {\n        analysis.total_directories++;\n\n        // Identify key directories\n        const keyDirs = [\n          \"api\",\n          \"modules\",\n          \"config\",\n          \"database\",\n          \"mcp-servers\",\n          \"scripts\",\n        ];\n        if (keyDirs.includes(node.name)) {\n          analysis.key_directories.push({\n            name: node.name,\n            children_count: node.children?.length || 0,\n          });\n        }\n\n        if (node.children) {\n          node.children.forEach(analyzeNode);\n        }\n      } else if (node.type === \"file\") {\n        analysis.total_files++;\n        const ext = node.extension || \"no-extension\";\n        analysis.file_types[ext] = (analysis.file_types[ext] || 0) + 1;\n      }\n    };\n\n    analyzeNode(structure);\n    return analysis;\n  }\n\n  // Additional helper methods...\n  async makeHttpsRequest(options) {\n    return new Promise((resolve, reject) => {\n      const req = https.request(options, (res) => {\n        let data = \"\";\n        res.on(\"data\", (chunk) => (data += chunk));\n        res.on(\"end\", () => {\n          if (res.statusCode >= 200 && res.statusCode < 300) {\n            resolve(data);\n          } else {\n            reject(new Error(`HTTP ${res.statusCode}: ${data}`));\n          }\n        });\n      });\n      req.on(\"error\", reject);\n      req.end();\n    });\n  }\n\n  setupErrorHandling() {\n    this.server.onerror = (error) => {\n      console.error(\"[Production MCP Server Error]:\", error);\n    };\n\n    process.on(\"SIGINT\", async () => {\n      await this.server.close();\n      process.exit(0);\n    });\n  }\n\n  async run() {\n    const transport = new StdioServerTransport();\n    await this.server.connect(transport);\n    console.error(\n      \"üöÄ ProspectPro Production MCP Server v2.0 - Enhanced & Consolidated\"\n    );\n    console.error(\n      \"   üìä Production Monitoring | üóÑÔ∏è  Database Analytics | üîß System Diagnostics\"\n    );\n    console.error(\n      \"   üîå API Testing | üìÅ Filesystem Analysis | üõ°Ô∏è  Security Validation\"\n    );\n  }\n}\n\n// Start server if run directly\nif (require.main === module) {\n  const server = new ProductionMCPServer();\n  server.run().catch(console.error);\n}\n\nmodule.exports = ProductionMCPServer;\n"}}},
{"type":"measure","name":"lsp.did_open","count":38,"duration":8.401},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":21,"duration":0.094},
{"type":"mark","name":"lsp.did_close","count":34,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/archive/old-frontend/package.json"}}},
{"type":"measure","name":"lsp.did_close","count":34,"duration":0.055},
{"type":"mark","name":"lsp.did_close","count":35,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/archive/deployment-logs/package.json"}}},
{"type":"measure","name":"lsp.did_close","count":35,"duration":0.034},
{"type":"mark","name":"lsp.did_open","count":39,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/production-security-optimization.sql","languageId":"sql","version":1,"text":"-- Supabase Production Security & Performance Optimization\n-- Fixes for SECURITY DEFINER views and function search_path warnings\n-- Date: October 2025\n-- Status: Production-ready security hardening\n\n-- =============================================================================\n-- PART 1: Fix SECURITY DEFINER Views\n-- =============================================================================\n\n-- These views were detected with SECURITY DEFINER inheritance issues\n-- We'll drop and recreate them without SECURITY DEFINER properties\n\n-- Fix 1: enrichment_cache_analytics view\nDROP VIEW IF EXISTS public.enrichment_cache_analytics CASCADE;\n\nCREATE VIEW public.enrichment_cache_analytics\nWITH (security_invoker = true) AS\nSELECT \n  request_type,\n  COUNT(*) as total_entries,\n  SUM(hit_count) as total_hits,\n  AVG(confidence_score) as avg_confidence,\n  SUM(cost) as total_cost_saved,\n  ROUND(AVG(hit_count), 2) as avg_hit_count,\n  MIN(created_at) as oldest_entry,\n  MAX(last_accessed_at) as last_activity,\n  COUNT(*) FILTER (WHERE expires_at > NOW()) as active_entries,\n  COUNT(*) FILTER (WHERE expires_at <= NOW()) as expired_entries\nFROM enrichment_cache\nGROUP BY request_type\nORDER BY total_hits DESC;\n\n-- Fix 2: cache_performance_summary view  \nDROP VIEW IF EXISTS public.cache_performance_summary CASCADE;\n\nCREATE VIEW public.cache_performance_summary\nWITH (security_invoker = true) AS\nSELECT \n  date,\n  SUM(total_requests) as daily_requests,\n  SUM(cache_hits) as daily_hits,\n  SUM(cache_misses) as daily_misses,\n  ROUND(\n    CASE \n      WHEN SUM(total_requests) > 0 \n      THEN SUM(cache_hits)::DECIMAL / SUM(total_requests) * 100 \n      ELSE 0 \n    END, \n    2\n  ) as daily_hit_ratio,\n  SUM(cost_saved) as daily_cost_saved,\n  SUM(total_cost) as daily_total_cost\nFROM enrichment_cache_stats\nGROUP BY date\nORDER BY date DESC;\n\n-- =============================================================================\n-- PART 2: Fix Function Search Path Warnings\n-- =============================================================================\n\n-- All functions need explicit search_path to prevent mutable path vulnerabilities\n-- This ensures functions use qualified schema references and can't be hijacked\n\n-- Fix 1: generate_cache_key function\nCREATE OR REPLACE FUNCTION public.generate_cache_key(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS TEXT \nSET search_path = public\nAS $$\nBEGIN\n  RETURN encode(\n    digest(\n      p_request_type || '::' || p_params::text,\n      'sha256'\n    ),\n    'hex'\n  );\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE SECURITY DEFINER;\n\n-- Fix 2: get_cached_response function\nCREATE OR REPLACE FUNCTION public.get_cached_response(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS JSONB \nSET search_path = public\nAS $$\nDECLARE\n  v_cache_key TEXT;\n  v_response JSONB;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  SELECT \n    response_data \n  INTO v_response\n  FROM public.enrichment_cache \n  WHERE \n    cache_key = v_cache_key \n    AND expires_at > NOW()\n    AND request_type = p_request_type;\n  \n  -- Update hit count and last accessed\n  IF v_response IS NOT NULL THEN\n    UPDATE public.enrichment_cache \n    SET \n      hit_count = hit_count + 1,\n      last_accessed_at = NOW()\n    WHERE cache_key = v_cache_key;\n  END IF;\n  \n  RETURN v_response;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Fix 3: store_cached_response function\nCREATE OR REPLACE FUNCTION public.store_cached_response(\n  p_request_type TEXT,\n  p_params JSONB,\n  p_response JSONB,\n  p_cost DECIMAL DEFAULT 0,\n  p_confidence_score INTEGER DEFAULT 0\n) RETURNS TEXT \nSET search_path = public\nAS $$\nDECLARE\n  v_cache_key TEXT;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  -- Store with 90-day expiration\n  INSERT INTO public.enrichment_cache (\n    cache_key,\n    request_type,\n    request_params,\n    response_data,\n    cost,\n    confidence_score,\n    expires_at\n  ) VALUES (\n    v_cache_key,\n    p_request_type,\n    p_params,\n    p_response,\n    p_cost,\n    p_confidence_score,\n    NOW() + INTERVAL '90 days'\n  ) ON CONFLICT (cache_key) \n  DO UPDATE SET\n    response_data = EXCLUDED.response_data,\n    cost = EXCLUDED.cost,\n    confidence_score = EXCLUDED.confidence_score,\n    expires_at = EXCLUDED.expires_at,\n    updated_at = NOW();\n  \n  RETURN v_cache_key;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Fix 4: cleanup_expired_cache function\nCREATE OR REPLACE FUNCTION public.cleanup_expired_cache() \nRETURNS INTEGER \nSET search_path = public\nAS $$\nDECLARE\n  v_deleted_count INTEGER;\nBEGIN\n  DELETE FROM public.enrichment_cache \n  WHERE expires_at <= NOW();\n  \n  GET DIAGNOSTICS v_deleted_count = ROW_COUNT;\n  \n  RETURN v_deleted_count;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- =============================================================================\n-- PART 3: Authentication & User Management Setup for Production\n-- =============================================================================\n\n-- User profiles table (extends auth.users for additional user data)\nCREATE TABLE IF NOT EXISTS public.user_profiles (\n  id UUID PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,\n  full_name TEXT,\n  company_name TEXT,\n  industry TEXT,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Subscription tiers for SaaS functionality\nCREATE TABLE IF NOT EXISTS public.subscription_tiers (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(50) NOT NULL UNIQUE,\n  price_monthly DECIMAL(10,2) NOT NULL DEFAULT 0.00,\n  price_yearly DECIMAL(10,2) NOT NULL DEFAULT 0.00,\n  max_searches INTEGER DEFAULT 10,\n  max_exports INTEGER DEFAULT 2,\n  features JSONB DEFAULT '{}',\n  is_active BOOLEAN DEFAULT true,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- User subscriptions to track limits and usage\nCREATE TABLE IF NOT EXISTS public.user_subscriptions (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n  tier_id INTEGER REFERENCES subscription_tiers(id),\n  status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'cancelled', 'expired')),\n  current_period_start TIMESTAMPTZ DEFAULT NOW(),\n  current_period_end TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '30 days'),\n  searches_used INTEGER DEFAULT 0,\n  exports_used INTEGER DEFAULT 0,\n  stripe_subscription_id TEXT,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW(),\n  UNIQUE(user_id)\n);\n\n-- Usage tracking for analytics and billing\nCREATE TABLE IF NOT EXISTS public.usage_logs (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n  action_type VARCHAR(20) NOT NULL CHECK (action_type IN ('search', 'export')),\n  campaign_id TEXT,\n  cost DECIMAL(10,4) DEFAULT 0,\n  timestamp TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- =============================================================================\n-- PART 4: Row Level Security (RLS) Policies\n-- =============================================================================\n\n-- Enable RLS on all user tables\nALTER TABLE public.user_profiles ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.user_subscriptions ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.usage_logs ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.subscription_tiers ENABLE ROW LEVEL SECURITY;\n\n-- Update existing tables to include user ownership\nALTER TABLE public.campaigns ADD COLUMN IF NOT EXISTS user_id UUID REFERENCES auth.users(id);\n\n-- User profiles policies\nCREATE POLICY \"Users can view own profile\" ON public.user_profiles\n  FOR SELECT USING (auth.uid() = id);\n\nCREATE POLICY \"Users can update own profile\" ON public.user_profiles\n  FOR UPDATE USING (auth.uid() = id);\n\nCREATE POLICY \"Users can insert own profile\" ON public.user_profiles\n  FOR INSERT WITH CHECK (auth.uid() = id);\n\n-- Subscription policies\nCREATE POLICY \"Users can view own subscription\" ON public.user_subscriptions\n  FOR SELECT USING (auth.uid() = user_id);\n\nCREATE POLICY \"Users can update own subscription\" ON public.user_subscriptions\n  FOR UPDATE USING (auth.uid() = user_id);\n\n-- Usage logs policies\nCREATE POLICY \"Users can view own usage\" ON public.usage_logs\n  FOR SELECT USING (auth.uid() = user_id);\n\nCREATE POLICY \"System can insert usage logs\" ON public.usage_logs\n  FOR INSERT WITH CHECK (true);\n\n-- Subscription tiers (public read)\nCREATE POLICY \"Anyone can view active subscription tiers\" ON public.subscription_tiers\n  FOR SELECT USING (is_active = true);\n\n-- Update campaigns policies for user ownership\nDROP POLICY IF EXISTS \"Public read campaigns\" ON public.campaigns;\nDROP POLICY IF EXISTS \"Public insert campaigns\" ON public.campaigns;\nDROP POLICY IF EXISTS \"Public update campaigns\" ON public.campaigns;\n\nCREATE POLICY \"Users can view own campaigns\" ON public.campaigns\n  FOR SELECT USING (auth.uid() = user_id OR user_id IS NULL);\n\nCREATE POLICY \"Users can create campaigns\" ON public.campaigns\n  FOR INSERT WITH CHECK (auth.uid() = user_id);\n\nCREATE POLICY \"Users can update own campaigns\" ON public.campaigns\n  FOR UPDATE USING (auth.uid() = user_id);\n\n-- Update leads policies for user-owned campaigns\nDROP POLICY IF EXISTS \"Public read leads\" ON public.leads;\nDROP POLICY IF EXISTS \"Public insert leads\" ON public.leads;\nDROP POLICY IF EXISTS \"Public update leads\" ON public.leads;\n\nCREATE POLICY \"Users can view leads from own campaigns\" ON public.leads\n  FOR SELECT USING (\n    EXISTS (\n      SELECT 1 FROM public.campaigns \n      WHERE campaigns.id = leads.campaign_id \n      AND (campaigns.user_id = auth.uid() OR campaigns.user_id IS NULL)\n    )\n  );\n\nCREATE POLICY \"System can insert leads\" ON public.leads\n  FOR INSERT WITH CHECK (true);\n\n-- =============================================================================\n-- PART 5: User Management Functions\n-- =============================================================================\n\n-- Function to create user profile and default subscription on signup\nCREATE OR REPLACE FUNCTION public.create_user_profile_and_subscription()\nRETURNS TRIGGER \nSET search_path = public\nAS $$\nBEGIN\n  -- Create user profile\n  INSERT INTO public.user_profiles (id, full_name)\n  VALUES (NEW.id, COALESCE(NEW.raw_user_meta_data->>'full_name', ''));\n  \n  -- Create free subscription (assuming Free tier exists with id=1)\n  INSERT INTO public.user_subscriptions (user_id, tier_id)\n  VALUES (NEW.id, (SELECT id FROM public.subscription_tiers WHERE name = 'Free' LIMIT 1));\n  \n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Trigger to auto-create profile and subscription\nDROP TRIGGER IF EXISTS create_user_profile_and_subscription_trigger ON auth.users;\nCREATE TRIGGER create_user_profile_and_subscription_trigger\n  AFTER INSERT ON auth.users\n  FOR EACH ROW EXECUTE FUNCTION public.create_user_profile_and_subscription();\n\n-- Function to check usage limits before actions\nCREATE OR REPLACE FUNCTION public.check_usage_limit(user_uuid UUID, action_type TEXT)\nRETURNS JSONB \nSET search_path = public\nAS $$\nDECLARE\n  subscription_record RECORD;\n  current_usage INTEGER;\n  max_allowed INTEGER;\n  can_proceed BOOLEAN;\nBEGIN\n  -- Get user subscription with tier info\n  SELECT us.*, st.max_searches, st.max_exports, st.name as tier_name\n  INTO subscription_record\n  FROM public.user_subscriptions us\n  JOIN public.subscription_tiers st ON us.tier_id = st.id\n  WHERE us.user_id = user_uuid AND us.status = 'active';\n  \n  IF NOT FOUND THEN\n    RETURN json_build_object(\n      'can_proceed', false,\n      'usage', 0,\n      'limit', 0,\n      'error', 'No active subscription found'\n    );\n  END IF;\n  \n  -- Reset monthly usage if period has ended\n  IF subscription_record.current_period_end < NOW() THEN\n    UPDATE public.user_subscriptions \n    SET \n      current_period_start = NOW(),\n      current_period_end = NOW() + INTERVAL '30 days',\n      searches_used = 0,\n      exports_used = 0\n    WHERE user_id = user_uuid;\n    \n    -- Refresh the record\n    SELECT us.*, st.max_searches, st.max_exports, st.name as tier_name\n    INTO subscription_record\n    FROM public.user_subscriptions us\n    JOIN public.subscription_tiers st ON us.tier_id = st.id\n    WHERE us.user_id = user_uuid AND us.status = 'active';\n  END IF;\n  \n  -- Check limits based on action type\n  IF action_type = 'search' THEN\n    current_usage := subscription_record.searches_used;\n    max_allowed := subscription_record.max_searches;\n  ELSIF action_type = 'export' THEN\n    current_usage := subscription_record.exports_used;\n    max_allowed := subscription_record.max_exports;\n  ELSE\n    RETURN json_build_object(\n      'can_proceed', false,\n      'usage', 0,\n      'limit', 0,\n      'error', 'Invalid action type'\n    );\n  END IF;\n  \n  -- Check if can proceed (-1 means unlimited)\n  can_proceed := (max_allowed = -1) OR (current_usage < max_allowed);\n  \n  RETURN json_build_object(\n    'can_proceed', can_proceed,\n    'usage', current_usage,\n    'limit', max_allowed,\n    'tier', subscription_record.tier_name,\n    'period_end', subscription_record.current_period_end\n  );\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Function to increment usage after successful actions\nCREATE OR REPLACE FUNCTION public.increment_usage(\n  user_uuid UUID, \n  action_type TEXT, \n  campaign_id_param TEXT DEFAULT NULL, \n  cost_param DECIMAL DEFAULT 0\n)\nRETURNS BOOLEAN \nSET search_path = public\nAS $$\nBEGIN\n  -- Log the usage\n  INSERT INTO public.usage_logs (user_id, action_type, campaign_id, cost)\n  VALUES (user_uuid, action_type, campaign_id_param, cost_param);\n  \n  -- Increment the appropriate counter\n  IF action_type = 'search' THEN\n    UPDATE public.user_subscriptions \n    SET searches_used = searches_used + 1\n    WHERE user_id = user_uuid;\n  ELSIF action_type = 'export' THEN\n    UPDATE public.user_subscriptions \n    SET exports_used = exports_used + 1\n    WHERE user_id = user_uuid;\n  END IF;\n  \n  RETURN TRUE;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- =============================================================================\n-- PART 6: Initial Data & Performance Optimization\n-- =============================================================================\n\n-- Insert default subscription tiers\nINSERT INTO public.subscription_tiers (name, price_monthly, price_yearly, max_searches, max_exports, features) VALUES\n('Free', 0.00, 0.00, 10, 2, '{\"api_access\": false, \"priority_support\": false, \"data_export\": \"csv\"}'),\n('Pro', 29.00, 290.00, 500, 50, '{\"api_access\": true, \"priority_support\": false, \"data_export\": \"csv,json\", \"advanced_filters\": true}'),\n('Enterprise', 99.00, 990.00, -1, -1, '{\"api_access\": true, \"priority_support\": true, \"data_export\": \"csv,json,xml\", \"advanced_filters\": true, \"custom_integrations\": true}')\nON CONFLICT (name) DO NOTHING;\n\n-- Performance indexes\nCREATE INDEX IF NOT EXISTS idx_user_subscriptions_user_id ON public.user_subscriptions(user_id);\nCREATE INDEX IF NOT EXISTS idx_user_subscriptions_status ON public.user_subscriptions(status);\nCREATE INDEX IF NOT EXISTS idx_usage_logs_user_id ON public.usage_logs(user_id);\nCREATE INDEX IF NOT EXISTS idx_usage_logs_timestamp ON public.usage_logs(timestamp);\nCREATE INDEX IF NOT EXISTS idx_campaigns_user_id ON public.campaigns(user_id);\nCREATE INDEX IF NOT EXISTS idx_enrichment_cache_request_type ON public.enrichment_cache(request_type);\nCREATE INDEX IF NOT EXISTS idx_enrichment_cache_expires_at ON public.enrichment_cache(expires_at);\n\n-- =============================================================================\n-- PART 7: Production Security Comments & Documentation\n-- =============================================================================\n\nCOMMENT ON VIEW public.enrichment_cache_analytics IS 'Cache analytics view with security_invoker for production safety';\nCOMMENT ON VIEW public.cache_performance_summary IS 'Cache performance summary with security_invoker for production safety';\n\nCOMMENT ON FUNCTION public.generate_cache_key(TEXT, JSONB) IS 'Generate SHA-256 cache key with explicit search_path for security';\nCOMMENT ON FUNCTION public.get_cached_response(TEXT, JSONB) IS 'Retrieve cached response with qualified schema references';\nCOMMENT ON FUNCTION public.store_cached_response(TEXT, JSONB, JSONB, DECIMAL, INTEGER) IS 'Store cached response with security-hardened function';\nCOMMENT ON FUNCTION public.cleanup_expired_cache() IS 'Cleanup expired cache entries with production security settings';\n\nCOMMENT ON FUNCTION public.check_usage_limit(UUID, TEXT) IS 'Check user subscription limits before API actions';\nCOMMENT ON FUNCTION public.increment_usage(UUID, TEXT, TEXT, DECIMAL) IS 'Increment usage counters after successful API actions';\n\nCOMMENT ON TABLE public.user_profiles IS 'Extended user profile data with RLS enabled';\nCOMMENT ON TABLE public.subscription_tiers IS 'SaaS subscription tier definitions';\nCOMMENT ON TABLE public.user_subscriptions IS 'User subscription status and usage tracking';\nCOMMENT ON TABLE public.usage_logs IS 'Detailed usage logs for analytics and billing';\n\n-- =============================================================================\n-- VERIFICATION QUERIES (Run after deployment to confirm fixes)\n-- =============================================================================\n\n/*\n-- Verify views are fixed (should return no SECURITY DEFINER references)\nSELECT \n  schemaname, \n  viewname, \n  definition \nFROM pg_views \nWHERE viewname IN ('enrichment_cache_analytics', 'cache_performance_summary')\nAND definition LIKE '%SECURITY DEFINER%';\n\n-- Verify functions have proper search_path (should return all functions with search_path set)\nSELECT \n  routine_name,\n  routine_type,\n  routine_definition\nFROM information_schema.routines \nWHERE routine_name IN ('generate_cache_key', 'get_cached_response', 'store_cached_response', 'cleanup_expired_cache')\nAND routine_schema = 'public';\n\n-- Verify RLS policies are active\nSELECT \n  schemaname, \n  tablename, \n  policyname, \n  permissive, \n  roles, \n  cmd, \n  qual \nFROM pg_policies \nWHERE tablename IN ('user_profiles', 'user_subscriptions', 'usage_logs', 'campaigns', 'leads');\n\n-- Test user subscription system (after authentication is enabled)\nSELECT * FROM public.subscription_tiers WHERE is_active = true;\n*/"}}},
{"type":"measure","name":"lsp.did_open","count":39,"duration":0.196},
{"type":"mark","name":"lsp.did_open","count":40,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/fix-supabase-security-warnings.sql","languageId":"sql","version":1,"text":"-- Fix Supabase Security Warnings\n-- This addresses SECURITY DEFINER views and function search_path issues\n-- \n-- FIXED ISSUES:\n-- 1. Function signature mismatch for store_cached_response (parameter order)\n-- 2. SECURITY DEFINER warnings for views\n-- 3. Missing search_path settings for functions\n-- 4. Explicit schema references to prevent ambiguity\n\n-- 1. Fix enrichment_cache_analytics view (remove SECURITY DEFINER if present)\nDROP VIEW IF EXISTS public.enrichment_cache_analytics CASCADE;\n\nCREATE VIEW public.enrichment_cache_analytics AS\nSELECT \n  request_type,\n  COUNT(*) as total_entries,\n  SUM(hit_count) as total_hits,\n  AVG(confidence_score) as avg_confidence,\n  SUM(cost) as total_cost_saved,\n  ROUND(AVG(hit_count), 2) as avg_hit_count,\n  MIN(created_at) as oldest_entry,\n  MAX(last_accessed_at) as last_activity,\n  COUNT(*) FILTER (WHERE expires_at > NOW()) as active_entries,\n  COUNT(*) FILTER (WHERE expires_at <= NOW()) as expired_entries\nFROM public.enrichment_cache\nGROUP BY request_type\nORDER BY total_hits DESC;\n\n-- 2. Fix cache_performance_summary view (remove SECURITY DEFINER if present)\nDROP VIEW IF EXISTS public.cache_performance_summary CASCADE;\n\nCREATE VIEW public.cache_performance_summary AS\nSELECT \n  date,\n  SUM(total_requests) as daily_requests,\n  SUM(cache_hits) as daily_hits,\n  SUM(cache_misses) as daily_misses,\n  ROUND(\n    CASE \n      WHEN SUM(total_requests) > 0 \n      THEN SUM(cache_hits)::DECIMAL / SUM(total_requests) * 100 \n      ELSE 0 \n    END, \n    2\n  ) as daily_hit_ratio,\n  SUM(cost_saved) as daily_cost_saved,\n  SUM(total_cost) as daily_total_cost\nFROM public.enrichment_cache_stats\nGROUP BY date\nORDER BY date DESC;\n\n-- 3. Fix function search_path issues by adding explicit search_path settings\nCREATE OR REPLACE FUNCTION public.generate_cache_key(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS TEXT AS $$\nBEGIN\n  RETURN encode(\n    digest(\n      p_request_type || '::' || p_params::text,\n      'sha256'\n    ),\n    'hex'\n  );\nEND;\n$$ LANGUAGE plpgsql \nSET search_path = public;\n\nCREATE OR REPLACE FUNCTION public.get_cached_response(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS JSONB AS $$\nDECLARE\n  v_cache_key TEXT;\n  v_response JSONB;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  -- Get cached response if not expired\n  SELECT response_data INTO v_response\n  FROM public.enrichment_cache\n  WHERE cache_key = v_cache_key\n    AND request_type = p_request_type\n    AND expires_at > NOW();\n  \n  -- Update hit count and last accessed time if found\n  IF v_response IS NOT NULL THEN\n    UPDATE public.enrichment_cache\n    SET hit_count = hit_count + 1,\n        last_accessed_at = NOW(),\n        updated_at = NOW()\n    WHERE cache_key = v_cache_key;\n    \n    -- Update cache statistics\n    INSERT INTO public.enrichment_cache_stats (date, request_type, cache_hits)\n    VALUES (CURRENT_DATE, p_request_type, 1)\n    ON CONFLICT (date, request_type)\n    DO UPDATE SET \n      cache_hits = enrichment_cache_stats.cache_hits + 1,\n      total_requests = enrichment_cache_stats.total_requests + 1,\n      hit_ratio = ROUND(\n        (enrichment_cache_stats.cache_hits + 1.0) / \n        (enrichment_cache_stats.total_requests + 1.0) * 100, \n        2\n      ),\n      updated_at = NOW();\n  ELSE\n    -- Update cache miss statistics\n    INSERT INTO public.enrichment_cache_stats (date, request_type, cache_misses)\n    VALUES (CURRENT_DATE, p_request_type, 1)\n    ON CONFLICT (date, request_type)\n    DO UPDATE SET \n      cache_misses = enrichment_cache_stats.cache_misses + 1,\n      total_requests = enrichment_cache_stats.total_requests + 1,\n      hit_ratio = ROUND(\n        enrichment_cache_stats.cache_hits / \n        (enrichment_cache_stats.total_requests + 1.0) * 100, \n        2\n      ),\n      updated_at = NOW();\n  END IF;\n  \n  RETURN v_response;\nEND;\n$$ LANGUAGE plpgsql \nSET search_path = public;\n\nCREATE OR REPLACE FUNCTION public.store_cached_response(\n  p_request_type TEXT,\n  p_params JSONB,\n  p_response JSONB,\n  p_cost DECIMAL DEFAULT 0,\n  p_confidence_score INTEGER DEFAULT 0\n) RETURNS TEXT AS $$\nDECLARE\n  v_cache_key TEXT;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  -- Store with 90-day expiration\n  INSERT INTO public.enrichment_cache (\n    cache_key,\n    request_type,\n    request_params,\n    response_data,\n    cost,\n    confidence_score,\n    expires_at\n  ) VALUES (\n    v_cache_key,\n    p_request_type,\n    p_params,\n    p_response,\n    p_cost,\n    p_confidence_score,\n    NOW() + INTERVAL '90 days'\n  )\n  ON CONFLICT (cache_key) \n  DO UPDATE SET\n    response_data = EXCLUDED.response_data,\n    cost = EXCLUDED.cost,\n    confidence_score = EXCLUDED.confidence_score,\n    hit_count = enrichment_cache.hit_count + 1,\n    expires_at = NOW() + INTERVAL '90 days',\n    updated_at = NOW();\n  \n  -- Update cost statistics\n  INSERT INTO public.enrichment_cache_stats (date, request_type, total_cost)\n  VALUES (CURRENT_DATE, p_request_type, p_cost)\n  ON CONFLICT (date, request_type)\n  DO UPDATE SET \n    total_cost = enrichment_cache_stats.total_cost + p_cost,\n    updated_at = NOW();\n  \n  RETURN v_cache_key;\nEND;\n$$ LANGUAGE plpgsql \nSET search_path = public;\n\nCREATE OR REPLACE FUNCTION public.cleanup_expired_cache() RETURNS INTEGER AS $$\nDECLARE\n  deleted_count INTEGER;\nBEGIN\n  DELETE FROM public.enrichment_cache\n  WHERE expires_at <= NOW();\n  \n  GET DIAGNOSTICS deleted_count = ROW_COUNT;\n  RETURN deleted_count;\nEND;\n$$ LANGUAGE plpgsql \nSET search_path = public;\n\n-- Fix campaign_analytics view (the main SECURITY DEFINER issue)\nDROP VIEW IF EXISTS public.campaign_analytics CASCADE;\n\nCREATE VIEW public.campaign_analytics AS\nSELECT\n  c.id,\n  c.business_type,\n  c.location,\n  c.target_count,\n  c.min_confidence_score,\n  c.status,\n  c.results_count,\n  c.total_cost,\n  c.budget_limit,\n  c.processing_time_ms,\n  c.created_at,\n  COUNT(l.id) AS actual_leads,\n  COALESCE(AVG(l.confidence_score), 0)::numeric(10,2) AS avg_confidence,\n  COALESCE(SUM(l.validation_cost), 0)::numeric(12,4) AS total_validation_cost,\n  COUNT(*) FILTER (WHERE l.cost_efficient IS TRUE) AS cost_efficient_leads\nFROM public.campaigns c\nLEFT JOIN public.leads l ON l.campaign_id = c.id\nGROUP BY\n  c.id,\n  c.business_type,\n  c.location,\n  c.target_count,\n  c.min_confidence_score,\n  c.status,\n  c.results_count,\n  c.total_cost,\n  c.budget_limit,\n  c.processing_time_ms,\n  c.created_at;\n\n-- Comments for clarity\nCOMMENT ON VIEW public.enrichment_cache_analytics IS 'Cache analytics view without SECURITY DEFINER';\nCOMMENT ON VIEW public.cache_performance_summary IS 'Cache performance summary view without SECURITY DEFINER';\nCOMMENT ON VIEW public.campaign_analytics IS 'Campaign analytics view without SECURITY DEFINER';\nCOMMENT ON FUNCTION public.generate_cache_key IS 'Generate cache key with explicit search_path';\nCOMMENT ON FUNCTION public.get_cached_response IS 'Get cached response with explicit search_path';\nCOMMENT ON FUNCTION public.store_cached_response IS 'Store cached response with explicit search_path';\nCOMMENT ON FUNCTION public.cleanup_expired_cache IS 'Cleanup expired cache with explicit search_path';"}}},
{"type":"measure","name":"lsp.did_open","count":40,"duration":0.102},
{"type":"mark","name":"lsp.did_open","count":41,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/supabase/migrations/20251003225603_production_security_optimization.sql","languageId":"sql","version":1,"text":"-- Supabase Production Security & Performance Optimization\n-- Fixes for SECURITY DEFINER views and function search_path warnings\n-- Date: October 2025\n-- Status: Production-ready security hardening\n\n-- =============================================================================\n-- PART 1: Fix SECURITY DEFINER Views\n-- =============================================================================\n\n-- These views were detected with SECURITY DEFINER inheritance issues\n-- We'll drop and recreate them without SECURITY DEFINER properties\n\n-- Fix 1: enrichment_cache_analytics view\nDROP VIEW IF EXISTS public.enrichment_cache_analytics CASCADE;\n\nCREATE VIEW public.enrichment_cache_analytics\nWITH (security_invoker = true) AS\nSELECT \n  request_type,\n  COUNT(*) as total_entries,\n  SUM(hit_count) as total_hits,\n  AVG(confidence_score) as avg_confidence,\n  SUM(cost) as total_cost_saved,\n  ROUND(AVG(hit_count), 2) as avg_hit_count,\n  MIN(created_at) as oldest_entry,\n  MAX(last_accessed_at) as last_activity,\n  COUNT(*) FILTER (WHERE expires_at > NOW()) as active_entries,\n  COUNT(*) FILTER (WHERE expires_at <= NOW()) as expired_entries\nFROM enrichment_cache\nGROUP BY request_type\nORDER BY total_hits DESC;\n\n-- Fix 2: cache_performance_summary view  \nDROP VIEW IF EXISTS public.cache_performance_summary CASCADE;\n\nCREATE VIEW public.cache_performance_summary\nWITH (security_invoker = true) AS\nSELECT \n  date,\n  SUM(total_requests) as daily_requests,\n  SUM(cache_hits) as daily_hits,\n  SUM(cache_misses) as daily_misses,\n  ROUND(\n    CASE \n      WHEN SUM(total_requests) > 0 \n      THEN SUM(cache_hits)::DECIMAL / SUM(total_requests) * 100 \n      ELSE 0 \n    END, \n    2\n  ) as daily_hit_ratio,\n  SUM(cost_saved) as daily_cost_saved,\n  SUM(total_cost) as daily_total_cost\nFROM enrichment_cache_stats\nGROUP BY date\nORDER BY date DESC;\n\n-- =============================================================================\n-- PART 2: Fix Function Search Path Warnings\n-- =============================================================================\n\n-- All functions need explicit search_path to prevent mutable path vulnerabilities\n-- This ensures functions use qualified schema references and can't be hijacked\n\n-- Fix 1: generate_cache_key function\nCREATE OR REPLACE FUNCTION public.generate_cache_key(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS TEXT \nSET search_path = public\nAS $$\nBEGIN\n  RETURN encode(\n    digest(\n      p_request_type || '::' || p_params::text,\n      'sha256'\n    ),\n    'hex'\n  );\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE SECURITY DEFINER;\n\n-- Fix 2: get_cached_response function\nCREATE OR REPLACE FUNCTION public.get_cached_response(\n  p_request_type TEXT,\n  p_params JSONB\n) RETURNS JSONB \nSET search_path = public\nAS $$\nDECLARE\n  v_cache_key TEXT;\n  v_response JSONB;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  SELECT \n    response_data \n  INTO v_response\n  FROM public.enrichment_cache \n  WHERE \n    cache_key = v_cache_key \n    AND expires_at > NOW()\n    AND request_type = p_request_type;\n  \n  -- Update hit count and last accessed\n  IF v_response IS NOT NULL THEN\n    UPDATE public.enrichment_cache \n    SET \n      hit_count = hit_count + 1,\n      last_accessed_at = NOW()\n    WHERE cache_key = v_cache_key;\n  END IF;\n  \n  RETURN v_response;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Fix 3: store_cached_response function\nCREATE OR REPLACE FUNCTION public.store_cached_response(\n  p_request_type TEXT,\n  p_params JSONB,\n  p_response JSONB,\n  p_cost DECIMAL DEFAULT 0,\n  p_confidence_score INTEGER DEFAULT 0\n) RETURNS TEXT \nSET search_path = public\nAS $$\nDECLARE\n  v_cache_key TEXT;\nBEGIN\n  v_cache_key := public.generate_cache_key(p_request_type, p_params);\n  \n  -- Store with 90-day expiration\n  INSERT INTO public.enrichment_cache (\n    cache_key,\n    request_type,\n    request_params,\n    response_data,\n    cost,\n    confidence_score,\n    expires_at\n  ) VALUES (\n    v_cache_key,\n    p_request_type,\n    p_params,\n    p_response,\n    p_cost,\n    p_confidence_score,\n    NOW() + INTERVAL '90 days'\n  ) ON CONFLICT (cache_key) \n  DO UPDATE SET\n    response_data = EXCLUDED.response_data,\n    cost = EXCLUDED.cost,\n    confidence_score = EXCLUDED.confidence_score,\n    expires_at = EXCLUDED.expires_at,\n    updated_at = NOW();\n  \n  RETURN v_cache_key;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Fix 4: cleanup_expired_cache function\nCREATE OR REPLACE FUNCTION public.cleanup_expired_cache() \nRETURNS INTEGER \nSET search_path = public\nAS $$\nDECLARE\n  v_deleted_count INTEGER;\nBEGIN\n  DELETE FROM public.enrichment_cache \n  WHERE expires_at <= NOW();\n  \n  GET DIAGNOSTICS v_deleted_count = ROW_COUNT;\n  \n  RETURN v_deleted_count;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- =============================================================================\n-- PART 3: Authentication & User Management Setup for Production\n-- =============================================================================\n\n-- User profiles table (extends auth.users for additional user data)\nCREATE TABLE IF NOT EXISTS public.user_profiles (\n  id UUID PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,\n  full_name TEXT,\n  company_name TEXT,\n  industry TEXT,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Subscription tiers for SaaS functionality\nCREATE TABLE IF NOT EXISTS public.subscription_tiers (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(50) NOT NULL UNIQUE,\n  price_monthly DECIMAL(10,2) NOT NULL DEFAULT 0.00,\n  price_yearly DECIMAL(10,2) NOT NULL DEFAULT 0.00,\n  max_searches INTEGER DEFAULT 10,\n  max_exports INTEGER DEFAULT 2,\n  features JSONB DEFAULT '{}',\n  is_active BOOLEAN DEFAULT true,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- User subscriptions to track limits and usage\nCREATE TABLE IF NOT EXISTS public.user_subscriptions (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n  tier_id INTEGER REFERENCES subscription_tiers(id),\n  status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'cancelled', 'expired')),\n  current_period_start TIMESTAMPTZ DEFAULT NOW(),\n  current_period_end TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '30 days'),\n  searches_used INTEGER DEFAULT 0,\n  exports_used INTEGER DEFAULT 0,\n  stripe_subscription_id TEXT,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW(),\n  UNIQUE(user_id)\n);\n\n-- Usage tracking for analytics and billing\nCREATE TABLE IF NOT EXISTS public.usage_logs (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,\n  action_type VARCHAR(20) NOT NULL CHECK (action_type IN ('search', 'export')),\n  campaign_id TEXT,\n  cost DECIMAL(10,4) DEFAULT 0,\n  timestamp TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- =============================================================================\n-- PART 4: Row Level Security (RLS) Policies\n-- =============================================================================\n\n-- Enable RLS on all user tables\nALTER TABLE public.user_profiles ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.user_subscriptions ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.usage_logs ENABLE ROW LEVEL SECURITY;\nALTER TABLE public.subscription_tiers ENABLE ROW LEVEL SECURITY;\n\n-- Update existing tables to include user ownership\nALTER TABLE public.campaigns ADD COLUMN IF NOT EXISTS user_id UUID REFERENCES auth.users(id);\n\n-- User profiles policies\nCREATE POLICY \"Users can view own profile\" ON public.user_profiles\n  FOR SELECT USING (auth.uid() = id);\n\nCREATE POLICY \"Users can update own profile\" ON public.user_profiles\n  FOR UPDATE USING (auth.uid() = id);\n\nCREATE POLICY \"Users can insert own profile\" ON public.user_profiles\n  FOR INSERT WITH CHECK (auth.uid() = id);\n\n-- Subscription policies\nCREATE POLICY \"Users can view own subscription\" ON public.user_subscriptions\n  FOR SELECT USING (auth.uid() = user_id);\n\nCREATE POLICY \"Users can update own subscription\" ON public.user_subscriptions\n  FOR UPDATE USING (auth.uid() = user_id);\n\n-- Usage logs policies\nCREATE POLICY \"Users can view own usage\" ON public.usage_logs\n  FOR SELECT USING (auth.uid() = user_id);\n\nCREATE POLICY \"System can insert usage logs\" ON public.usage_logs\n  FOR INSERT WITH CHECK (true);\n\n-- Subscription tiers (public read)\nCREATE POLICY \"Anyone can view active subscription tiers\" ON public.subscription_tiers\n  FOR SELECT USING (is_active = true);\n\n-- Update campaigns policies for user ownership\nDROP POLICY IF EXISTS \"Public read campaigns\" ON public.campaigns;\nDROP POLICY IF EXISTS \"Public insert campaigns\" ON public.campaigns;\nDROP POLICY IF EXISTS \"Public update campaigns\" ON public.campaigns;\n\nCREATE POLICY \"Users can view own campaigns\" ON public.campaigns\n  FOR SELECT USING (auth.uid() = user_id OR user_id IS NULL);\n\nCREATE POLICY \"Users can create campaigns\" ON public.campaigns\n  FOR INSERT WITH CHECK (auth.uid() = user_id);\n\nCREATE POLICY \"Users can update own campaigns\" ON public.campaigns\n  FOR UPDATE USING (auth.uid() = user_id);\n\n-- Update leads policies for user-owned campaigns\nDROP POLICY IF EXISTS \"Public read leads\" ON public.leads;\nDROP POLICY IF EXISTS \"Public insert leads\" ON public.leads;\nDROP POLICY IF EXISTS \"Public update leads\" ON public.leads;\n\nCREATE POLICY \"Users can view leads from own campaigns\" ON public.leads\n  FOR SELECT USING (\n    EXISTS (\n      SELECT 1 FROM public.campaigns \n      WHERE campaigns.id = leads.campaign_id \n      AND (campaigns.user_id = auth.uid() OR campaigns.user_id IS NULL)\n    )\n  );\n\nCREATE POLICY \"System can insert leads\" ON public.leads\n  FOR INSERT WITH CHECK (true);\n\n-- =============================================================================\n-- PART 5: User Management Functions\n-- =============================================================================\n\n-- Function to create user profile and default subscription on signup\nCREATE OR REPLACE FUNCTION public.create_user_profile_and_subscription()\nRETURNS TRIGGER \nSET search_path = public\nAS $$\nBEGIN\n  -- Create user profile\n  INSERT INTO public.user_profiles (id, full_name)\n  VALUES (NEW.id, COALESCE(NEW.raw_user_meta_data->>'full_name', ''));\n  \n  -- Create free subscription (assuming Free tier exists with id=1)\n  INSERT INTO public.user_subscriptions (user_id, tier_id)\n  VALUES (NEW.id, (SELECT id FROM public.subscription_tiers WHERE name = 'Free' LIMIT 1));\n  \n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Trigger to auto-create profile and subscription\nDROP TRIGGER IF EXISTS create_user_profile_and_subscription_trigger ON auth.users;\nCREATE TRIGGER create_user_profile_and_subscription_trigger\n  AFTER INSERT ON auth.users\n  FOR EACH ROW EXECUTE FUNCTION public.create_user_profile_and_subscription();\n\n-- Function to check usage limits before actions\nCREATE OR REPLACE FUNCTION public.check_usage_limit(user_uuid UUID, action_type TEXT)\nRETURNS JSONB \nSET search_path = public\nAS $$\nDECLARE\n  subscription_record RECORD;\n  current_usage INTEGER;\n  max_allowed INTEGER;\n  can_proceed BOOLEAN;\nBEGIN\n  -- Get user subscription with tier info\n  SELECT us.*, st.max_searches, st.max_exports, st.name as tier_name\n  INTO subscription_record\n  FROM public.user_subscriptions us\n  JOIN public.subscription_tiers st ON us.tier_id = st.id\n  WHERE us.user_id = user_uuid AND us.status = 'active';\n  \n  IF NOT FOUND THEN\n    RETURN json_build_object(\n      'can_proceed', false,\n      'usage', 0,\n      'limit', 0,\n      'error', 'No active subscription found'\n    );\n  END IF;\n  \n  -- Reset monthly usage if period has ended\n  IF subscription_record.current_period_end < NOW() THEN\n    UPDATE public.user_subscriptions \n    SET \n      current_period_start = NOW(),\n      current_period_end = NOW() + INTERVAL '30 days',\n      searches_used = 0,\n      exports_used = 0\n    WHERE user_id = user_uuid;\n    \n    -- Refresh the record\n    SELECT us.*, st.max_searches, st.max_exports, st.name as tier_name\n    INTO subscription_record\n    FROM public.user_subscriptions us\n    JOIN public.subscription_tiers st ON us.tier_id = st.id\n    WHERE us.user_id = user_uuid AND us.status = 'active';\n  END IF;\n  \n  -- Check limits based on action type\n  IF action_type = 'search' THEN\n    current_usage := subscription_record.searches_used;\n    max_allowed := subscription_record.max_searches;\n  ELSIF action_type = 'export' THEN\n    current_usage := subscription_record.exports_used;\n    max_allowed := subscription_record.max_exports;\n  ELSE\n    RETURN json_build_object(\n      'can_proceed', false,\n      'usage', 0,\n      'limit', 0,\n      'error', 'Invalid action type'\n    );\n  END IF;\n  \n  -- Check if can proceed (-1 means unlimited)\n  can_proceed := (max_allowed = -1) OR (current_usage < max_allowed);\n  \n  RETURN json_build_object(\n    'can_proceed', can_proceed,\n    'usage', current_usage,\n    'limit', max_allowed,\n    'tier', subscription_record.tier_name,\n    'period_end', subscription_record.current_period_end\n  );\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- Function to increment usage after successful actions\nCREATE OR REPLACE FUNCTION public.increment_usage(\n  user_uuid UUID, \n  action_type TEXT, \n  campaign_id_param TEXT DEFAULT NULL, \n  cost_param DECIMAL DEFAULT 0\n)\nRETURNS BOOLEAN \nSET search_path = public\nAS $$\nBEGIN\n  -- Log the usage\n  INSERT INTO public.usage_logs (user_id, action_type, campaign_id, cost)\n  VALUES (user_uuid, action_type, campaign_id_param, cost_param);\n  \n  -- Increment the appropriate counter\n  IF action_type = 'search' THEN\n    UPDATE public.user_subscriptions \n    SET searches_used = searches_used + 1\n    WHERE user_id = user_uuid;\n  ELSIF action_type = 'export' THEN\n    UPDATE public.user_subscriptions \n    SET exports_used = exports_used + 1\n    WHERE user_id = user_uuid;\n  END IF;\n  \n  RETURN TRUE;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n\n-- =============================================================================\n-- PART 6: Initial Data & Performance Optimization\n-- =============================================================================\n\n-- Insert default subscription tiers\nINSERT INTO public.subscription_tiers (name, price_monthly, price_yearly, max_searches, max_exports, features) VALUES\n('Free', 0.00, 0.00, 10, 2, '{\"api_access\": false, \"priority_support\": false, \"data_export\": \"csv\"}'),\n('Pro', 29.00, 290.00, 500, 50, '{\"api_access\": true, \"priority_support\": false, \"data_export\": \"csv,json\", \"advanced_filters\": true}'),\n('Enterprise', 99.00, 990.00, -1, -1, '{\"api_access\": true, \"priority_support\": true, \"data_export\": \"csv,json,xml\", \"advanced_filters\": true, \"custom_integrations\": true}')\nON CONFLICT (name) DO NOTHING;\n\n-- Performance indexes\nCREATE INDEX IF NOT EXISTS idx_user_subscriptions_user_id ON public.user_subscriptions(user_id);\nCREATE INDEX IF NOT EXISTS idx_user_subscriptions_status ON public.user_subscriptions(status);\nCREATE INDEX IF NOT EXISTS idx_usage_logs_user_id ON public.usage_logs(user_id);\nCREATE INDEX IF NOT EXISTS idx_usage_logs_timestamp ON public.usage_logs(timestamp);\nCREATE INDEX IF NOT EXISTS idx_campaigns_user_id ON public.campaigns(user_id);\nCREATE INDEX IF NOT EXISTS idx_enrichment_cache_request_type ON public.enrichment_cache(request_type);\nCREATE INDEX IF NOT EXISTS idx_enrichment_cache_expires_at ON public.enrichment_cache(expires_at);\n\n-- =============================================================================\n-- PART 7: Production Security Comments & Documentation\n-- =============================================================================\n\nCOMMENT ON VIEW public.enrichment_cache_analytics IS 'Cache analytics view with security_invoker for production safety';\nCOMMENT ON VIEW public.cache_performance_summary IS 'Cache performance summary with security_invoker for production safety';\n\nCOMMENT ON FUNCTION public.generate_cache_key(TEXT, JSONB) IS 'Generate SHA-256 cache key with explicit search_path for security';\nCOMMENT ON FUNCTION public.get_cached_response(TEXT, JSONB) IS 'Retrieve cached response with qualified schema references';\nCOMMENT ON FUNCTION public.store_cached_response(TEXT, JSONB, JSONB, DECIMAL, INTEGER) IS 'Store cached response with security-hardened function';\nCOMMENT ON FUNCTION public.cleanup_expired_cache() IS 'Cleanup expired cache entries with production security settings';\n\nCOMMENT ON FUNCTION public.check_usage_limit(UUID, TEXT) IS 'Check user subscription limits before API actions';\nCOMMENT ON FUNCTION public.increment_usage(UUID, TEXT, TEXT, DECIMAL) IS 'Increment usage counters after successful API actions';\n\nCOMMENT ON TABLE public.user_profiles IS 'Extended user profile data with RLS enabled';\nCOMMENT ON TABLE public.subscription_tiers IS 'SaaS subscription tier definitions';\nCOMMENT ON TABLE public.user_subscriptions IS 'User subscription status and usage tracking';\nCOMMENT ON TABLE public.usage_logs IS 'Detailed usage logs for analytics and billing';\n\n-- =============================================================================\n-- VERIFICATION QUERIES (Run after deployment to confirm fixes)\n-- =============================================================================\n\n/*\n-- Verify views are fixed (should return no SECURITY DEFINER references)\nSELECT \n  schemaname, \n  viewname, \n  definition \nFROM pg_views \nWHERE viewname IN ('enrichment_cache_analytics', 'cache_performance_summary')\nAND definition LIKE '%SECURITY DEFINER%';\n\n-- Verify functions have proper search_path (should return all functions with search_path set)\nSELECT \n  routine_name,\n  routine_type,\n  routine_definition\nFROM information_schema.routines \nWHERE routine_name IN ('generate_cache_key', 'get_cached_response', 'store_cached_response', 'cleanup_expired_cache')\nAND routine_schema = 'public';\n\n-- Verify RLS policies are active\nSELECT \n  schemaname, \n  tablename, \n  policyname, \n  permissive, \n  roles, \n  cmd, \n  qual \nFROM pg_policies \nWHERE tablename IN ('user_profiles', 'user_subscriptions', 'usage_logs', 'campaigns', 'leads');\n\n-- Test user subscription system (after authentication is enabled)\nSELECT * FROM public.subscription_tiers WHERE is_active = true;\n*/"}}},
{"type":"measure","name":"lsp.did_open","count":41,"duration":0.171},
{"type":"mark","name":"lsp.did_close","count":36,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/package.json"}}},
{"type":"measure","name":"lsp.did_close","count":36,"duration":0.03},
{"type":"mark","name":"lsp.did_open","count":42,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/lib/supabase.ts","languageId":"typescript","version":1,"text":"import { createClient } from \"@supabase/supabase-js\";\n\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL;\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY;\n\nif (!supabaseUrl || !supabaseAnonKey) {\n  throw new Error(\"Missing Supabase environment variables\");\n}\n\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey, {\n  auth: {\n    persistSession: true,\n    autoRefreshToken: true,\n  },\n});\n\n// Edge Functions URL\nexport const EDGE_FUNCTIONS_URL =\n  import.meta.env.VITE_EDGE_FUNCTIONS_URL || `${supabaseUrl}/functions/v1`;\n\n// Edge Function endpoints for vault-secured progressive enrichment\nexport const EDGE_FUNCTIONS = {\n  // Progressive Enrichment Orchestrator (vault-secured)\n  ENRICHMENT_ORCHESTRATOR: `${EDGE_FUNCTIONS_URL}/enrichment-orchestrator`,\n\n  // Individual enrichment services (vault-secured)\n  ENRICHMENT_BUSINESS_LICENSE: `${EDGE_FUNCTIONS_URL}/enrichment-business-license`,\n  ENRICHMENT_PDL: `${EDGE_FUNCTIONS_URL}/enrichment-pdl`,\n  ENRICHMENT_HUNTER: `${EDGE_FUNCTIONS_URL}/enrichment-hunter`,\n  ENRICHMENT_NEVERBOUNCE: `${EDGE_FUNCTIONS_URL}/enrichment-neverbounce`,\n\n  // Legacy endpoints (for backward compatibility)\n  ENHANCED_BUSINESS_DISCOVERY: `${EDGE_FUNCTIONS_URL}/enhanced-business-discovery`,\n  LEAD_VALIDATION: `${EDGE_FUNCTIONS_URL}/lead-validation-edge`,\n  BUSINESS_DISCOVERY: `${EDGE_FUNCTIONS_URL}/business-discovery-edge`,\n  DIAGNOSTICS: `${EDGE_FUNCTIONS_URL}/diag`,\n} as const;\n\n// Progressive Enrichment Tiers (Actual API costs)\nexport const ENRICHMENT_TIERS = {\n  STARTER: {\n    name: \"Starter\",\n    price: 0.034, // Google Places API cost per search\n    stages: [\"business-license\", \"company-enrichment\"],\n    description: \"Basic business validation and company data\",\n    hasOwnershipData: false,\n  },\n  PROFESSIONAL: {\n    name: \"Professional\",\n    price: 0.076, // Google Places + Hunter.io ($0.034 + $0.042 average)\n    stages: [\"business-license\", \"company-enrichment\", \"email-discovery\"],\n    description: \"Business validation + verified email discovery\",\n    hasOwnershipData: false,\n  },\n  ENTERPRISE: {\n    name: \"Enterprise\",\n    price: 0.118, // Google Places + Hunter.io + NeverBounce ($0.034 + $0.042 + $0.042)\n    stages: [\n      \"business-license\",\n      \"company-enrichment\",\n      \"email-discovery\",\n      \"email-verification\",\n    ],\n    description: \"Complete enrichment + email verification\",\n    hasOwnershipData: false,\n  },\n  COMPLIANCE: {\n    name: \"Compliance\",\n    price: 1.118, // All above + Apollo.io ($0.118 + $1.00)\n    stages: [\n      \"business-license\",\n      \"company-enrichment\",\n      \"email-discovery\",\n      \"email-verification\",\n      \"person-enrichment\",\n    ],\n    description: \"Full compliance-grade enrichment with executive contacts\",\n    hasOwnershipData: true,\n  },\n} as const;\n"}}},
{"type":"measure","name":"lsp.did_open","count":42,"duration":0.891},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":22,"duration":0.101},
{"type":"mark","name":"lsp.did_close","count":37,"args":{"textDocument":{"uri":"vscode-userdata:/c%3A/Users/Alext/AppData/Roaming/Code/User/settings.json"}}},
{"type":"measure","name":"lsp.did_close","count":37,"duration":0.007},
{"type":"mark","name":"lsp.did_close","count":38,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/mcp-servers/production-server.js"}}},
{"type":"measure","name":"lsp.did_close","count":38,"duration":1.266},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":23,"duration":0.103},
{"type":"mark","name":"lsp.did_close","count":39,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/production-security-optimization.sql"}}},
{"type":"measure","name":"lsp.did_close","count":39,"duration":0.054},
{"type":"mark","name":"lsp.did_close","count":40,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/fix-supabase-security-warnings.sql"}}},
{"type":"measure","name":"lsp.did_close","count":40,"duration":0.036},
{"type":"mark","name":"lsp.did_close","count":41,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/supabase/migrations/20251003225603_production_security_optimization.sql"}}},
{"type":"measure","name":"lsp.did_close","count":41,"duration":0.036},
{"type":"mark","name":"lsp.did_close","count":42,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/src/lib/supabase.ts"}}},
{"type":"measure","name":"lsp.did_close","count":42,"duration":0.367},
{"type":"mark","name":"lsp.testing_update"},
{"type":"measure","name":"lsp.testing_update","count":24,"duration":0.097},
{"type":"mark","name":"lsp.did_open","count":43,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/security-update-oct-2025.sql","languageId":"sql","version":1,"text":""}}},
{"type":"measure","name":"lsp.did_open","count":43,"duration":0.054},
{"type":"mark","name":"lsp.did_change_batched","count":3,"args":"file:///workspaces/ProspectPro/database/security-update-oct-2025.sql"},
{"type":"measure","name":"lsp.did_change_batched","count":3,"duration":14.873},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":1,"duration":0.02},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":2,"duration":0.011},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":3,"duration":0.048},
{"type":"mark","name":"lsp.did_open","count":44,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/simple-security-migration.sql","languageId":"sql","version":1,"text":""}}},
{"type":"measure","name":"lsp.did_open","count":44,"duration":0.05},
{"type":"mark","name":"lsp.did_change_batched","count":4,"args":"file:///workspaces/ProspectPro/database/simple-security-migration.sql"},
{"type":"measure","name":"lsp.did_change_batched","count":4,"duration":7.53},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":3,"duration":0.017},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":4,"duration":0.009},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":4,"duration":0.341},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":5,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":6,"duration":0.002},
{"type":"mark","name":"lsp.did_open","count":45,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/supabase/migrations/20251003232115_security_update_oct_2025.sql","languageId":"sql","version":1,"text":""}}},
{"type":"measure","name":"lsp.did_open","count":45,"duration":0.053},
{"type":"mark","name":"lsp.did_change_batched","count":5,"args":"file:///workspaces/ProspectPro/supabase/migrations/20251003232115_security_update_oct_2025.sql"},
{"type":"measure","name":"lsp.did_change_batched","count":5,"duration":0.116},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":7,"duration":0.025},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":5,"duration":0.026},
{"type":"mark","name":"lsp.did_open","count":46,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/database/complete-schema-security.sql","languageId":"sql","version":1,"text":""}}},
{"type":"measure","name":"lsp.did_open","count":46,"duration":0.041},
{"type":"mark","name":"lsp.did_change_batched","count":6,"args":"file:///workspaces/ProspectPro/database/complete-schema-security.sql"},
{"type":"measure","name":"lsp.did_change_batched","count":6,"duration":10.932},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":8,"duration":0.012},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":9,"duration":0.012},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":6,"duration":0.022},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":10,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":11,"duration":0.002},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":12,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":13,"duration":0.001},
{"type":"mark","name":"lsp.did_open","count":47,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/supabase/migrations/20251003232321_complete_schema_security.sql","languageId":"sql","version":1,"text":""}}},
{"type":"measure","name":"lsp.did_open","count":47,"duration":0.058},
{"type":"mark","name":"lsp.did_change_batched","count":7,"args":"file:///workspaces/ProspectPro/supabase/migrations/20251003232321_complete_schema_security.sql"},
{"type":"measure","name":"lsp.did_change_batched","count":7,"duration":0.19},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":14,"duration":0.019},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":7,"duration":0.023},
{"type":"mark","name":"lsp.did_open","count":48,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md","languageId":"markdown","version":1,"text":""}}},
{"type":"measure","name":"lsp.did_open","count":48,"duration":0.042},
{"type":"mark","name":"lsp.did_change_batched","count":8,"args":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},
{"type":"measure","name":"lsp.did_change_batched","count":8,"duration":10.47},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":15,"duration":0.014},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":16,"duration":0.013},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":8,"duration":0.024},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":17,"duration":0.002},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":18,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":19,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":20,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":21,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":22,"duration":0.001},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":9,"duration":0.024},
{"type":"mark","name":"lsp.did_change_batched","count":9,"args":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},
{"type":"measure","name":"lsp.did_change_batched","count":9,"duration":0.092},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":10,"duration":0.013},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":11,"duration":0.008},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":12,"duration":0.006},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":23,"duration":0.0},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":13,"duration":0.023},
{"type":"mark","name":"lsp.did_save"},
{"type":"measure","name":"lsp.did_save","count":14,"duration":0.022},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":24,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":25,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":26,"duration":0.001},
{"type":"mark","name":"lsp.diagnostic"},
{"type":"measure","name":"lsp.diagnostic","count":27,"duration":0.001},
{"type":"mark","name":"lsp.code_action","count":1,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},"range":{"start":{"line":0,"character":0},"end":{"line":0,"character":0}},"context":{"diagnostics":[],"triggerKind":2}}},
{"type":"mark","name":"lsp.document_symbol","count":1,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"}}},
{"type":"mark","name":"lsp.inlay_hint","count":1,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},"range":{"start":{"line":0,"character":0},"end":{"line":112,"character":41}}}},
{"type":"mark","name":"lsp.document_symbol","count":2,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"}}},
{"type":"mark","name":"lsp.code_lens","count":1,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"}}},
{"type":"mark","name":"lsp.folding_range","count":1,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"}}},
{"type":"mark","name":"lsp.inlay_hint","count":2,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},"range":{"start":{"line":0,"character":0},"end":{"line":125,"character":0}}}},
{"type":"mark","name":"lsp.inlay_hint","count":3,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},"range":{"start":{"line":0,"character":0},"end":{"line":138,"character":0}}}},
{"type":"mark","name":"lsp.code_action","count":2,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},"range":{"start":{"line":39,"character":0},"end":{"line":39,"character":43}},"context":{"diagnostics":[],"triggerKind":2}}},
{"type":"mark","name":"lsp.hover","count":1,"args":{"textDocument":{"uri":"file:///workspaces/ProspectPro/SECURITY_UPDATE_MANUAL_GUIDE.md"},"position":{"line":38,"character":3}}},
